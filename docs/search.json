[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "The lectures of Andy Weeger are published here.\n\nLectures\n\nBachelor\n\nService Management\n\n\n\nMaster\n\nIntro to AI"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Me",
    "section": "",
    "text": "For more details please check my rofile at the HNU website"
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#sci-fi",
    "href": "lectures/intro-to-ai/c1-intro.html#sci-fi",
    "title": "C1 — Intro",
    "section": "Sci-Fi",
    "text": "Sci-Fi\n\nThe perception of AI changed over the decades. This is well reflected in Sci-Fi Movies, e.g.\n\nR2D2 in Star Wars\nThe Terminator\nAgent Smith in the Matrix\nSonny in I,Robot\nWall·E\netc."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#reality",
    "href": "lectures/intro-to-ai/c1-intro.html#reality",
    "title": "C1 — Intro",
    "section": "Reality",
    "text": "Reality\n\nWill the fictions become reality? We will se. In any case, the intellectual frontiers of AI are wide open. The subfields span from artificial general intelligence (learning, reasoning, perception, etc.) to specific fields (e.g., translating, playing go) (Russel and Norvig 2022).\n\n\n“I believe it’s going to change the world more than anything in the history of mankind — even more than electricity.” —Kai-Fu Lee\n\n\n“The pace of progress in artificial intelligence is incredibly fast. Unless you have direct exposure to groups like Deepmind, you have no idea how fast—it is growing at a pace close to exponential. The risk of something seriously dangerous happening is in the five-year timeframe. 10 years at most.” —Elon Musk\n\n\n“Forget artificial intelligence - in the brave new world of big data, it’s artificial idiocy we should be looking out for.” —Tom Chatfield"
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#towards-a-definition-of-ai",
    "href": "lectures/intro-to-ai/c1-intro.html#towards-a-definition-of-ai",
    "title": "C1 — Intro",
    "section": "Towards a definition of AI",
    "text": "Towards a definition of AI\nAI is the science of making machines to\n\n\nthink (though processes and reasoning)\n\nlike people\nrationally\n\nand to act (behavior)\n\nlike people\nrationally (Russel and Norvig 2022)\n\n\n\n\n\n\n\n\n\n\nWhat is rational?\n\n\n\nThe term rational is used here in a very specific, technical way:\n\nRational: maximally achieving pre-defined goals\nRationality only concerns what decisions are made (not the thought process behind them)\nGoals are expressed in terms of the utility of outcomes\nBeing rational means maximizing your expected utility"
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#acting-humanly",
    "href": "lectures/intro-to-ai/c1-intro.html#acting-humanly",
    "title": "C1 — Intro",
    "section": "Acting humanly",
    "text": "Acting humanly\n\nThe Turing Test approach\nThe Turing Test (Turing 1950) tests if a computer has the ability to mimic peoples’ behavior. To pass the test, it would need following capabilities:\n\n\nnatural language processing (communicate)\nknowledge representation (store information)\nautomated reasoning (answer questions, draw new conclusions)\nmachine learning (adapt to new circumstances)\n\n\n\nWant to do a Turing Test? Play “Bot or Not”\n\n\n\n\n\n\n\n\nTuring Test\n\n\n\nThe Turing Test (Turing 1950) was designed as a tought experiment that would sidestep the philosophical vagueness of the question “Can a machine think?” A computer passes the test if a human interrogator, after posing some written questions, cannot tell wether the written responses come from a person or from a computer (Russel and Norvig 2022).\nThe Total Turing Test additionally requires interaction with objects and people in the real world. This also requires computer vision and robotic capabilities."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#thinking-humanly",
    "href": "lectures/intro-to-ai/c1-intro.html#thinking-humanly",
    "title": "C1 — Intro",
    "section": "Thinking humanly",
    "text": "Thinking humanly\n\nThe cognitive modelling approach\nCognitive science is the study of the human brain and its processes — it examines how the human brain may be functioning. Cognitive science requires analytical observation and experimentation. We can learn about human thought in three ways (Russel and Norvig 2022):\n\n\nintrospection (trying to catch our own thoughts)\nexperiments (observing a person in action)\nbrain imaging (observing the brain in action)\n\n\n\n\n\n\n\n\n\nDifferences between cognitive computing and AI\n\n\n\nCognitive science is about making computers solve complex problems similar to how humans solve problems. Cognitive computing tries to replicate how humans would solve problems, while AI is not bound to human cognitive processes."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#thinking-rationally",
    "href": "lectures/intro-to-ai/c1-intro.html#thinking-rationally",
    "title": "C1 — Intro",
    "section": "Thinking rationally",
    "text": "Thinking rationally\n\nThe laws of thought approach\nThe “laws of thought” refer to fundamental axiomatic rules upon which rational discorse itself is often considered to be based.\n\n\nSocrates is a man and all men are mortal,\nthus, it can be concluded that Socrates is mortal\n-Aristotle\n\n\n\nIn principle, computers have been able to solve any solvable problem (i.e., make correct inferences), as long as\n\n\n\nthere are statements about any objects in the world,\nstatements about the relations among them, and\nsufficient computing power available\n\n\n\n\n\n\n\n\n\nLogic, knowledge and probability\n\n\n\nThese laws of thought were supposed to govern the operation of the mind; the studies initiated the field called logic. However, human decisions are not always mathematically perfect or logical.\nLogic as conventionally understood requires knowledge of the world that is certain. As this condition is seldom achieved, the theory of probability fills this gap. Probability allows for rigorous reasoning with uncertain information. (Russel and Norvig 2022)"
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#acting-rationally",
    "href": "lectures/intro-to-ai/c1-intro.html#acting-rationally",
    "title": "C1 — Intro",
    "section": "Acting rationally",
    "text": "Acting rationally\n\nThe rational agent approach\nAn agent is something that acts, an rational agent is one that acts so as to achieve the best coutcome (i.e., does the right thing), or, when there is uncertainty, the best expected outcome (i.e., does the appropriate thing).\n\nWhat counts as the best thing is defined by the objective that we provide to the agent (Russel and Norvig 2022).\n\n\nThe approach goes beyond the “laws of thought” approach as it involves actions based on\n\n\n\ninference (deducing that a given action is the best and then to act on this conclusion) and\non other mechanisms such as reflex (when speed is more sucessful than careful deliberation that takes some time)\n\n\n\n\n\n\n\n\n\nStandard model in AI\n\n\n\nRussel and Norvig (2022) call the approach where the primary definition of success is getting better and better at achieving rigid human-specified goals the standard model of AI research. This standard model prevails not only in AI, “but also in control theory, where a controller minimizes a cost funciton; in operations research, where a policy maximizes a sum of rewards; in statistics, where a decision rule minimizes a loss funciton; and in economics, where a decision maker maximizes utility or some measure of social welfare” (p. 22).\nThey also criticize the standard model because it is increasingly difficult to specify the goal completely and correctly (e.g., autonomous driving involves multiple goals such as reaching the goal safely, where a strict definition of safety requires staying in the garage because driving on the road has a risk of injury due to myriad factors; how should the trade-off between reaching the goal and taking a risk of injury be made? There are so many questions that are difficult to answer a priori). Mis-specified goals most likely do not reflect what human designers intend, e.g., by not taking into account human values that are not included in the goals."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro.html#benificial-machines",
    "href": "lectures/intro-to-ai/c1-intro.html#benificial-machines",
    "title": "C1 — Intro",
    "section": "Benificial machines",
    "text": "Benificial machines\n\nMachines that are provably beneficial to humans\nAccording to Russel and Norvig (2022) Two refinements to the standard model of AI are needed:\n\n\nThe ability of any agent to choose rational actions is constrained by the computational untractability of doing so\nAn intelligent agent should not pursue a definite object, it should pursue objectives that benefit humans, while being uncertain as to what they are\n\n\n\nWhen a machine knows that it does not know the entire objective, it has an incentive to act cautiously, to ask permission, to learn more about our preferences through observation, and to submit to human control."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#sci-fi",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#sci-fi",
    "title": "C1 — Intro",
    "section": "Sci-Fi",
    "text": "Sci-Fi\n\nThe perception of AI changed over the decades. This is well reflected in Sci-Fi Movies, e.g.\n\nR2D2 in Star Wars\nThe Terminator\nAgent Smith in the Matrix\nSonny in I,Robot\nWall·E\netc."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#reality",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#reality",
    "title": "C1 — Intro",
    "section": "Reality",
    "text": "Reality\n\nWill the fictions become reality? We will se. In any case, the intellectual frontiers of AI are wide open. The subfields span from artificial general intelligence (learning, reasoning, perception, etc.) to specific fields (e.g., translating, playing go) (Russel and Norvig 2022).\n\n\n“I believe it’s going to change the world more than anything in the history of mankind — even more than electricity.” —Kai-Fu Lee\n\n\n“The pace of progress in artificial intelligence is incredibly fast. Unless you have direct exposure to groups like Deepmind, you have no idea how fast—it is growing at a pace close to exponential. The risk of something seriously dangerous happening is in the five-year timeframe. 10 years at most.” —Elon Musk\n\n\n“Forget artificial intelligence - in the brave new world of big data, it’s artificial idiocy we should be looking out for.” —Tom Chatfield"
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#towards-a-definition-of-ai",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#towards-a-definition-of-ai",
    "title": "C1 — Intro",
    "section": "Towards a definition of AI",
    "text": "Towards a definition of AI\nAI is the science of making machines to\n\n\nthink (though processes and reasoning)\n\nlike people\nrationally\n\nand to act (behavior)\n\nlike people\nrationally (Russel and Norvig 2022)\n\n\n\n\n\n\n\n\n\n\nWhat is rational?\n\n\nThe term rational is used here in a very specific, technical way:\n\nRational: maximally achieving pre-defined goals\nRationality only concerns what decisions are made (not the thought process behind them)\nGoals are expressed in terms of the utility of outcomes\nBeing rational means maximizing your expected utility"
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#acting-humanly",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#acting-humanly",
    "title": "C1 — Intro",
    "section": "Acting humanly",
    "text": "Acting humanly\nThe Turing Test approach\nThe Turing Test (Turing 1950) tests if a computer has the ability to mimic peoples’ behavior. To pass the test, it would need following capabilities:\n\n\nnatural language processing (communicate)\nknowledge representation (store information)\nautomated reasoning (answer questions, draw new conclusions)\nmachine learning (adapt to new circumstances)\n\n\n\nWant to do a Turing Test? Play “Bot or Not”\n\n\n\n\n\n\n\n\nTuring Test\n\n\nThe Turing Test (Turing 1950) was designed as a tought experiment that would sidestep the philosophical vagueness of the question “Can a machine think?” A computer passes the test if a human interrogator, after posing some written questions, cannot tell wether the written responses come from a person or from a computer (Russel and Norvig 2022).\nThe Total Turing Test additionally requires interaction with objects and people in the real world. This also requires computer vision and robotic capabilities."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#thinking-humanly",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#thinking-humanly",
    "title": "C1 — Intro",
    "section": "Thinking humanly",
    "text": "Thinking humanly\nThe cognitive modelling approach\nCognitive science is the study of the human brain and its processes — it examines how the human brain may be functioning. Cognitive science requires analytical observation and experimentation. We can learn about human thought in three ways (Russel and Norvig 2022):\n\n\nintrospection (trying to catch our own thoughts)\nexperiments (observing a person in action)\nbrain imaging (observing the brain in action)\n\n\n\n\n\n\n\n\n\nDifferences between cognitive computing and AI\n\n\nCognitive science is about making computers solve complex problems similar to how humans solve problems. Cognitive computing tries to replicate how humans would solve problems, while AI is not bound to human cognitive processes."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#thinking-rationally",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#thinking-rationally",
    "title": "C1 — Intro",
    "section": "Thinking rationally",
    "text": "Thinking rationally\nThe laws of thought approach\nThe “laws of thought” refer to fundamental axiomatic rules upon which rational discorse itself is often considered to be based.\n\n\nSocrates is a man and all men are mortal,\nthus, it can be concluded that Socrates is mortal\n-Aristotle\n\n\n\nIn principle, computers have been able to solve any solvable problem (i.e., make correct inferences), as long as\n\n\n\nthere are statements about any objects in the world,\nstatements about the relations among them, and\nsufficient computing power available\n\n\n\n\n\n\n\n\n\nLogic, knowledge and probability\n\n\nThese laws of thought were supposed to govern the operation of the mind; the studies initiated the field called logic. However, human decisions are not always mathematically perfect or logical.\nLogic as conventionally understood requires knowledge of the world that is certain. As this condition is seldom achieved, the theory of probability fills this gap. Probability allows for rigorous reasoning with uncertain information. (Russel and Norvig 2022)"
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#acting-rationally",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#acting-rationally",
    "title": "C1 — Intro",
    "section": "Acting rationally",
    "text": "Acting rationally\nThe rational agent approach\nAn agent is something that acts, an rational agent is one that acts so as to achieve the best coutcome (i.e., does the right thing), or, when there is uncertainty, the best expected outcome (i.e., does the appropriate thing).\n\nWhat counts as the best thing is defined by the objective that we provide to the agent (Russel and Norvig 2022).\n\n\nThe approach goes beyond the “laws of thought” approach as it involves actions based on\n\n\n\ninference (deducing that a given action is the best and then to act on this conclusion) and\non other mechanisms such as reflex (when speed is more sucessful than careful deliberation that takes some time)\n\n\n\n\n\n\n\n\n\nStandard model in AI\n\n\nRussel and Norvig (2022) call the approach where the primary definition of success is getting better and better at achieving rigid human-specified goals the standard model of AI research. This standard model prevails not only in AI, “but also in control theory, where a controller minimizes a cost funciton; in operations research, where a policy maximizes a sum of rewards; in statistics, where a decision rule minimizes a loss funciton; and in economics, where a decision maker maximizes utility or some measure of social welfare” (p. 22).\nThey also criticize the standard model because it is increasingly difficult to specify the goal completely and correctly (e.g., autonomous driving involves multiple goals such as reaching the goal safely, where a strict definition of safety requires staying in the garage because driving on the road has a risk of injury due to myriad factors; how should the trade-off between reaching the goal and taking a risk of injury be made? There are so many questions that are difficult to answer a priori). Mis-specified goals most likely do not reflect what human designers intend, e.g., by not taking into account human values that are not included in the goals."
  },
  {
    "objectID": "lectures/intro-to-ai/c1-intro-slides.html#benificial-machines",
    "href": "lectures/intro-to-ai/c1-intro-slides.html#benificial-machines",
    "title": "C1 — Intro",
    "section": "Benificial machines",
    "text": "Benificial machines\nMachines that are provably beneficial to humans\nAccording to Russel and Norvig (2022) Two refinements to the standard model of AI are needed:\n\n\nThe ability of any agent to choose rational actions is constrained by the computational untractability of doing so\nAn intelligent agent should not pursue a definite object, it should pursue objectives that benefit humans, while being uncertain as to what they are\n\n\n\nWhen a machine knows that it does not know the entire objective, it has an incentive to act cautiously, to ask permission, to learn more about our preferences through observation, and to submit to human control."
  },
  {
    "objectID": "lectures/intro-to-ai/administrivia.html#gap-model",
    "href": "lectures/intro-to-ai/administrivia.html#gap-model",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "GAP Model",
    "text": "GAP Model\n\n\n\n\n\nGAP Modell Leonardi (2013)\n\n\n\n\n\nsome explanation\nothers here"
  },
  {
    "objectID": "lectures/intro-to-ai/administrivia.html#going-to-sleep",
    "href": "lectures/intro-to-ai/administrivia.html#going-to-sleep",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep\n\n\nTab ABTab BA\n\n\nTab content AB …\n\n\nTab content BA …\n. . .\nGO!"
  },
  {
    "objectID": "lectures/intro-to-ai/administrivia.html#incrementals",
    "href": "lectures/intro-to-ai/administrivia.html#incrementals",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Incrementals",
    "text": "Incrementals\n\n\nEat spaghetti\nDrink wine"
  },
  {
    "objectID": "lectures/intro-to-ai/administrivia.html#spalten",
    "href": "lectures/intro-to-ai/administrivia.html#spalten",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Spalten",
    "text": "Spalten\n\n\n\ncontents…\n\n\ncontents…"
  },
  {
    "objectID": "lectures/intro-to-ai/administrivia.html#come-on",
    "href": "lectures/intro-to-ai/administrivia.html#come-on",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Come on",
    "text": "Come on\ncontent before the pause\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important."
  },
  {
    "objectID": "lectures/intro-to-ai/s-administrivia.html#gap-model",
    "href": "lectures/intro-to-ai/s-administrivia.html#gap-model",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "GAP Model",
    "text": "GAP Model\n\n\n\n\n\nGAP Modell Leonardi (2013)\n\n\n\n\n\nsome explanation\nothers here"
  },
  {
    "objectID": "lectures/intro-to-ai/s-administrivia.html#going-to-sleep",
    "href": "lectures/intro-to-ai/s-administrivia.html#going-to-sleep",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep\n\n\nTab ABTab BA\n\n\nTab content AB …\n\n\nTab content BA …\n. . .\nGO!"
  },
  {
    "objectID": "lectures/intro-to-ai/s-administrivia.html#incrementals",
    "href": "lectures/intro-to-ai/s-administrivia.html#incrementals",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Incrementals",
    "text": "Incrementals\n\n\nEat spaghetti\nDrink wine"
  },
  {
    "objectID": "lectures/intro-to-ai/s-administrivia.html#spalten",
    "href": "lectures/intro-to-ai/s-administrivia.html#spalten",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Spalten",
    "text": "Spalten\n\n\n\ncontents…\n\n\ncontents…"
  },
  {
    "objectID": "lectures/intro-to-ai/s-administrivia.html#come-on",
    "href": "lectures/intro-to-ai/s-administrivia.html#come-on",
    "title": "Intro to Artificial Intelligence 🧠",
    "section": "Come on",
    "text": "Come on\ncontent before the pause\n\n\n\n\n\n\n\n\nNote\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important."
  },
  {
    "objectID": "lectures/service-management/administrivia.html",
    "href": "lectures/service-management/administrivia.html",
    "title": "Service Management",
    "section": "",
    "text": "Top\nSlides"
  },
  {
    "objectID": "lectures/service-management/c1.html",
    "href": "lectures/service-management/c1.html",
    "title": "C1 — Relevance",
    "section": "",
    "text": "Top\nSlides"
  }
]