<!DOCTYPE html>
<html lang="en"><head>
<link href="../../../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Andy Weeger">
  <meta name="dcterms.date" content="2024-02-12">
  <title>awe.lectures – Agent Types</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/theme/quarto-38905d13cb9cc007a76808dad09f60e2.css">
  
  <script type="text/javascript" charset="UTF-8">
  document.addEventListener('DOMContentLoaded', function () {
  cookieconsent.run({
    "notice_banner_type":"interstitial",
    "consent_type":"express",
    "palette":"dark",
    "language":"en",
    "page_load_consent_levels":["strictly-necessary"],
    "notice_banner_reject_button_hide":false,
    "preferences_center_close_button_hide":false,
    "website_name":""
    ,
  "language":"en"
    });
  });
  </script> 
    
  <link href="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Agent Types – awe.lectures">
<meta property="og:description" content="🧠 Introduction to AI">
<meta property="og:site_name" content="awe.lectures">
</head>
<body class="quarto-light">
<div class="footer custom">

    <div class="version">
        V0.4
    </div>

    <div class="footnote">
        Andy Weeger / Neu-Ulm University of Applied Sciences Neu-Ulm / Introduction to Artificial Intelligence (AI)
   </div>

    <div class="logo">
        <svg viewbox="0 0 125 39" xmlns="http://www.w3.org/2000/svg" version="1.1" space="preserve">
            <g>
             <title>HNU</title>
             <path d="m8.58222,0l7.5,0l0,12.7l-7.5,0l0,-12.7zm7.4,24.1l6.5,0l0,-3l-13.9,0l0,15.4l-3.9,0l0,2.3l11.3,0l0,-14.7zm24,-24.1l-7.4,0l0,36.5l-3.9,0l0,2.3l11.3,0l0,-38.8zm60.2,28.4c1.1,0 2.1,-0.1 2.9,-0.4c-1.3,-1.2 -1.9,-3.2 -1.9,-6.4l0,-21.6l-7.4,0l0,19.3c0,5.9 1.5,9.1 6.4,9.1z" id="svg_1"></path>
             <path d="m96.78222,37c2.8,1.6 6.4,2.5 10.6,2.5c11.2,0 17.7,-6 17.7,-16.3l0,-23.2l-7.4,0l0,21.1c0,11.3 -7.7,16.1 -17.6,16.1c-1.1,0 -2.2,-0.1 -3.3,-0.2zm-30.8,-27l-7.1,-10l-7.3,0l14.4,20.4l0,-10.4zm17,28.8l0,-38.8l-7.5,0l0,36.5l-3.5,0l1.7,2.3l9.3,0zm-24,-14.8l-8,-10.8l0,23.3l-3,0l0,2.3l11,0l0,-14.8z" id="svg_2"></path>
            </g>   
        </svg>
    </div>

</div>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg" data-background-opacity="1" data-background-size="cover" class="quarto-title-block">
  <h1 class="title">Agent Types</h1>
  <p class="subtitle">🧠 Introduction to AI</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Andy Weeger 
</div>
        <p class="quarto-title-affiliation">
            Neu-Ulm University of Applied Sciences
          </p>
    </div>
</div>

  <p class="date">February 12, 2024</p>
</section>
<section>
<section id="agents" class="title-slide slide level1 vertical-center" data-background-color="#0333ff" data-background-image="../assets/bg.jpeg">
<h1>Agents</h1>

</section>
<section id="agent" class="title-slide slide level2">
<h2>Agent</h2>
<div id="fig-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/actor.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Agents interact with environments through sensors and actuators
</figcaption>
</figure>
</div>
<aside class="notes">
<p>An agent is anything that can be viewed as perceiving its <strong>environment</strong> through <strong>sensors</strong> and acting upon that environment through <strong>actuators</strong>.</p>
<ul>
<li>The term <strong>percept</strong> refers to the content an agent’s sensors are perceiving</li>
<li>An agent’s <strong>percept sequence</strong> is the complete history of everything the agent has ever perceived</li>
<li>The <strong>agent function</strong> maps any given percept sequence to an action (an abstract mathematical description)</li>
<li>The agent function for an AI agent will be implemented by an <strong>agent program</strong> (a concrete implementation, running within some physical system)</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>To illustrate these ideas <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022, p. 55</a>)</span> use a simple example—the vacuum-cleaner world, which consists of a robotic vacuum-cleaning agent in a world consisting of squares that can be either dirty or clean. The vacuum agent perceives which square it is in and whether there is dirt in the square. The agent starts in square A. The available actions are to move to the right, move to the left, suck up the dirt, or do nothing. One very simple agent function is the following: if the current square is dirty, then suck; otherwise, move to the other square.</p>
</div>
</div>
</div>
<p>According to <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022, p. 56</a>)</span>, all areas of engineering can be seen as designing artifacts that interact with the world. AI operates at the most interesting end to the spectrum, where the artifacts have significant computational resources and the task environment requires nontrivial decision making.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="rational-agent" class="title-slide slide level2">
<h2>Rational agent</h2>
<p>A rational agent is one that does the right thing.</p>
<div class="fragment">
<blockquote>
<p>For each possible percept sequence, a rational agent should select an <strong>action</strong> that is expected to maximize its <strong>performance measure</strong>, given the evidence provided by the <strong>percept sequence</strong> and whatever built-in <strong>knowledge</strong> the agent has <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 58</a>)</span>.</p>
</blockquote>
</div>
<aside class="notes">
<p>What is rational at any given time depends on four things:</p>
<ul>
<li>The performance measure that defines the criterion of success</li>
<li>The agent’s prior knowledge of the environment</li>
<li>The actions that the agent can performance</li>
<li>The agent’s percept sequence to date</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>Under following circumstances, the vacuum cleaning agent is rational:</p>
<ul>
<li>The performance measure of the vacuum cleaner might award one point for each clean square at each time step, over a “lifetime” of 1,000 time steps (to prevent the cleaner to oscillate needlessly back and forth).</li>
<li>The “geography” of the environment is known <em>a priori</em> but the dirt distribution and the initial location of the agent are not. Clean squares stay clean and sucking cleans the current square. The <em>Right</em> and <em>Left</em> actions move the agent one square except when this would take the agent outside the environment in which case the agent remains where it is.</li>
<li>The only available action is <em>Right</em>, <em>Left</em>, and <em>Suck</em>.</li>
<li>The agent correctly perceives its location and whether that location contains dirt.</li>
</ul>
<p>For details such as tabulated agent functions please see <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022</a>)</span>.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>It can be quite hard to formulate a performance measure correctly, however:</p>
<blockquote>
<p>If we use, to achieve our purposes, a mechanical agency with those operation we cannot interfere once we have started it […] we had better be quite sure that the purpose built into the machine is the purpose which we really desire <span class="citation" data-cites="Wiener1960Some">(<a href="#/literature" role="doc-biblioref" onclick="">Wiener, 1960, p. 1358</a>)</span></p>
</blockquote>
</div>
</section>

<section id="exercise" class="title-slide slide level2 html-hidden unlisted discussion-slide" data-background-color="black">
<h2>Exercise</h2>
<div class="large">
<p>Under which circumstances does a <strong>vacuum cleaning agent</strong> act rational?</p>
</div>
</section>

<section id="rationality" class="title-slide slide level2">
<h2>Rationality</h2>
<p>Rationality is not the same as perfection.</p>
<ul>
<li class="fragment">Rationality maximizes <em>expected</em> performance</li>
<li class="fragment">Perfection maximizes <em>actual</em> performance</li>
<li class="fragment">Perfection requires omniscience</li>
<li class="fragment">Rational choice depends only on the percept sequence <em>to date</em></li>
</ul>
<aside class="notes">
<p>As the environment is usually not completely known <em>a priori</em> and completely predictable (or stable), information gathering and learning are important parts of rationality <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 59</a>)</span>.</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>The vacuum cleaner needs to explore an initially unknown environment (i.e., exploration) to maximize its expected performance. In addition, a vacuum cleaner that learns to predict where and when additional dirt will appear will do better than one that does not.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section>
<section id="environments" class="title-slide slide level1 vertical-center" data-background-color="#0333ff" data-background-image="../assets/bg.jpeg">
<h1>Environments</h1>

</section>
<section id="components" class="title-slide slide level2">
<h2>Components</h2>
<p>Before designing an agent (<em>the solution</em>), the task environment (<em>the problem</em>) must be specified as fully as possible, including</p>
<ul>
<li class="fragment">the performance measure (P),</li>
<li class="fragment">the environment (E),</li>
<li class="fragment">the actuators (A), and</li>
<li class="fragment">the sensors (S)</li>
</ul>
<div class="fragment">
<p><span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022</a>)</span> call the task environment PEAS.</p>
</div>
<aside class="notes">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example of an PEAS description</strong></p>
</div>
<div class="callout-content">
<p>Task environment of a taxi driver agent</p>
<ul>
<li><strong>P</strong>: Safe, fast, legal, comfortable, maximize profits, minimize impact on other road users</li>
<li><strong>E</strong>: Roads, other road users, police, pedestrians, customers, weather</li>
<li><strong>A</strong>: Steering, accelerator, brake, signal horn, display, speech</li>
<li><strong>S</strong>: Cameras, radar, speedometer, GPS, engine, sensors, accelerometer, microphones, touchscreen</li>
</ul>
<p>Source: <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022, p. 61</a>)</span></p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="properties" class="title-slide slide level2">
<h2>Properties</h2>
<p>Task environments can be categorized along following dimensions <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, pp. 62–64</a>)</span>:</p>
<ul>
<li class="fragment">Fully observable <em>vs.</em> partially observable</li>
<li class="fragment">Single agent <em>vs.</em> multi-agent</li>
<li class="fragment">Deterministic <em>vs.</em> nondeterministic</li>
<li class="fragment">Episodic <em>vs.</em> sequential</li>
<li class="fragment">Static <em>vs.</em> dynamic</li>
<li class="fragment">Discrete <em>vs.</em> continuous</li>
<li class="fragment">Known <em>vs.</em> unknown</li>
</ul>
<aside class="notes">
<p><strong>Explanations</strong></p>
<ul>
<li>If an agent’s sensors give it access to the full state of the environment at any point in time, then we say that the task environment is <em>fully observable</em> (e.g., image analysis).</li>
<li>When multiple agents intend to maximize a performance measure that depends on the behavior of other agents, we say the environment is <em>multi-agent</em> (e.g., chess).</li>
<li>When the environment is completely determined by the current state and the actions performed by the agent(s), it is called a <em>deterministic</em> environment (e.g., crossword puzzle). When a model of the environment explicitly uses probabilities, it is called a <em>stochastic</em> environment (e.g., poker).</li>
<li>If an agent’s experience is divided into atomic episodes in which the agent receives a perception and then performs a single action, and if the next episode does not depend on the actions performed in the previous episodes, then we say that the task environment is <em>episodic</em> (e.g., image analysis).</li>
<li>If the environment changes while an agent is deliberating, then the environment is <em>dynamic</em> (e.g., taxi driving).</li>
<li>If the environment has a finite number of different states, we speak of <em>discrete</em> environments (e.g., chess).</li>
<li>If the outcomes (or outcome probabilities) for all actions are given, then the environment is <em>known</em> (e.g., solitaire card game).</li>
</ul>
<p>Source: <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022</a>)</span>, p.62-64</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>The hardest case is <em>partially observable, multi-agent, nondeterministic, sequential, dynamic, and continuous.</em></p>
</div>
</section>

<section id="exercise-1" class="title-slide slide level2 html-hidden unlisted discussion-slide" data-background-color="black">
<h2>Exercise</h2>
<div class="large">
<p>Describe the task environment of a <strong>taxi driver agent</strong>.</p>
</div>
</section>
</section>
<section>
<section id="agent-types" class="title-slide slide level1 vertical-center" data-background-color="#0333ff" data-background-image="../assets/bg.jpeg">
<h1>Agent types</h1>

</section>
<section id="simple-reflex-agents" class="title-slide slide level2">
<h2>Simple reflex agents</h2>
<div id="fig-sr-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-sr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/simple-reflex-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: A simple reflex agent
</figcaption>
</figure>
</div>
<aside class="notes">
<div class="small">
<p>Rectangles are used to denote the current internal state of the agent’s decision process, rectangles with rounded corners to represent the background information used in the process.</p>
</div>
<p>Simple reflex agents select actions on the basis of the <em>current</em> percept, ignoring the rest of the percept history. Thus, these agents work only if the correct decision can be made on the basis of just the current percept. The environment needs to be fully observable <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 68</a>)</span>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="model-based-reflex-agents" class="title-slide slide level2">
<h2>Model-based reflex agents</h2>
<div id="fig-mr-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-mr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/model-based-reflex-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: A model-based reflex agent
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Model-based reflex agents use transition models and sensor models to keep track of the state of the world as perceived by the sensors (i.e., internal state). <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 70</a>)</span>.</p>
<p>The <strong>transition model</strong> reflects “how the world works,” i.e., how the world evolves (a) independently of the agent and (b) depending on the agent’s actions.</p>
<p>The <strong>sensor model</strong> reflects how the state of the world is reflected in the agent’s percepts (i.e., by its sensors).</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Types of representation of states</strong></p>
</div>
<div class="callout-content">
<p>The representations of states can be placed along an axis of increasing complexity and expressive power <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, pp. 76–77</a>)</span>:</p>
<ul>
<li>An <strong>atomic representation</strong> is one in which each state is treated as a black box with not internal structure, meaning the state either does or does not match what you’re looking for. In a sliding tile puzz_le, for instance, you either have the correct alignment of tiles or you do not.</li>
<li>A <strong>factored representation</strong> is one in which the states are defined by set of features (e.g., Boolean, real-valued, or one of a fixed set of symbols). In a sliding puzzle, this might be a simple heuristic like “number of tiles out of place”.</li>
<li>A <strong>structured representation</strong> is one in which the states are expressed in form of objects and relations between them (e.g., expressed by logic or probability). Such knowledge about relations called facts.</li>
</ul>
<p>The more expressive language is much more concise, but makes reasoning and learning more complex.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="goal-based-agents" class="title-slide slide level2">
<h2>Goal-based agents</h2>
<div id="fig-gb-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-gb-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/goal-based-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gb-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: A model-based, goal-based agent
</figcaption>
</figure>
</div>
<aside class="notes">
<p>A model-based, goal-based agent keeps track of the world state as well as a set of goals it is trying to achieve. Such an agent chooses an action that will (eventually) lead to the achievement of its goals <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 72</a>)</span>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="utility-based-agents" class="title-slide slide level2">
<h2>Utility-based agents</h2>
<div id="fig-ub-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-ub-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/utility-based-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ub-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: A model-based, utility-based agent
</figcaption>
</figure>
</div>
</section>
<aside class="notes">
<p>A model-based, utility-based agent uses a model of the world, along with a utility function that measures its preferences among states of the world. It chooses the action that leads to the best expected utility, where expected utility is computed by averaging over all possible states, weighted by the probability of the outcome <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 73</a>)</span>.</p>
<p>The <strong>utility function</strong> is essentially an internalization of the performance measure.</p>
<p>A utility-based agent has many advantages in terms of flexibility and learning, which are particularly helpful in environments characterized by partial observability and nondeterminism.</p>
<p>In addition, there are cases where the goals are insufficient but a utility-based agent can still make rational decisions based on the probabilities and the utilities of the outcomes:</p>
<ul>
<li>When there are conflicting goals, the utility function specifies the appropriate tradeoff.</li>
<li>Likelihood of success (i.e., goal achievement) can be weighed against the importance of the goals</li>
</ul>
<p>Model- and utility-based agents are difficult to implement. They need to model and keep track of the task environment, which requires ingenious sensors, sophisticated algorithms, and a high computational complexity.</p>
<p>There are also utility-based agents that are not model-based. These agents just learn what action is best in a particular situation without any “understanding” of its impact on the environment (e.g., based on reinforcement learning).</p>
<section id="main-differences" class="slide level3">
<h3>Main differences</h3>
<p>The main difference between <strong>simple reflex agents</strong> and <strong>model-based reflex agents</strong> is that the latter keep track of the state of the world. Model-based reflex agents generate knowledge about how the world evolves independently of the agent and how actions of the agent change the world (i.e., they have knowledge about “how the world works”). This knowledge is “stored” in the transition model of the world. A model-based reflex agents still decides on condition-action rules which action to take (i.e., the codified reflexes).</p>
<p>The main difference between <strong>model-based reflex agents</strong> and <strong>goal-based agents</strong> is that it does not act on fixed condition-action rules, but on some sort of goal information that describes situations that are desirable (e.g., in the case of route-finding the destination). Based on the goal, the best possible action (based on the knowledge of the world), needs to be selected. Goal-based decision making involves consideration of the future based on the transition model (i.e., “what will happen if I do such-and-such?”) and how it helps to achieve the goal. In reflex agents designs, this information I not explicitly represented, because the built rules map directly from the percepts to actions, without considering/knowing the future state.</p>
<p>The main difference between <strong>goal-based agents</strong> and <strong>utility-based agents</strong> is that the performance measure is more general. It does not only consider a binary distinction between “goal achieved” and “goal not achieved” but allows comparing different world states according to their relative utility or expected utility, respectively (i.e., how happy the agent is with the resulting state). Utility-based agents can still make rational decisions when there are conflicting goals for which only one can be achieved (here the utility function needs to specify a trade-off) and when there are several goals that the agent can aim for, none of which can be achieved with certainty (here the utility function provides a which in which the likelihood of success can be weighed against the importance of the goals, e.g., speed and energy consumption in routing).</p>
<p>Example: a goal-based agent for routing just selects actions based on a single, binary goal: reaching the destination; a utility-based agents also considers additional goals like spending as less time as possible on the road, spending as less money as possible, having the best scenery on the trip, etc. and tries to maximize overall utility across these goals. In this example, reaching the destiny is the ultimate goal, without achieving that utility would be zero. However, utility will increase or decrease related to how the actions chosen impact the achievement of the other goals, which importance need to be weighed.</p>
</section>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

<section id="recap" class="title-slide slide level2 html-hidden unlisted discussion-slide" data-background-color="black">
<h2>Recap</h2>
<div class="large">
<p>What are the <strong>main differences</strong> between the agents?</p>
</div>
</section>

<section id="main-differences-1" class="title-slide slide level2 html-hidden">
<h2>Main differences</h2>
<p>In contrast to <strong>simple reflex agents</strong>, <strong>model-based reflex agents</strong> keep track of the state of the world (“stored” in the transition model). However, both act on fixed condition-action rules.</p>
<div class="fragment">
<p><strong>Goal-based agents</strong> , have some sort of goal information that describes situations that are desirable and enables them to make goal-based decisions making (i.e., involving consideration of the future based on the transition model.</p>
</div>
<div class="fragment">
<p>The performance measure of <strong>utility-based agents</strong> is more general. It does not only consider a binary distinction between “goal achieved” and “goal not achieved” but allows comparing different world states according to their relative utility or expected utility, respectively.</p>
</div>
<div class="fragment">
<div class="smaller">
<p>Example: a goal-based agent for routing just selects actions based on a single, binary goal: reaching the destination; a utility-based agents also considers additional goals like spending as less time as possible on the road, spending as less money as possible, having the best scenery on the trip, etc. and tries to maximize overall utility across these goals. In this example, reaching the destiny is the ultimate goal, without achieving that utility would be zero. However, utility will increase or decrease related to how the actions chosen impact the achievement of the other goals, which importance need to be weighed.</p>
</div>
</div>
</section>

<section id="learning-agents" class="title-slide slide level2">
<h2>Learning agents</h2>
<div id="fig-l-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/learning-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: A learning agent
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Each type of agent can be either hand-programmed or created as a learning agent. The behavior of learning agents is (also) determined by their own experience, while the behavior of hand-programmed agents is solely determined by their initial programming. Thus, learning agents have greater <strong>autonony</strong>.</p>
<p>A learning agent consists of four conceptual components <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022</a>, p- 74-75)</span>, as shown in <a href="#/fig-l-agent" class="quarto-xref">Figure&nbsp;6</a>:</p>
<ul>
<li>The <strong>performance element</strong> is responsible for taking percepts and selecting actions (i.e., what has previously been considered the entire agent program).</li>
<li>The <strong>learning element</strong> is responsible for improvements. It uses feedback from the critic on how the agent is doing and determines how the performance element should be modified to do better in the future. It can make changes to any of the “knowledge components” shown in the agent diagrams (i.e., condition-action-rules, transition model, sensor model)</li>
<li>The <strong>performance standard</strong> is responsible to inform the agent about the meaning of percepts — are they good nor not (e.g., the meaning of receiving no tips from passengers is a negative contribution to an automated taxis’s overall performance). The standard is fixed and cannot be influenced by the agent.</li>
<li>The <strong>problem generator</strong> is responsible for suggesting actions that lead to new and informative experiences. The problem generator suggests exploratory actions that may be suboptimal in the short term, but can lead to the discovery of better actions in the long term.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section>
<section id="exercises" class="title-slide slide level1 vertical-center" data-background-color="black">
<h1>✏️ Exercises</h1>

</section>
<section id="concepts" class="title-slide slide level2">
<h2>Concepts</h2>
<p>Define in your own words the following terms:</p>
<ul>
<li>Rationality</li>
<li>Autonomy</li>
<li>Agent</li>
<li>Environment</li>
<li>Sensor</li>
<li>Actuator</li>
<li>Percept</li>
<li>Agent function</li>
<li>Agent program</li>
</ul>
</section>

<section id="agent-types-1" class="title-slide slide level2">
<h2>Agent types</h2>
<p>Explain the differences between the following agent types in your own words. Describe the component(s) that is/are specific for each type.</p>
<ul>
<li>Reflex agent</li>
<li>Model-based agent</li>
<li>Goal-based agent</li>
<li>Utility-based agent</li>
<li>Learning agent</li>
</ul>
</section>

<section id="vacuum-cleaner" class="title-slide slide level2">
<h2>Vacuum cleaner</h2>
<p>Under which circumstances does a <strong>robotic vacuum cleaner</strong> act rational?</p>
<p>Describe the task environment of such an agent.</p>
</section>

<section id="peas" class="title-slide slide level2">
<h2>PEAS</h2>
<p>For each of the following agents, specify the performance measure, the environment, the actuators, and the sensors.</p>
<ul>
<li>Microwave oven</li>
<li>Chess program</li>
<li>Autonomous supply delivery</li>
</ul>
</section>

<section id="performance-measure" class="title-slide slide level2">
<h2>Performance measure</h2>
<p>Describe a task environment in which the performance measure is easy to specify completely and correctly, and a in which it is not.</p>
</section>

<section id="assertions" class="title-slide slide level2">
<h2>Assertions</h2>
<p>For each of the following assertions, say whether it is true or false and support your answer with examples or counterexamples where appropriate.</p>
<ol type="1">
<li>An agent that senses only partial information about the state cannot be perfectly rational.</li>
<li>There exist task environments in which no pure reflex agent can behave rationally.</li>
<li>There exists a task environment in which every agent is rational.</li>
<li>Every agent is rational in an unobservable environment.</li>
<li>A perfectly rational poker-playing agent never loses.</li>
</ol>
<aside class="notes">
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Solution notes</a></li><li><a href="#tabset-1-2">Answers</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<p>Open only if you need help.</p>
</div>
<div id="tabset-1-2">
<ol type="1">
<li><strong>False.</strong> Perfect rationality refers to the ability to make gooddecisions given the sensor information received.</li>
<li><strong>True.</strong> A pure reflex agent ignores previous percepts and cannot obtain an optimal state estimate in a partially observable environment</li>
<li><strong>True.</strong> For example, in an environment with a single state, such that all actions have the same reward, it does not matter which action is taken.</li>
<li><strong>False.</strong> Some actions are stupid (and the agent may know this if it has a model) even if it has no environment input.</li>
<li><strong>False.</strong> Unless it draws the perfect hand, the agent can lose if an opponent has better cards.</li>
</ol>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="task-environment" class="title-slide slide level2">
<h2>Task environment</h2>
<p>For each of the following activities characterize the task environment it in terms of the properties discussed in the lecture notes.</p>
<ul>
<li>Playing soccer</li>
<li>Exploring the subsurface oceans of Titan</li>
<li>Shopping for used AI books on the internet</li>
<li>Playing a tennis match</li>
</ul>
</section>

<section id="task-environment-2" class="title-slide slide level2">
<h2>Task environment #2</h2>
<p>For each of the following task environment properties, rank the example task environments from most to least according to how well the environment satisfies the property.</p>
<p>Lay out any assumptions you make to reach your conclusions.</p>
<ol type="a">
<li>Fully observable: driving; document classification; tutoring a student in calculus; skin cancer diagnosis from images</li>
<li>Continuous: driving; spoken conversation; written conversation; climate engineering by stratospheric aerosol injection</li>
<li>Stochastic: driving; sudoku; poker; soccer</li>
<li>Static: chat room; checkers; tax planning; tennis</li>
</ol>
</section>
</section>
<section id="literature" class="title-slide slide level1 smaller scrollable">
<h1>Literature</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-RusselNorvig2022AIMA" class="csl-entry" role="listitem">
Russel, S., &amp; Norvig, P. (2022). <em>Artificial intelligence: A modern approach</em>. Pearson Education.
</div>
<div id="ref-Wiener1960Some" class="csl-entry" role="listitem">
Wiener, N. (1960). Some moral and technical consequences of automation. <em>Science</em>, <em>131</em>(3410), 1355–1358.
</div>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: false,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1080,

        height: 640,

        // Factor of the display size that should remain empty around the content
        margin: 0,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script>
    // Copy over background colors to new div
    divs = document.querySelectorAll('[data-background-color]');

    Array.from(divs).map(function (x) {
      const color = x.dataset.backgroundColor;

      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-color-div");
      new_div.style.backgroundColor = color;
      x.appendChild(new_div);
      x.removeAttribute("data-background-color");
    })

    // Remove background colors from backgrounds div
    Array.from(
      document.querySelectorAll("[data-background-hash]")
    ).map(function (x) {
      x.removeAttribute("data-background-hash");
      x.style.backgroundColor = null;
    })
    </script>

    <script>
    // Copy over background images to new div
    divs = document.querySelectorAll('[data-background-image]');

    Array.from(divs).map(function (x) {
      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-image-div");

      if (x.dataset.backgroundImage != undefined) {
        new_div.style.backgroundImage = "url(" + x.dataset.backgroundImage + ")";
        x.removeAttribute("data-background-image");
      }
      if (x.dataset.backgroundSize != undefined) {
        new_div.style.backgroundSize = x.dataset.backgroundSize;
        x.removeAttribute("data-background-size");
      }
      if (x.dataset.backgroundPosition != undefined) {
        new_div.style.backgroundPosition = x.dataset.backgroundPosition;
        x.removeAttribute("data-background-position");
      }
      if (x.dataset.backgroundRepeat != undefined) {
        new_div.style.backgroundRepeat = x.dataset.backgroundRepeat;
        x.removeAttribute("data-background-repeat");
      }
      if (x.dataset.backgroundOpacity != undefined) {
        new_div.style.backgroundOpacity = x.dataset.backgroundOpacity;
        x.removeAttribute("data-background-opacity");
      }

      x.appendChild(new_div);
    })
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var video_div = document.querySelectorAll(".backgrounds video");
    var slide_div = document.querySelectorAll("[data-background-video]");

    for (let i = 0; i < video_div.length; i++) {
      video_div[i].setAttribute("class", "background-video-div");

      slide_div[i].appendChild(video_div[i]);
      slide_div[i].removeAttribute("data-background-video");
    }

    Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var video_div = document.querySelectorAll(".backgrounds video");
      var slide_div = document.querySelectorAll("[data-background-video]");

      for (let i = 0; i < video_div.length; i++) {
        video_div[i].setAttribute("class", "background-video-div");

        slide_div[i].appendChild(video_div[i]);
        slide_div[i].removeAttribute("data-background-video");
      }

      Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());
    });
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var iframe_div = document.querySelectorAll(".backgrounds iframe");
    var slide_div = document.querySelectorAll("[data-background-iframe]");

    for (let i = 0; i < iframe_div.length; i++) {
      iframe_div[i].setAttribute("class", "background-iframe-div");

      slide_div[i].appendChild(iframe_div[i]);
      slide_div[i].removeAttribute("data-background-iframe");
    }

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var iframe_div = document.querySelectorAll(".backgrounds iframe");
      var slide_div = document.querySelectorAll("[data-background-iframe]");

      for (let i = 0; i < iframe_div.length; i++) {
        iframe_div[i].setAttribute("class", "background-iframe-div");

        slide_div[i].appendChild(iframe_div[i]);
        slide_div[i].removeAttribute("data-background-iframe");
      }
    });
    </script>

    <script>
    // Clean up slide background styles
    divs = document.querySelectorAll('.slide-background-content');
    Array.from(divs).map(function (x) {
      x.style = null;
    })
    </script>

    <script>

      // Move menu button
      menu_div = document.querySelector(".slide-menu-button");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move progress bar
      menu_div = document.querySelector(".progress");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move slide number
      slide_number = document.querySelector(".slide-number");
      document.querySelector(".slides").appendChild(slide_number);
      
      // Move custom footer
      footer = document.querySelector(".footer.custom");
      document.querySelector(".slides").appendChild(footer);

    </script>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/awe-hnu\.github\.io");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>