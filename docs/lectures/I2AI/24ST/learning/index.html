<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andy Weeger">

<title>Learning ‚Äì awe.lectures</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<link href="../../../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-30d6ba78130312a1c129854e52a348e9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"interstitial",
  "consent_type":"express",
  "palette":"dark",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<meta name="robots" content="noindex">   

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Learning ‚Äì awe.lectures">
<meta property="og:description" content="üß† Introduction to AI">
<meta property="og:image" content="https://awe-hnu.github.io/lectures/I2AI/24ST/learning/images/learning-agent.svg">
<meta property="og:site_name" content="awe.lectures">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">awe ‚Äî Lecture Notes</span>
    </a>
  </div>
          <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../index.html"> 
<span class="menu-text">Start</span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Learning</h1>
            <p class="subtitle lead">üß† Introduction to AI</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Lecture Notes</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Andy Weeger </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Feb 13, 2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">May 3, 2024</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p><a href="slides.html" class="btn btn-primary" target="blank">Slides</a></p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#definition" id="toc-definition" class="nav-link active" data-scroll-target="#definition">Definition</a></li>
  <li><a href="#the-learning-agent" id="toc-the-learning-agent" class="nav-link" data-scroll-target="#the-learning-agent">The learning agent</a></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees">Decision trees</a></li>
  <li><a href="#statistical-ml" id="toc-statistical-ml" class="nav-link" data-scroll-target="#statistical-ml">Statistical ML</a></li>
  <li><a href="#deep-learning" id="toc-deep-learning" class="nav-link" data-scroll-target="#deep-learning">Deep learning</a></li>
  <li><a href="#development-process" id="toc-development-process" class="nav-link" data-scroll-target="#development-process">Development process</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">‚úèÔ∏è Exercises</a></li>
  <li><a href="#literature" id="toc-literature" class="nav-link" data-scroll-target="#literature">Literature</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-page-left" id="quarto-document-content">





<section id="definition" class="level1">
<h1>Definition</h1>
<blockquote class="blockquote">
<p>Learning agents are those that can improve their behavior through diligent study of past experiences and predictions of the future <em><span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 668</a>)</span></em></p>
</blockquote>
<p>A learning agent</p>
<div class="incremental">
<ul class="incremental">
<li>uses so-called <strong>machine learning</strong> (ML), if it is a computer;</li>
<li>improves performance based on experience (i.e., observations of the world);</li>
<li>is required when the designer lacks omniscience (i.e., in unknown environments) and/or</li>
<li>has no idea how to program a solution themselves (e.g., recognizing faces)</li>
</ul>
</div>
</section>
<section id="the-learning-agent" class="level1 vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">
<h1 class="vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">The learning agent</h1>
<div class="notes">
<p>So far an agent‚Äôs percepts have only served to help the agent choose its actions. Now they will also serve to improve future behavior.</p>
</div>
<section id="visualization" class="level2">
<h2 data-anchor-id="visualization">Visualization</h2>
<div id="fig-l-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/learning-agent.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: A learning agent based on @RusselNorvig2022AIMA [p. 74]"><img src="images/learning-agent.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A learning agent based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 74</a>)</span>
</figcaption>
</figure>
</div>
<hr>
</section>
<section id="building-blocks" class="level2">
<h2 data-anchor-id="building-blocks">Building blocks</h2>
<p><strong>Performance element:</strong> Processes percepts and chooses actions (relates to the basics of AI we have studied so far)</p>
<p><strong>Learning element:</strong> Carries out improvements. Requires awareness and feedback on how the agent is doing in the environment</p>
<p><strong>Critic:</strong> Evaluation of the agent‚Äôs behavior based on a given external behavioral measure (i.e., feedback)</p>
<p><strong>Problem generator:</strong> Suggests explorative actions that lead the agent to new experiences</p>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Performance element
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <strong>performance elements</strong> of the agent designs described in chapter <a href="../2/">Intelligent agents</a> are composed of</p>
<ul>
<li>a direct mapping from conditions to the current state of actions;</li>
<li>a means to infer relevant properties of the world from the percept sequence;</li>
<li>information about the way the world evolves and about the results of possible actions the agent can take;</li>
<li>utility information indicating the desirability of actions; and/or</li>
<li>goals that describe the most desirable states;</li>
</ul>
</div>
</div>
</div>
</section>
<section id="the-learning-element" class="level2">
<h2 data-anchor-id="the-learning-element">The learning element</h2>
<p>The design of the learning element is influenced by four important aspects:</p>
<div class="incremental">
<ul class="incremental">
<li>Which <strong>component</strong> of the performance element is to be improved?</li>
<li>What <strong>representation</strong> should be chosen (i.e., what model)?</li>
<li>What <strong>prior information</strong> is available (i.e., prior knowledge that influences the model)?</li>
<li>What form of <strong>feedback</strong> is available?</li>
</ul>
</div>
</section>
<section id="types-of-feedback" class="level2">
<h2 data-anchor-id="types-of-feedback">Types of feedback</h2>
<p>The type of feedback available for learning is usually the most important factor in determining the nature of the learning problem.</p>
<div class="incremental">
<ul class="incremental">
<li><strong>Supervised learning:</strong> Involves learning a function from examples of its inputs and outputs <em>‚ûû correct answer for each training instance</em></li>
<li><strong>Unsupervised learning:</strong> The agent has to learn patterns in the input when no specific output values are given <em>‚ûû reward sequence, no correct answers</em></li>
<li><strong>Reinforcement learning:</strong> The most general form of learning in which the agent is not told what to do by a teacher. Rather, it must learn from reinforcements (punishments or rewards). It typically involves learning how the environment works <em>‚ûû ‚Äújust make sense of the data‚Äù</em></li>
</ul>
</div>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Examples
</div>
</div>
<div class="callout-body-container callout-body">
<dl>
<dt>Supervised learning</dt>
<dd>
Image classification ‚Äî inputs can be camera images, each one accompanied by an output saying, e.g., ‚Äúbus‚Äù or ‚Äúpedestrian‚Äù. An output like this is called a <strong>label</strong>. The agents learns a function that, when given a new image, predicts the appropriate label.
</dd>
<dt>Unsupervised learning</dt>
<dd>
Clustering ‚Äî detecting potentially useful clusters of input examples. For instance, when shown millions of images, a computer vision system could identify large cluster of similar images (without ‚Äúknowing‚Äù what is shown on these).
</dd>
<dt>Reinforcement learning</dt>
<dd>
A chess agent ‚Äî imagine, it is told at the end of a game that it has won (a reward) or lost (a punishment). Based on that feedback, it has to decide which of the actions prior to the reinforcement were most responsible for it, and to alter its actions to aim towards more rewards in future.
</dd>
</dl>
</div>
</div>
</div>
</section>
<section id="why-learning-works" class="level2">
<h2 data-anchor-id="why-learning-works">Why learning works</h2>
<p>How can we be sure that our learned hypothesis will predict well for previously unseen inputs? I.e., how do we know that the hypothesis <span class="math inline">\(h\)</span> is close to the target function <span class="math inline">\(f\)</span> when <span class="math inline">\(f\)</span> is unknown?</p>
<p>The underlying principle of <strong>computational learning theory</strong> is, that any hypothesis that is seriously wrong will almost certainly be ‚Äúfound out‚Äù with high probability after a small number of examples</p>
<p>Thus, any hypothesis that is consistent with a sufficiently large set of training examples is unlikely to be seriously wrong: that is, it must be <strong>probably approximately correct</strong> (PAC)</p>
</section>
<section id="inductive-learning" class="level2">
<h2 data-anchor-id="inductive-learning">Inductive learning</h2>
<p>The task of learning is to find good hypotheses about the world.</p>
<div class="incremental">
<ul class="incremental">
<li>An <strong>example</strong> is a pair <span class="math inline">\((x, f(x))\)</span> (input and output)</li>
<li>The complete set of examples is called the <strong>training set</strong> (supervised learning)</li>
<li><strong>Pure inductive inference:</strong> for a collection of examples for <span class="math inline">\(f\)</span> (the <strong>target function</strong>), return a function <span class="math inline">\(h\)</span> (hypothesis) that approximates <span class="math inline">\(f\)</span></li>
<li>The function h typically is member of a <strong>hypothesis space</strong> <span class="math inline">\(H\)</span></li>
<li>A good hypothesis should <strong>generalize the data</strong> well (i. e., will <strong>predict</strong> unseen examples correctly)</li>
<li>A hypothesis is <strong>consistent</strong> with the data set if it agrees with all the data</li>
</ul>
</div>
<p>How do we choose from among multiple consistent hypotheses?</p>
<p><strong>Ockham‚Äôs razor:</strong> prefer the simplest hypothesis that matches the data</p>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ockham‚Äôs razor
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ockham‚Äôs razor is a choice between more complex, low-bias hypotheses that fit the training data well and simple, low-variance hypotheses that may generalize better. Wililiam of Ockham stated in the first century the principle that ‚Äúplurality [of entities] should not be posited without necessity ‚Äî the so-called Ockham‚Äôs razor that‚Äùshaves off‚Äù dubious explanations.</p>
</div>
</div>
</div>
<hr>
<section id="example-curve-fitting" class="level3">
<h3 data-anchor-id="example-curve-fitting">Example: curve-fitting</h3>
<div id="fig-fitting" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fitting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/curve-fitting.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Finding hypotheses to fit data"><img src="images/curve-fitting.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fitting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Finding hypotheses to fit data
</figcaption>
</figure>
</div>
<p>For plots of best-fit functions (<em>h</em>) from four different hypothesis spaces (<em>H</em>) trained on a data set (a = linear; b = degree-7 polynomial, c = degree-6 polynomial, d = sinusoidal)</p>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Underfitting and overfitting [<span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022</a>)</span>; p.&nbsp;673]
</div>
</div>
<div class="callout-body-container callout-body">
<p>A hypothesis is <strong>underfitting</strong> when it fails to find a pattern in the data (i.e., the model has not learned enough from the data). In turn, a hypothesis is <strong>overfitting</strong> the data when it pays too much attention to the particular data set it is trained on, causing it to perform poorly on unseen data (i.e., the generalization of the model is unreliable).</p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="decision-trees" class="level1 vertical-center headline-only page-columns page-full" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">
<h1 class="vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">Decision trees</h1>
<section id="learning-decision-trees" class="level2">
<h2 data-anchor-id="learning-decision-trees">Learning decision trees</h2>
<p>A <strong>decision tree</strong> is a representation of a function that maps a vector of attribute values to a single output value‚Äîa ‚Äúdecision‚Äù.</p>
<p><strong>Search</strong> is used to find a decision (i.e., performing a sequence of tests).</p>
<p>In <strong>Boolean decision trees</strong>, the input is a set of vector of input attributes <em>X</em> and a single Boolean output value <em>y</em></p>
<p><strong>Learning process</strong>: Definition of the goal predicate in the form of a decision tree.</p>
<div class="incremental">
<ul class="incremental">
<li>An internal node of the decision tree represents a test of a property</li>
<li>Branches are labeled with the possible values of the test</li>
<li>Each leaf node specifies the Boolean value to be returned if that leaf is reached</li>
</ul>
</div>
</section>
<section id="expressiveness" class="level2">
<h2 data-anchor-id="expressiveness">Expressiveness</h2>
<p>A Boolean decision tree is equivalent to a logical statement of the form</p>
<p><span class="math display">\[
\begin{flalign}
Output \iff (Path_1 \lor Path_2 \lor ...)
\end{flalign}
\]</span></p>
<p>where each <span class="math inline">\(Path_i\)</span> is a <strong>conjunction</strong> of the form <span class="math inline">\((A_m = v_x \; \land \; A_n = v_y \; \land \; ...)\)</span> of <strong>attribute-value tests</strong> corresponding to a path from the root to a <span class="math inline">\(true\)</span> leaf.</p>
<p>Any function in propositional logic can be represented by a decision tree by translating every row of a truth table to a path in the tree.</p>
<p>This can lead to a tree whose size is <strong>exponential</strong> in the number of attributes.</p>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Digression: hypothesis spaces
</div>
</div>
<div class="callout-body-container callout-body">
<p>How many distinct decision trees with <span class="math inline">\(n\)</span> Boolean attributes?<br>
= number of Boolean functions<br>
= number of distinct truth tables with <span class="math inline">\(2^n\)</span> rows = <span class="math inline">\(2^{2^n}\)</span></p>
<p>E.g., with 6 Boolean attributes, there are 18,446,744,073,709,551,616 trees</p>
<p>How many purely conjunctive hypotheses (e.g., <span class="math inline">\(Hungry \land \neg Rain\)</span>)?</p>
<p>Each attribute can be in (positive), in (negative), or out (i.e., not part of the sentence):<br>
<span class="math inline">\(3^n\)</span> distinct conjunctive hypotheses</p>
</div>
</div>
</div>
</section>
<section id="limitations" class="level2">
<h2 data-anchor-id="limitations">Limitations</h2>
<p>Although decision trees can represent functions with smaller trees, there are functions that require an exponentially large decision tree, e.g.</p>
<div class="incremental">
<ul class="incremental">
<li><strong>Majority function</strong>, which returns true if more than half of the inputs are true</li>
<li><strong>Parity function</strong>, which returns true if and only if an even number of inputs are true</li>
<li><span class="math inline">\(y &gt; A_1 + A_2\)</span> with real-valued attributes <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
</div>
<p>Summary: decision trees are good for some kinds of functions and bad for others.</p>
</section>
<section id="example-problem" class="level2 page-columns page-full">
<h2 data-anchor-id="example-problem">Example problem</h2>
<p>Supervised learning problem of deciding whether to wait for a table at a restaurant <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 668</a>)</span></p>
<p>The output (<em>y</em>) is a Boolean variable <strong>WillWait</strong></p>
<p>The input (<em>x</em>) is a vector of ten attributes values (discrete values):</p>
<div class="smaller">
<div class="incremental">
<ul class="incremental">
<li><strong>Alternate</strong> ‚Äì Is there an alternative? (T/F)</li>
<li><strong>Bar</strong> ‚Äì Does the restaurant have a bar to wait in? (T/F)</li>
<li><strong>Fri</strong> ‚Äì Is it Friday or Saturday? (T/F)</li>
<li><strong>Hungry</strong> ‚Äì Am I hungry? (T/F)</li>
<li><strong>Patrons</strong> ‚Äì How many guests are there? (none, some, full)</li>
<li><strong>Price</strong> ‚Äì How expensive is the food? (‚Ç¨, ‚Ç¨‚Ç¨, ‚Ç¨‚Ç¨‚Ç¨)</li>
<li><strong>WaitEstimate</strong> ‚Äì How long do we have to wait? (0-10, 10-30, 30-60, &gt;60)</li>
<li><strong>Reservation</strong> ‚Äì Have I made a reservation? (T/F)</li>
<li><strong>Raining</strong> ‚Äì Is it raining outside? (T/F)</li>
<li><strong>Type</strong> ‚Äì What kind of restaurant is it? (French, Italian, Thai, Burger)</li>
</ul>
</div>
</div>
<hr>
<section id="example-decision-tree" class="level3">
<h3 data-anchor-id="example-decision-tree">Example decision tree</h3>
<div id="fig-tree" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/decision-tree.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Decision tree restaurant example based on @RusselNorvig2022AIMA [p. 674]"><img src="images/decision-tree.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Decision tree restaurant example based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 674</a>)</span>
</figcaption>
</figure>
</div>
<hr>
</section>
<section id="underlying-training-set" class="level3 page-columns page-full">
<h3 data-anchor-id="underlying-training-set">Underlying training set</h3>
<div class="column-page-inset-right">
<div class="smaller">
<div id="tbl-res-ts" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-res-ts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 8%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 7%">
<col style="width: 6%">
<col style="width: 9%">
<col style="width: 10%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Example</th>
<th style="text-align: center;">Alt</th>
<th style="text-align: center;">Bar</th>
<th style="text-align: center;">Fri</th>
<th style="text-align: center;">Hun</th>
<th style="text-align: center;">Pat</th>
<th style="text-align: center;">Price</th>
<th style="text-align: center;">Rain</th>
<th style="text-align: center;">Res</th>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Est</th>
<th style="text-align: left;">WillWait</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_1\)</span></td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Some</td>
<td style="text-align: center;">‚Ç¨‚Ç¨‚Ç¨</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">French</td>
<td style="text-align: center;">0-10</td>
<td style="text-align: left;"><span class="math inline">\(y_1 =\)</span> Yes</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_2\)</span></td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">‚Ç¨</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Thai</td>
<td style="text-align: center;">30-60</td>
<td style="text-align: left;"><span class="math inline">\(y_2 =\)</span> No</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_3\)</span></td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Some</td>
<td style="text-align: center;">‚Ç¨</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Burger</td>
<td style="text-align: center;">0-10</td>
<td style="text-align: left;"><span class="math inline">\(y_3 =\)</span> Yes</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_4\)</span></td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">‚Ç¨</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Thai</td>
<td style="text-align: center;">10-30</td>
<td style="text-align: left;"><span class="math inline">\(y_4 =\)</span> Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_5\)</span></td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">‚Ç¨‚Ç¨‚Ç¨</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">French</td>
<td style="text-align: center;">&gt;60</td>
<td style="text-align: left;"><span class="math inline">\(y_5 =\)</span> No</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_6\)</span></td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Some</td>
<td style="text-align: center;">‚Ç¨‚Ç¨</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Italian</td>
<td style="text-align: center;">0-10</td>
<td style="text-align: left;"><span class="math inline">\(y_6 =\)</span> Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_7\)</span></td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">None</td>
<td style="text-align: center;">‚Ç¨</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Burger</td>
<td style="text-align: center;">0-10</td>
<td style="text-align: left;"><span class="math inline">\(y_7 =\)</span> No</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_8\)</span></td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Some</td>
<td style="text-align: center;">‚Ç¨‚Ç¨</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Thai</td>
<td style="text-align: center;">0-10</td>
<td style="text-align: left;"><span class="math inline">\(y_8 =\)</span> Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_9\)</span></td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">‚Ç¨</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Burger</td>
<td style="text-align: center;">&gt;60</td>
<td style="text-align: left;"><span class="math inline">\(y_9 =\)</span> No</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_{10}\)</span></td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">‚Ç¨‚Ç¨‚Ç¨</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Italian</td>
<td style="text-align: center;">10-30</td>
<td style="text-align: left;"><span class="math inline">\(y_{10}=\)</span> No</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_{11}\)</span></td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">None</td>
<td style="text-align: center;">‚Ç¨</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Thai</td>
<td style="text-align: center;">0-10</td>
<td style="text-align: left;"><span class="math inline">\(y_{11} =\)</span> No</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_{12}\)</span></td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">‚Ç¨</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Burger</td>
<td style="text-align: center;">30-60</td>
<td style="text-align: left;"><span class="math inline">\(y_{12} =\)</span> Yes</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-res-ts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Examples for the restaurant domain
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="inducing-decision-trees-from-examples" class="level2">
<h2 data-anchor-id="inducing-decision-trees-from-examples">Inducing decision trees from examples</h2>
<p>To get a <strong>naive solution</strong>, we simply construct a tree with one path to a leaf for each example.</p>
<div class="incremental">
<ul class="incremental">
<li>We test all the attributes along the path and attach the classification of the example to the leaf</li>
<li>Whereas the resulting tree will correctly classify all given examples, it will not say much about other cases</li>
<li>It just memorizes the observations and <strong>does not generalize</strong></li>
</ul>
</div>
<p>How to find a tree that is <strong>consistent with the training set</strong> (<a href="#tbl-res-ts" class="quarto-xref">Table&nbsp;1</a>), yet <strong>as small as possible</strong>?</p>
<div class="incremental">
<ul class="incremental">
<li>It is <strong>intractable</strong> to find a guaranteed smallest consistent tree.</li>
<li>However, with some simple heuristics, we can efficiently find one that is <strong>close to the smallest</strong> (i.e., ‚Äúsmallish‚Äù tree).</li>
<li><strong>Decision tree learning</strong> adopts a greedy divide-and-conquer strategy.</li>
</ul>
</div>
</section>
<section id="divide-and-conquer-strategy" class="level2">
<h2 data-anchor-id="divide-and-conquer-strategy">Divide-and-conquer strategy</h2>
<p>Always use the <strong>most important attribute</strong> first, then recursively solve the smaller subproblems</p>
<div class="incremental">
<ul class="incremental">
<li>The ‚Äúmost important attribute‚Äù is the one that makes the most difference<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></li>
<li>Split the training set into subsets each corresponding to a particular value of that attribute</li>
<li>Now that we have divided the training set into several smaller training sets, we can recursively apply this process to the smaller training sets</li>
</ul>
</div>
<p>That way, we hope to get to the <strong>correct classification</strong> with a <strong>small number of tests</strong><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<hr>
<section id="recursive-learning-process" class="level3">
<h3 data-anchor-id="recursive-learning-process">Recursive learning process</h3>
<p>In each recursive step there are four cases to consider:</p>
<div class="incremental">
<ul class="incremental">
<li>Positive and negative examples: choose a <strong>new attribute</strong></li>
<li><strong>Common outcome</strong> (only positive or only negative examples): done (answer is <em>Yes</em> or <em>No</em>).</li>
<li><strong>No examples:</strong> there was no example with the desired property. Answer <em>Yes</em> if the majority of the parent node‚Äôs examples is positive, otherwise <em>No</em>.</li>
<li><strong>No attributes left</strong>, but there are still examples with different classifications: there were errors in the data (i.e., noise) or the attributes do not give sufficient information. Answer <em>Yes</em> if the majority of examples is positive, otherwise <em>No</em>.</li>
</ul>
</div>
<hr>
</section>
</section>
<section id="resulting-tree" class="level2">
<h2 data-anchor-id="resulting-tree">Resulting tree</h2>
<p>Properties of the learning outcome:</p>
<div class="incremental">
<ul class="incremental">
<li>The resulting tree is <strong>considerably simpler</strong> than the one originally given (and from which the training examples were generated)</li>
<li>The learning algorithm outputs a tree that is <strong>consistent</strong> with all examples it has seen</li>
<li>The tree does not need to agree with the correct function, e.g.&nbsp;it suggests not to wait if we are not hungry. If we are, there are cases in which it tells us to wait.</li>
<li>Some tests (<em>Raining</em>, <em>Reservation</em>) are not included since the algorithm can classify the examples without them</li>
</ul>
</div>
<hr>
</section>
<section id="performance-assessment" class="level2">
<h2 data-anchor-id="performance-assessment">Performance assessment</h2>
<p>To assess the power of the prediction, the following method can be applied:</p>
<div class="incremental">
<ul class="incremental">
<li>Collect a large number of examples</li>
<li>Divide it into two disjoint sets: the <strong>training set</strong> and the <strong>test set</strong></li>
<li>Use the training set to generate <span class="math inline">\(h\)</span></li>
<li>Measure the percentage of examples of the test set that are correctly classified by <span class="math inline">\(h\)</span></li>
<li>Repeat the process for randomly-selected training sets of different sizes</li>
</ul>
</div>
<p>As the training set grows, the prediction quality increases</p>
</section>
<section id="generalization" class="level2">
<h2 data-anchor-id="generalization">Generalization</h2>
<p>Pruning reduces the size of decision trees by removing sections of the tree that are non-critical and redundant to classify instances.</p>
<div class="incremental">
<ul class="incremental">
<li>Pruning reduces the complexity of the final hypothesis (tree size) and reduces overfitting<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></li>
<li>Predictive accuracy as measured by a cross-validation set<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></li>
<li>One of the simplest forms of pruning is <strong>reduced error pruning</strong>:
<ul class="incremental">
<li>For each leave, each node is replaced with its most popular output</li>
<li>If the prediction accuracy is not affected then the change is kept</li>
<li>It is somewhat naive, but simple and speedy</li>
</ul></li>
</ul>
</div>
</section>
<section id="summary" class="level2">
<h2 data-anchor-id="summary">Summary</h2>
<div class="incremental">
<ul class="incremental">
<li>Decision trees are one possibility for <strong>representing (Boolean) functions</strong></li>
<li>They <strong>can be exponential</strong> in the number of attributes</li>
<li>It is often too difficult to find the minimal decision tree</li>
<li>One method for generating decision trees that are as flat as possible is based on ranking the attributes</li>
<li>The ranks are computed based on the information gain</li>
</ul>
</div>
</section>
</section>
<section id="statistical-ml" class="level1 vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">
<h1 class="vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">Statistical ML</h1>
<section id="motivation" class="level2">
<h2 data-anchor-id="motivation">Motivation</h2>
<p>As discussed in <a href="../6/">chapter probability</a>, <strong>probability and utility theory</strong> allow agents to deal with uncertainty</p>
<p>To apply probabilistic reasoning, however, the agents must first learn their probabilistic theories of the world from experience</p>
<p>We will discuss statistical learning methods as robust ways to <strong>learn probabilistic models</strong></p>
</section>
<section id="bayesian-learning" class="level2">
<h2 data-anchor-id="bayesian-learning">Bayesian learning</h2>
<p>Learning can be viewed as <strong>Bayesian updating</strong> of a probability distribution over the hypothesis space</p>
<p><span class="math inline">\(H\)</span> is the hypothesis variable, values <span class="math inline">\(h_1, h_2, . . .\)</span>, prior <span class="math inline">\(P(H)\)</span></p>
<p><span class="math inline">\(j\)</span>th observation of <span class="math inline">\(d_j\)</span> gives the outcome of random variable <span class="math inline">\(D_j\)</span><br>
training data <span class="math inline">\(d = d_1,..., d_N\)</span></p>
<p>Given the data so far, each hypothesis has a posterior probability:</p>
<p><span class="math display">\[
\begin{flalign}
P(h_i|d) = \alpha P(d|h_i)P(h_i)
\end{flalign}
\]</span></p>
<p>where <span class="math inline">\(P(d|h_i)\)</span> is called the <strong>likelihood</strong></p>
<p>Predictions use a <strong>likelihood-weighted average</strong> over the hypotheses:</p>
<p><span class="math display">\[
\begin{flalign}
P(H|d) = \sum_i{P(H|d,h_i)P(h_i|d)} = \sum_i{P(H|h_i)P(h_i|d)}
\end{flalign}
\]</span></p>
</section>
<section id="example" class="level2">
<h2 data-anchor-id="example">Example</h2>
<p>Suppose there are five kinds of bags of candies:</p>
<div class="incremental">
<ul class="incremental">
<li>10% are <span class="math inline">\(h_1\)</span> : 100% <em>cherry</em> candies</li>
<li>20% are <span class="math inline">\(h_2\)</span> : 75% <em>cherry</em> and 25% <em>lime</em> candies</li>
<li>40% are <span class="math inline">\(h_3\)</span> : 50% <em>cherry</em> and 50% <em>lime</em> candies</li>
<li>20% are <span class="math inline">\(h_4\)</span> : 25% <em>cherry</em> and 75% <em>lime</em> candies</li>
<li>10% are <span class="math inline">\(h_5\)</span> : 100% <em>lime</em> candies</li>
</ul>
</div>
<p>Then we draw 5 candies from some bag (<span class="math inline">\(d_1,...,d_10\)</span>), which are all <em>lime</em> candies.</p>
<p>What kind of bag is it?<br>
What flavor will the next candy be?</p>
<hr>
<section id="posterior-probability-of-hypotheses" class="level3">
<h3 data-anchor-id="posterior-probability-of-hypotheses">Posterior probability of hypotheses</h3>
<p><span class="math inline">\(P(h_k|d) = Œ±P(d|h_k)P(h_k)\)</span></p>
<p><span class="math inline">\(P(h1 | 5\;limes) = Œ±P(5\;limes | h1)P(h1) = \alpha ¬∑ 0.0^5 ¬∑ 0.1 = 0\)</span> <span class="math inline">\(P(h2 | 5\;limes) = Œ±P(5\;limes | h2)P(h2) = \alpha ¬∑ 0.25^5¬∑ 0.2 = 0.000195Œ±\)</span> <span class="math inline">\(P(h3 | 5\;limes) = Œ±P(5\;limes | h3)P(h3) = \alpha ¬∑ 0.5^5 ¬∑ 0.4 = 0.0125Œ±\)</span> <span class="math inline">\(P(h4 | 5\;limes) = Œ±P(5\;limes | h4)P(h4) = \alpha ¬∑ 0.75^5 ¬∑ 0.2 = 0.0475Œ±\)</span> <span class="math inline">\(P(h5 | 5\;limes) = Œ±P(5\;limes | h5)P(h5) = \alpha ¬∑ 1.0^5 ¬∑ 0.1 = 0.1Œ±\)</span></p>
<p><span class="math inline">\(\alpha = 1/(0 + 0.000195 + 0.0125 + 0.0475 + 0.1) = 6.2424\)</span></p>
<p><span class="math inline">\(P(h_1 | 5\;limes) = 0\)</span><br>
<span class="math inline">\(P(h_2 | 5\;limes) = 0.00122\)</span><br>
<span class="math inline">\(P(h_3 | 5\;limes) = 0.07803\)</span><br>
<span class="math inline">\(P(h_4 | 5\;limes) = 0.29650\)</span><br>
<span class="math inline">\(P(h_5 | 5\;limes) = 0.62424\)</span></p>
<hr>
</section>
<section id="evolution-of-the-five-hypotheses" class="level3">
<h3 data-anchor-id="evolution-of-the-five-hypotheses">Evolution of the five hypotheses</h3>
<p>The posterior probabilties change the more evidence we gain.</p>
<div id="fig-eprob" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-eprob-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/example-probs.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Posterior probability of candy-hypotheses"><img src="images/example-probs.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eprob-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Posterior probability of candy-hypotheses
</figcaption>
</figure>
</div>
<hr>
</section>
<section id="prediction-probability" class="level3">
<h3 data-anchor-id="prediction-probability">Prediction probability</h3>
<p>Let‚Äôs calculate the probabilit that we draw a lime on our 6th attempt given the data we have (types of bags and observations made).</p>
<p><span class="math display">\[
\begin{flalign}
P(d_{j+1}|d) = \sum_k{P(d_{j+1}|d,h_k)P(h_k|X)} = \sum_k{P(d_{j+1}|h_k)P(h_k|d)}
\end{flalign}
\]</span> <span class="math display">\[
\begin{align}
P(lime \; on \; 6 | 5 \; limes) &amp; = P(lime \; on \; 6 | h1)P(h1 | 5 \; limes) \\
&amp; + P(lime \; on \; 6 | h2)P(h2 | 5 \; limes) \\
&amp; + P(lime \; on \; 6 | h3)P(h3 | 5 \; limes) \\
&amp; + P(lime \; on \; 6 | h4)P(h4 | 5 \; limes) \\
&amp; + P(lime \; on \; 6 | h5)P(h5 | 5 \; limes) \\
&amp; = 0 √ó 0 \\
&amp; + 0.25 √ó 0.00122 \\
&amp; + 0.5 √ó 0.07830 \\
&amp; + 0.75 √ó 0.29650 \\
&amp; + 1.0 √ó 0.62424 \\
&amp; = 0.88607 \\
\end{align}
\]</span></p>
<hr>
</section>
<section id="likelihood-weighted-average" class="level3">
<h3 data-anchor-id="likelihood-weighted-average">Likelihood-weighted average</h3>
<div id="fig-ep-prob" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ep-prob-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/example-p-prob.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Probability that next candy is lime given d"><img src="images/example-p-prob.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ep-prob-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Probability that next candy is lime given <strong>d</strong>
</figcaption>
</figure>
</div>
</section>
</section>
<section id="observations" class="level2">
<h2 data-anchor-id="observations">Observations</h2>
<p>The Bayesian prediction <strong>eventually agrees with the true hypothesis</strong></p>
<div class="incremental">
<ul class="incremental">
<li>For any fixed prior that does not rule out the true hypothesis, the posterior of any false hypothesis will eventually vanish</li>
<li>The Bayesian prediction is <strong>optimal</strong> and, given the hypothesis prior, any other prediction will be correct less often</li>
</ul>
</div>
<p>However, summing over the hypothesis space is often intractable</p>
<p>‚ûû Real problems require us to resort to <strong>approximate or simplified methods</strong></p>
</section>
<section id="map-learning" class="level2">
<h2 data-anchor-id="map-learning">MAP learning</h2>
<p>Summing over the hypothesis space is often intractable (e.g., 18,446,744,073,709,551,616 Boolean functions of 6 attributes).</p>
<p>A common approximation is to make predictions based on a <strong>single most probable hypothesis</strong>.</p>
<p><strong>Maximum a posteriori</strong> (MAP)<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> learning: choose <span class="math inline">\(h_{MAP}\)</span> maximizing <span class="math inline">\(P(h_i|d)\)</span><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>For large data sets, prior becomes irrelevant.</p>
<p><strong>Maximum likelihood (ML) learning</strong><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> means, thus, to choose <span class="math inline">\(h_{ML}\)</span> maximizing <span class="math inline">\(P(d|h_i)\)</span>.</p>
<p><span class="math display">\[
\begin{flalign}
P(h_i|d) = \frac{P(d|h_i)P(h_i)}{P(d)} \approx P(d|h_i)P(h_i) \approx P(d|h_{MAP})
\end{flalign}
\]</span></p>
<p>We don‚Äôt need to directly calculate <span class="math inline">\(P(d)\)</span> (i.e., the evidence term) for finding the MAP estimate as <span class="math inline">\(P(d)\)</span> acts like a constant and does not affect which value maximizes the posterior probability.</p>
<hr>
<p>MAP learning aims to find the value that maximizes the product of likelihood (<span class="math inline">\(P(d|h_i)\)</span>) and prior probability (<span class="math inline">\(P(h_i)\)</span>).</p>
<p>As more data arrive, MAP and Bayesian predictions become closer</p>
<p>‚ûû Finding MAP hypotheses is often much easier than Bayesian learning<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>Usually specialized machine learning algorithms handle the complex calculations behind finding the MAP estimate.</p>
<div class="notes">
<p><strong>Candy example</strong></p>
<ul>
<li>In the candy example, <span class="math inline">\(h_{MAP}=h5\)</span> after three lime candies in a row</li>
<li>The <strong>MAP learner</strong> the predicts that the fourth candy is lime with probability 1.0, whereas the Bayesian prediction is still 0.8</li>
</ul>
</div>
</section>
<section id="summary-1" class="level2">
<h2 data-anchor-id="summary-1">Summary</h2>
<div class="incremental">
<ul class="incremental">
<li>Bayesian learning techniques formulate learning as a form of <strong>probabilistic inference</strong></li>
<li><strong>Full Bayesian learning</strong> gives best possible predictions but is intractable</li>
<li><strong>Maximum a posterior</strong> learning selects the most likely hypothesis given the data (balancing complexity with accuracy on training data)</li>
<li><strong>Maximum likelihood</strong> assumes uniform prior, OK for large data sets</li>
</ul>
</div>
</section>
</section>
<section id="deep-learning" class="level1 vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">
<h1 class="vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">Deep learning</h1>
<section id="introduction" class="level2">
<h2 data-anchor-id="introduction">Introduction</h2>
<p>Conventional machine-learning techniques as those discussed above are limited in their ability to process <strong>natural data in their raw form</strong>.</p>
<p>Careful engineering and considerable domain expertise are required to transform the raw data into a <strong>suitable internal representation</strong> from which the learning system could detect or classify patterns in some input.</p>
<p>In <strong>representation learning</strong> the system uses methods to automatically discover the representations needed for detection or classification.</p>
<p><strong>Deep-learning methods</strong> creates multiple levels of representation by transforming the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level.</p>
<p>With the composition of enough such transformations, very complex functions can be learned.</p>
</section>
<section id="representations" class="level2">
<h2 data-anchor-id="representations">Representations</h2>
<p>The key aspect of deep learning is that the levels of representations (i.e., layers of features) <strong>are not designed by human engineers</strong>: they are learned from data using a <strong>general-purpose learning procedure</strong>.</p>
<p>Example: object detection in images</p>
<div class="incremental">
<ul class="incremental">
<li>An image comes in the form of an array of pixel values (raw input; input layer)</li>
<li>The first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image (hidden layer 1)</li>
<li>The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions (hidden layer 2)</li>
<li>The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects (hidden layer 3)</li>
<li>Subsequent layers would detect objects as combinations of the parts of familiar objects</li>
</ul>
</div>
<hr>
<section id="visualization-1" class="level3">
<h3 data-anchor-id="visualization-1">Visualization</h3>
<div id="fig-deep-nn" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-deep-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/deep-nn.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: Illustration of a deep neural network consisting of multiple representation layers"><img src="images/deep-nn.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-deep-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Illustration of a deep neural network consisting of multiple representation layers
</figcaption>
</figure>
</div>
</section>
</section>
<section id="application" class="level2">
<h2 data-anchor-id="application">Application</h2>
<p>Deep learning methods can <strong>discover intricate structures in high-dimensional data</strong>.</p>
<p>Using this capability, deep learning is making major advances in solving problems that could not have been solved before (<span class="citation" data-cites="lecun2015deep">LeCun, Bengio, and Hinton (<a href="#ref-lecun2015deep" role="doc-biblioref">2015</a>)</span>), e.g.,</p>
<div class="incremental">
<ul class="incremental">
<li>image and speech recognition,</li>
<li>analysing particle accelerator data,</li>
<li>reconstructing brain circuits,</li>
<li>predicting the effects of DNA mutations on gene expression and disease</li>
<li>natural language understanding (e.g., topic classification, sentiment analysis, question answering and language translation)</li>
</ul>
</div>
</section>
<section id="convolutional-neural-networks" class="level2">
<h2 data-anchor-id="convolutional-neural-networks">Convolutional neural networks</h2>
<p>A <strong><em>convolutional neural network (ConvNet)</em></strong> is a specific kind of neural network with multiple layers,designed to process data that come in the form of multiple arrays<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>The role of the ConvNet is to <strong>reduce the arrays</strong> into a form which is easier to process, without losing features which are critical for getting a good prediction.</p>
<p>A ConvNet is structured as a series of stages, which are composed of two types of layers: <strong>convolutional layers</strong> and <strong>pooling layers</strong>.</p>
<div class="incremental">
<ul class="incremental">
<li>The <strong>convolution layer</strong>: extraction of the high-level features from the input (by applying convolutional operations/filters)</li>
<li>The <strong>pooling layer</strong>: reduction of the spatial size of the convoled feature to decrease the computational power required to process the data through dimensionality reduction.</li>
</ul>
</div>
<p>Good read: <a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">A Comprehensive Guide to Convolutional Neural Networks ‚Äî the ELI5 way</a></p>
</section>
</section>
<section id="development-process" class="level1 vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">
<h1 class="vertical-center headline-only" data-background-color="#564ac6" data-background-image="../assets/bg.jpeg">Development process</h1>
<section id="overview" class="level2">
<h2 data-anchor-id="overview">Overview</h2>
<p>We are still in the early stages of defining a methodology for machine learning projects; the tools and processes are not as well developed as in software engineering</p>
<p><span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 722ff</a>)</span> propose a process that involves following typical steps</p>
<div class="incremental">
<ul class="incremental">
<li>Problem formulation</li>
<li>Data collection, assessment, and management</li>
<li>Model selection and training</li>
<li>Checking trustworthiness of the system</li>
<li>Operation, monitoring, and maintenance</li>
</ul>
</div>
</section>
<section id="problem" class="level2">
<h2 data-anchor-id="problem">Problem</h2>
<p>Figuring out what problem you want to solve compromises three parts:</p>
<div class="incremental">
<ol class="incremental" type="1">
<li><strong>Problem:</strong> What problem do I solve for my users?<br>
‚ûû Find an objective that you can track and that relates to your ‚Äútrue goals‚Äù</li>
<li><strong>Suitability:</strong> What parts of the problem(s) can be solved by ML?<br>
‚ûû Often not all parts of the problem require ML</li>
<li><strong>Approach:</strong> What kind of learning is appropriate?<br>
‚ûû Often a <em>semi-supervised learning approach</em> is suitable (few labeled examples, large collection of unlabeled examples)</li>
</ol>
</div>
</section>
<section id="data" class="level2">
<h2 data-anchor-id="data">Data</h2>
<blockquote class="blockquote">
<p>Real data are messy</p>
</blockquote>
<p>ML needs data, <strong>a lot of data</strong>, of which at least a subset is labeled</p>
<p>Manufacturing these data can be done by <strong>own labor</strong> or by <strong>crowdsourcing</strong> (paid, volunteers, users); one might also start with <strong>publicly available general-purpose dataset</strong> (or a model that has been pretrained) and then add specific data</p>
<p>Maintain a <strong>data provenance</strong> for all data (i.e., for each columns of your data set, you should know the exact definition, where the data come from, what the possible values are, and who has worked on it)</p>
<p>When data are limited, <strong>data augmentation</strong> can help (i.e., creating multiple versions of each image by rotating, translating, cropping, or scaling each image, or by changing brightness or color balancing or adding noise)</p>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Helpful questions
</div>
</div>
<div class="callout-body-container callout-body">
<p>Questions to be asked are - Is this the right data for my task? - Does it capture enough of the right inputs to give us a chance of learning a model? - Does it contain the outputs I want to predict? - If not, can I build an unsupervised model? - Or can I label a portion of the data and then do semi-supervised learning? - Is it relevant data? - How much data do I need? Recommendation: draw a learning curve to see if more data will help. - Could there be data entry errors? - What to be done with missing data fields? - Are there spelling errors or inconsistent terminology in text data? - Are there outliers in the data?</p>
</div>
</div>
</div>
<hr>
<section id="feature-engineering" class="level3">
<h3 data-anchor-id="feature-engineering">Feature engineering</h3>
<p>After correcting overt errors, the data should be preprocessed so that they can be handled more easily</p>
<div class="incremental">
<ul class="incremental">
<li><strong>Quantization:</strong> forcing a continuous valued input into fixed bins (e.g., waiting time in 0-10, 10-30, 30-60, or &gt;60 minutes)</li>
<li><strong>Normalization data:</strong> transforming data so that it has a standard deviation of 1</li>
<li><strong>Separating categorical attributes:</strong> transform the data into separate Boolean attributes, where exactly one of it is true</li>
</ul>
</div>
<hr>
</section>
</section>
<section id="model" class="level2">
<h2 data-anchor-id="model">Model</h2>
<p>Before starting with building a model, you might start with getting an <strong>intuitive feel for the data</strong> (e.g., by means of exploratory data analysis)</p>
<p>There is no guaranteed way to pick the <strong>best model class</strong>, but there are some rough guidelines:</p>
<div class="incremental">
<ul class="incremental">
<li><strong>Random forests</strong> are good then there are a lot of categorical features, where many of these may be irrelevant</li>
<li><strong>Nonparametric methods</strong> are good when having a lot of data and no prior model</li>
<li><strong>Logistic regression</strong> does well when the data are linearly separable (or can be converted to be so)</li>
</ul>
</div>
<p>Do what worked well in similar past problems‚Äîand search: run experiments with multiple possible models</p>
</section>
<section id="trustworthiness" class="level2">
<h2 data-anchor-id="trustworthiness">Trustworthiness</h2>
<p>Doing well with test data is a necessary but not sufficient condition for <strong>trust</strong> in the model (by you and your stakeholders), it also requires</p>
<div class="incremental">
<ul class="incremental">
<li><strong>Verification and validation:</strong> you test on the training, validation, and datasets, do code reviews, monitoring, and set measures for accountability<br>
‚ûû Do the best to ensure that the system will not be wrong and, for the case, set responsibilities</li>
<li><strong>Interpretability:</strong> you understand how answers relate to inputs ‚ûû Do the best to inspect and interpret your model</li>
<li><strong>Explainability:</strong> the model helps you to understand why a certain output has been produced for a given input ‚ûû Do the best to explain what your model does<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></li>
</ul>
</div>
</section>
<section id="operation" class="level2">
<h2 data-anchor-id="operation">Operation</h2>
<p>After the model is deployed to the users, additional challenges will arise</p>
<div class="incremental">
<ul class="incremental">
<li><strong>Long tail of user inputs:</strong> you might see inputs that were never tested before and you need to know whether your model generalizes well for them (i.e., you need to monitor the performance)</li>
<li><strong>Nonstationarity:</strong> the world changes over time (e.g., spammers adapt their tactics); you need to consider how often to adapt the model (i.e., find a tradeoff between a well tested model and a model that is built from the latest data)</li>
</ul>
</div>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
A set of criteria to see how well you are doing at deploying ML models
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Tests for features and data</strong> (1) Feature expectations are captured in a schema. (2) AU feature. are beneficial. (3) No feature‚Äôs cost is too much. ( 4) Features adhere to meta-level requirements. (5) The data pipeline has appropriate privacy controls. (6) New features can be added quickly. (7) All input feature code is tested.</p>
<p><strong>Tests for model development</strong> (1) Every model specification undergoes a code review. (2) Every model is checked in to a repository. (3) Offline proxy metrics correlate with actual metrics (4) All hyperparameters have been tuned. (5) The impact of model staleness is known. (6) A simpler model is not better. (7) Model quality is sufficient on all important data slices. The model has been tested for considerations of inclusion.</p>
<p><strong>Tests for ML infrastructure</strong> (1) Training is reproducible. (2) Model specification code is unit tested. (3) The full ML pipeline is integration tested. (4) Model quality is validated before attempting to serve it. (5) The model allows debugging by observing the step-by-step computation of training or inference on a single example. (6) Models are tested via a canary process before they enter production serving environments. (7) Models can be quickly and safely rolled back to a previous serving version.</p>
<p><strong>Monitoring tests for ML</strong> (1) Dependency changes result in notification. (2) Data invariants hold in training and serving inputs. (3) Training and serving features compute the same values (4) Models are not too tales (5) The model is numerically stable. (6) The model ha not experienced regressions in training speed, serving latency, throughput, or RAM usage. (7) The model has not experienced a regression in prediction quality on served data.</p>
<p>Source: <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 731</a>)</span></p>
</div>
</div>
</div>
</section>
</section>
<section id="exercises" class="level1 vertical-center" data-background-color="black">
<h1 class="vertical-center" data-background-color="black">‚úèÔ∏è Exercises</h1>
<section id="learning-scenarios" class="level2">
<h2 data-anchor-id="learning-scenarios">Learning scenarios</h2>
<p>Consider following problems:</p>
<ol type="1">
<li>Me learning to play tennis</li>
<li>An infant learning to speak</li>
</ol>
<p>Discuss following questions:</p>
<ul>
<li>Explain how this process fits into the general learning model.</li>
<li>Describe the percepts and actions of the player.</li>
<li>What types of learning I must do?</li>
<li>What example data is available?</li>
</ul>
</section>
<section id="learning-types" class="level2">
<h2 data-anchor-id="learning-types">Learning types</h2>
<p>Describe the differences between supervised, unsupervised, and reinforcement learning.</p>
</section>
<section id="ockhams-razor-1" class="level2">
<h2 data-anchor-id="ockhams-razor-1">Ockham‚Äôs razor</h2>
<p>In your own words, explain to us what Ockham‚Äôs razor is. Find an example that you can use to enrich your explanation of the concept.</p>
</section>
<section id="ml-concepts" class="level2">
<h2 data-anchor-id="ml-concepts">ML concepts</h2>
<p>Define the following machine-learning terms in your own words</p>
<ol type="a">
<li>Inductive learning</li>
<li>Training set</li>
<li>Hypothesis</li>
<li>Bias</li>
<li>Variance</li>
<li>Curve fitting</li>
</ol>
</section>
<section id="qualification-problem" class="level2">
<h2 data-anchor-id="qualification-problem">Qualification problem</h2>
<p>Draw a decision tree for the problem of deciding whether to move forward at a road intersection, given that the light has just turned green.</p>
<p>What problems do you see? Argue based on the qualification problem discussed in <a href="../6/#motivation">chapter probability</a>.</p>
<p>Generalize your findings and describe for which kind of problems decision trees are not suitable.</p>
</section>
<section id="divide-and-conquer" class="level2">
<h2 data-anchor-id="divide-and-conquer">Divide-and-conquer</h2>
<p>Create the decision tree by applying the divide-and-conquer approach on the restaurant examples.</p>
<p>Compare the naive tree with the tree gained by applying the divide-and-conquer heuristic. What differences do you see?.</p>
<div class="notes">
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Solution note</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Open</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>Open only if you need help.</p>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div id="fig-l-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/divide-and-conquer.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: Splitting the examples by testing on attributes, based on @RusselNorvig2022AIMA [p. 677]"><img src="images/divide-and-conquer.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Splitting the examples by testing on attributes, based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 677</a>)</span>
</figcaption>
</figure>
</div>
<p>At each node, we show the positive (light boxes) and negative (dark boxes) examples remaining. (a) Splitting on <em>Type</em> brings us no nearer to distinguishing between positive and negative examples. <em>Type</em> is a <strong>poor attribute</strong> (b) Splitting on <em>Patrons</em> does a good job of separating positive and negative examples. After splitting on <em>Patrons</em>, <em>Hungry</em> is a fairly good selection test. The full tree would be <em>Patrons</em>, <em>Hungry</em>, <em>Type</em> and <em>Fri</em>.</p>
</div>
</div>
</div>
</div>
</section>
<section id="decision-tree" class="level2">
<h2 data-anchor-id="decision-tree">Decision tree</h2>
<p>Explain how decision trees can be used to create a learning agent. Relate your answers to the components outlined in the lecture notes.</p>
<p>We never test the same attribute twice along one path in a decision tree. Why not?</p>
</section>
<section id="cat-recognition" class="level2">
<h2 data-anchor-id="cat-recognition">Cat recognition</h2>
<p>You want to teach a robot to recognize cat, using a set of features (the presence of blue eyes <code>b</code>, stripe <code>s</code>, or spot <code>m</code>). You also have several pictures of dogs to use as negative examples. The following table summarizes the content of training samples. Each binary feature is represented as <em>1</em> (meaning the feature is present) or <em>0</em> (meaning it is absent). The subject of <code>y</code> of the photo is encoded as <em>1</em> for cat or <em>-1</em> for dog.</p>
<div id="tbl-e7-obs" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-e7-obs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"><code>m</code></th>
<th style="text-align: center;"><code>b</code></th>
<th style="text-align: center;"><code>s</code></th>
<th style="text-align: center;">Subject <code>y</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-e7-obs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Observations
</figcaption>
</figure>
</div>
<ol type="1">
<li>Suppose the robot has a Naive Bayes-based brain. Write the Naive Bayes classification rule for this problem (i.e.&nbsp;write a formula which, given a data point x = (m, b, s), returns the most likely subject y). Write the formula in terms of likelyhood (conditional probabilties) and prior probabilities.</li>
<li>Give estimates for the parameters of the classification rule based on the training samples.</li>
<li>Suppose a subject which has stripes but no spots or blue eyes. What would happen if the robot had to guess the identity of the subject?</li>
</ol>
</section>
<section id="statisticians" class="level2">
<h2 data-anchor-id="statisticians">Statisticians</h2>
<p>Two statisticians go to the doctor and are both given the same prognosis: A 40% chance that the problem is the deadly disease A, and a 60% chance of the fatal disease B. Fortunately, there are anti-A and anti-B drugs that are inexpensive, 100% effective, and free of side-effects. The statisticians have the choice of taking one drug, both, or neither.</p>
<p>What will the first statistician (an avid Bayesian) do? How about the second statistician, who always uses the maximum likelihood hypothesis?</p>
<p>The doctor does some research and discovers that disease B actually comes in two versions, dextro-B and levo-B, which are equally likely and equally treatable by the anti-B drug.</p>
<p>Now that there are three hypotheses, what will the two statisticians do?</p>
</section>
</section>
<section id="literature" class="level1">
<h1>Literature</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-lecun2015deep" class="csl-entry" role="listitem">
LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. <span>‚ÄúDeep Learning.‚Äù</span> <em>Nature</em> 521 (7553): 436‚Äì44.
</div>
<div id="ref-RusselNorvig2022AIMA" class="csl-entry" role="listitem">
Russel, Stuart, and Peter Norvig. 2022. <em>Artificial Intelligence: A Modern Approach</em>. Harlow: Pearson Education.
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The decision is a diagonal line, and all decision tree tests divide the space up into rectangular, axis-aligned boxes. We would have to stack a lot of boxes to closely approximate the diagonal line.<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>The selection is implemented by means of a <em>choosing attribute test</em>, which is based on information theory and measures the information gain from the attribute tests. For more details please refer to <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 681</a> ff)</span><a href="#fnref2" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn3"><p>Meaning that all paths in the tree will be <strong>short</strong> and the tree as a whole will be <strong>shallow</strong><a href="#fnref3" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn4"><p>A tree that is too large risks overfitting the training data and poorly generalizing to new samples.<a href="#fnref4" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn5"><p>The training set is divided into two groups; 70% of the training set is used to build the tree, and the remaining 30% for validation; leading to <em>three</em> data sets (training, validation, test)<a href="#fnref5" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn6"><p>Pronounced ‚Äúem-ay-pee‚Äù<a href="#fnref6" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn7"><p>Which is equal to maximizing <span class="math inline">\(P(d|h_i)P(h_i)\)</span> or <span class="math inline">\(\ log P(d|h_i) + \log P(h_i)\)</span><a href="#fnref7" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn8"><p>Maximum likelihood is the ‚Äústandard‚Äù (non-Bayesian) statistical learning method<a href="#fnref8" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn9"><p>MAP learning provides a natural embodiment of <strong>Ockham‚Äôs razor</strong><a href="#fnref9" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn10"><p>1D for signals an sequences such as language, 2D for images or audio spectograms, 3D for video<a href="#fnref10" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn11"><p>Regulations such as the European GDPR require systems to provide explanations<a href="#fnref11" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/awe-hnu\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2025, Andy Weeger
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../../index.html">
<p>Start</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://www.hnu.de" target="_blank">
<p>HNU</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../../imprint.html">
<p>Imprint</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>