<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andy Weeger">

<title>Introduction to ML ‚Äì awe.lectures</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<link href="../../../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-58977f975ce4fb9f23873c5269492814.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"interstitial",
  "consent_type":"express",
  "palette":"dark",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<meta name="mermaid-theme" content="neutral">
<script src="../../../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<meta name="robots" content="noindex">   

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Introduction to ML ‚Äì awe.lectures">
<meta property="og:description" content="üß† Introduction to AI">
<meta property="og:image" content="https://awe-hnu.github.io/lectures/I2AI/26ST/learning/images/learning-agent.svg">
<meta property="og:site_name" content="awe.lectures">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">awe ‚Äî Lecture Notes</span>
    </a>
  </div>
          <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../../index.html" aria-current="page"> 
<span class="menu-text">Start</span></a>
  </li>  
</ul>
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">Introduction to ML</h1>
        </a>     
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">Introduction to ML</h1>
            <p class="subtitle lead">üß† Introduction to AI</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Lecture Notes</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-body">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Andy Weeger </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Apr 15, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">May 15, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../../../../index.html" class="sidebar-logo-link">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Admin</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://elearning.hnu.de/course/view.php?id=21594" class="sidebar-item-text sidebar-link" target="_blank">
 <span class="menu-text">Moodle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/admin/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Administrivia</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Lecture notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/intro/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/agents/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Environments &amp; Agents</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/search/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Search &amp; Planning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/knowledge/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Knowledge &amp; Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/probability-theory/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/bayes-net/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/learning/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Introduction to ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/decision-trees/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../lectures/I2AI/26ST/neural-networks/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p><a href="slides.html" class="btn btn-primary" target="blank">Slides</a></p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#la-architecture" id="toc-la-architecture" class="nav-link" data-scroll-target="#la-architecture">LA architecture</a></li>
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning">Supervised learning</a></li>
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning" class="nav-link" data-scroll-target="#unsupervised-learning">Unsupervised learning</a></li>
  <li><a href="#reinforcement-learning" id="toc-reinforcement-learning" class="nav-link" data-scroll-target="#reinforcement-learning">Reinforcement learning</a></li>
  <li><a href="#the-learning-process" id="toc-the-learning-process" class="nav-link" data-scroll-target="#the-learning-process">The learning process</a></li>
  <li><a href="#model-complexity" id="toc-model-complexity" class="nav-link" data-scroll-target="#model-complexity">Model complexity</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#literature" id="toc-literature" class="nav-link" data-scroll-target="#literature">Literature</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-body" id="quarto-document-content">





<section id="introduction" class="level1 headline-only">
<h1 class="headline-only">Introduction</h1>
<section id="characteristics" class="level2">
<h2 data-anchor-id="characteristics">Characteristics</h2>
<blockquote class="blockquote">
<p>Learning agents are those that can improve their behavior through diligent study of past experiences and predictions of the future. <em><span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, p. 668</a>)</span></em></p>
</blockquote>
<p>At its core, a learning agent (LA):</p>
<div class="incremental">
<ul class="incremental">
<li>Uses <strong>machine learning</strong> (ML) when it‚Äôs a computer system</li>
<li>Improves performance based on experience (observations)</li>
<li>Is necessary when designers lack complete knowledge of environments</li>
<li>Solves problems that are difficult to program explicitly (e.g., face recognition)</li>
</ul>
</div>
<div class="notes">
<p>This definition from <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022</a>)</span> emphasizes the key aspect of learning: <strong>improvement through experience</strong>.</p>
</div>
</section>
<section id="definition" class="level2">
<h2 data-anchor-id="definition">Definition</h2>
<blockquote class="blockquote">
<p>A computer is said to learn from <strong>experience E</strong> with respect to some <strong>task T</strong> and some <strong>performance measure P</strong>, if its performance on T, as measured by P, improves with experience E. <em><span class="citation" data-cites="mitchel1997machine">Mitchel (<a href="#ref-mitchel1997machine" role="doc-biblioref">1997, p. 2</a>)</span></em></p>
</blockquote>
<p>Any ML project needs to clearly specify:</p>
<div class="incremental">
<ul class="incremental">
<li>The <strong>task T</strong> (what problem are we solving?)</li>
<li>The <strong>experience E</strong> (what data will the system learn from?)</li>
<li>The <strong>performance measure P</strong> (how will we evaluate success?)</li>
</ul>
</div>
<div class="notes">
<p>The <strong>performance measure</strong> component is arguably the most critical component to define correctly. Poorly defined performance measures lead to misaligned systems that optimize for the wrong objectives, creating several serious problems:</p>
<ul>
<li><strong>Goal misalignment</strong>: The system optimizes for metrics that don‚Äôt actually capture what humans value or need</li>
<li><strong>Unexpected behaviors</strong>: The system may find unexpected or undesirable ways to maximize the specified metric</li>
<li><strong>Goodhart‚Äôs Law</strong>: Once a measure becomes the explicit target for optimization, it often loses its value as an accurate representation of what we actually care about<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</li>
<li><strong>Neglect of unmeasured factors</strong>: Important considerations that aren‚Äôt explicitly measured may be ignored or sacrificed</li>
</ul>
<p>Thus, the careful definition of performance measures is essential for ensuring ML systems solve the intended problems and align with human values.</p>
<p>The <strong>experience component</strong> is what fundamentally distinguishes machine learning from traditional programming. In traditional programming, humans encode rules that the computer follows, while in machine learning, the computer discovers rules from data.</p>
<div class="columns">
<div class="column">
<p><strong>Traditional programming</strong></p>
<ul>
<li>Rules are explicitly coded by humans</li>
<li>System behavior is predetermined by these rules</li>
<li>Changes require manual reprogramming</li>
<li>No ability to improve from data</li>
</ul>
</div><div class="column">
<p><strong>Machine Learning</strong></p>
<ul>
<li>Rules are derived from data (the ‚Äúexperience‚Äù)</li>
<li>System behavior emerges from patterns in the data</li>
<li>Changes can occur automatically with new data</li>
<li>Continuous improvement through additional experience</li>
</ul>
</div>
</div>
<p>This shift represents a profound change in how problem-solving with computers is approached. Rather than trying to encode all possible rules and scenarios, ML allows to let systems discover patterns themselves through exposure to relevant experiences.</p>
</div>
</section>
<section id="why-learning-works" class="level2">
<h2 data-anchor-id="why-learning-works">Why learning works</h2>
<p>How can we be sure that our learned hypothesis will predict well for previously unseen inputs? I.e., how do we know that the hypothesis <span class="math inline">\(h\)</span> is close to the target function <span class="math inline">\(f\)</span> when <span class="math inline">\(f\)</span> is unknown?</p>
<p>The underlying principle of <strong>computational learning theory</strong> is, that any hypothesis that is seriously wrong will almost certainly be ‚Äúfound out‚Äù with high probability after a small number of examples.</p>
<p>Thus, any hypothesis that is consistent with a sufficiently large set of training examples is unlikely to be seriously wrong: that is, it must be <strong>probably approximately correct</strong> (PAC).</p>
</section>
<section id="ml-x-ai" class="level2">
<h2 data-anchor-id="ml-x-ai">ML x AI</h2>
<p>ML constitutes one of the 4 categories of AI and is currently dominant in AI applications.</p>
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    AI[Artificial Intelligence] --&gt; ML[Machine Learning]
    AI --&gt; SP[Search and Planning]
    AI --&gt; KI[Knowledge and Inference]
    AI --&gt; MU[Modeling of Uncertainty]
    
    ML --&gt; SL[Supervised Learning]
    ML --&gt; UL[Unsupervised Learning]
    ML --&gt; RL[Reinforcement Learning]
    
    style AI fill:#000,stroke:#000,stroke-width:1px,color:#fff
    style ML fill:#0333ff,stroke:#0333ff,stroke-width:1px,color:#fff
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<div class="notes">
<p>However, the other branches have important historical significance and <strong>complementary roles</strong>:</p>
<ul>
<li><strong>Machine learning</strong> excels at pattern recognition, handling messy real-world data, adapting to new situations</li>
<li><strong>Search and planning</strong> is concerned with finding <strong>optimal solutions</strong>, guaranteeing results, and handling combinatorial problems. It encompasses algorithms like A*, minimax, and planning systems.</li>
<li><strong>Knowledge and inference</strong> excels at <strong>explicit reasoning</strong>, incorporating human expertise, and transparency. It includes expert systems, knowledge graphs, and logical reasoning.</li>
<li><strong>Modeling of uncertainty</strong> is concerned with handling incomplete information, quantifying confidence, and risk assessment. It covers Bayesian networks, fuzzy logic, and probabilistic reasoning</li>
</ul>
<p>Consequently, the most powerful AI systems often combine techniques from multiple branches. For example:</p>
<ul>
<li>Autonomous vehicles use ML for perception, planning algorithms for navigation, and uncertainty modeling for safety decisions</li>
<li>Medical diagnosis systems might combine knowledge graphs of medical facts with ML-based pattern recognition from patient data</li>
<li>Game AI like AlphaGo combines reinforcement learning with tree search algorithms</li>
</ul>
</div>
</section>
</section>
<section id="la-architecture" class="level1 headline-only">
<h1 class="headline-only">LA architecture</h1>
<section id="visualization" class="level2">
<h2 data-anchor-id="visualization">Visualization</h2>
<div id="fig-l-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/learning-agent.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A learning agent based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, p. 74</a>)</span>
</figcaption>
</figure>
</div>
</section>
<section id="building-blocks" class="level2">
<h2 data-anchor-id="building-blocks">Building blocks</h2>
<p><strong>Performance element:</strong> Processes percepts and chooses actions (relates to the basics of AI we have studied so far).</p>
<p><strong>Learning element:</strong> Carries out improvements ‚Äî requires awareness and feedback on how the agent is doing in the environment.</p>
<p><strong>Critic:</strong> Evaluation of the agent‚Äôs behavior based on a given external behavioral measure (i.e., feedback).</p>
<p><strong>Problem generator:</strong> Suggests explorative actions that lead the agent to new experiences.</p>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Performance element
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <strong>performance elements</strong> of the agent designs described in chapter <a href="../2/">Intelligent agents</a> are composed of</p>
<ul>
<li>a direct mapping from conditions to the current state of actions;</li>
<li>a means to infer relevant properties of the world from the percept sequence;</li>
<li>information about the way the world evolves and about the results of possible actions the agent can take;</li>
<li>utility information indicating the desirability of actions; and/or</li>
<li>goals that describe the most desirable states;</li>
</ul>
</div>
</div>
</div>
</section>
<section id="the-learning-element" class="level2">
<h2 data-anchor-id="the-learning-element">The learning element</h2>
<p>The design of the learning element is influenced by four important aspects:</p>
<div class="incremental">
<ul class="incremental">
<li>Which <strong>component</strong> of the performance element is to be improved?</li>
<li>What <strong>representation</strong> should be chosen (i.e., model type)?</li>
<li>What <strong>prior information</strong> is available (i.e., prior knowledge that influences the model)?</li>
<li>What form of <strong>feedback</strong> is available?</li>
</ul>
</div>
</section>
<section id="types-of-feedback" class="level2" data-visibility="hidden">
<h2 data-visibility="hidden" data-anchor-id="types-of-feedback">Types of feedback</h2>
<p>The type of feedback available for learning is usually the most important factor in determining the nature of the learning problem.</p>
<div class="incremental">
<ul class="incremental">
<li><strong>Supervised learning</strong>: Involves learning a function from examples of its inputs and outputs <em>‚ûû correct answer for each training instance</em>
<ul class="incremental">
<li>Requires labeled data</li>
<li>Examples: classification, regression</li>
</ul></li>
<li><strong>Unsupervised learning</strong>: The agent has to learn patterns in the input when no specific output values are given <em>‚ûû reward sequence, no correct answers</em>
<ul class="incremental">
<li>No labels needed</li>
<li>Examples: Clustering, dimensionality reduction</li>
</ul></li>
<li><strong>Reinforcement learning</strong>: The most general form of learning in which the agent is not told what to do by a teacher. Rather, it must learn from reinforcements (punishments or rewards). It typically involves learning how the environment works <em>‚ûû ‚Äújust make sense of the data‚Äù</em>
<ul class="incremental">
<li>No direct labels, but feedback on actions</li>
<li>Examples: Game playing, robotic control</li>
</ul></li>
</ul>
</div>
<div class="notes">
<p>These categories aren‚Äôt rigid - many modern systems combine elements of multiple approaches, often refered to as semi-supervised and self-supervised learning.</p>
<ul>
<li><strong>Semi-supervised learning</strong>: using small amounts of labeled data with large amounts of unlabeled data</li>
<li><strong>Self-supervised learning</strong>: creating ‚Äúsynthetic‚Äù supervision signals from unlabeled data</li>
</ul>
</div>
</section>
</section>
<section id="supervised-learning" class="level1 headline-only">
<h1 class="headline-only">Supervised learning</h1>
<section id="visualization-1" class="level2">
<h2 data-anchor-id="visualization-1">Visualization</h2>
<div id="fig-sl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sl-training.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Training phase of supervised learning
</figcaption>
</figure>
</div>
<hr>
<p>The model is then used as follows:</p>
<div id="fig-sl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sl-application.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Application phase of supervised learning
</figcaption>
</figure>
</div>
<div class="notes">
<p>Supervised learning resonates with our natural understanding of teaching. Just as we teach children by showing examples and providing feedback, supervised learning algorithms learn from labeled data. This approach mirrors human education ‚Äî we demonstrate correct answers and expect learners to generalize from specific examples to broader concepts. The clear relationship between inputs and desired outputs makes supervised learning conceptually straightforward. However, unlike humans who can often understand concepts from just a few examples, machine learning models typically require hundreds or thousands of labeled instances to perform well, and they lack the contextual understanding that humans bring to learning tasks.</p>
</div>
</section>
<section id="key-challenges" class="level2">
<h2 data-anchor-id="key-challenges">Key challenges</h2>
<div class="medium">
<div class="incremental">
<ul class="incremental">
<li>Getting enough labeled data</li>
<li>Ensuring labels are accurate</li>
<li>Dealing with imbalanced data classes</li>
<li>Feature selection and engineering</li>
</ul>
</div>
</div>
<div class="notes">
<p>‚ÄúGarbage in, garbage out‚Äù is especially relevant in supervised learning. Your training data quality directly determines the ceiling of your model‚Äôs performance ‚Äî no algorithm can overcome fundamentally flawed data. This creates several critical considerations: data must be representative of real-world applications; inconsistent labels introduce confusion into the learning process; and edge cases must be adequately represented. The process of collecting, cleaning, and verifying training data often consumes the majority of time in practical ML projects. When evaluating supervised learning results, always consider whether performance limitations stem from the algorithm or from the underlying data quality.</p>
</div>
</section>
<section id="approaches" class="level2" data-visibility="hidden">
<h2 data-visibility="hidden" data-anchor-id="approaches">Approaches</h2>
<p><strong>Classification</strong> and <strong>regression</strong> represent fundamental approaches in supervised learning. Classification tasks predict discrete categories or labels ‚Äî is this email spam? Does this image show a tumor? Which species of flower is in this photograph? These problems have definite, separate outcomes with no middle ground. Common examples include sentiment analysis, fraud detection, and image recognition. Regression predicts continuous numerical values on a spectrum, such as house prices based on features like square footage, patient‚Äôs blood glucose levels from symptom data, or tomorrow‚Äôs temperature. This distinction influences everything from model selection to evaluation metrics - accuracy makes sense for classification but not for regression, where measures like mean squared error are more appropriate. Many real-world problems can be framed as either classification or regression depending on specific needs.</p>
<section id="classification-algorithms" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="classification-algorithms">Classification algorithms</h3>
<ul>
<li><strong>Logistic Regression</strong>: Despite its name, this is used for classification problems. It predicts the probability of an instance belonging to a particular class.</li>
<li><strong>Support Vector Machines (SVM)</strong>: Creates a hyperplane that maximally separates different classes in feature space.</li>
<li><strong>Decision Trees</strong>: Splits data based on feature values to create a tree-like model of decisions.</li>
<li><strong>Random Forests</strong>: Ensemble of decision trees that improves accuracy and reduces overfitting.</li>
<li><strong>Neural Networks</strong>: Multiple layers of interconnected nodes that can learn complex patterns for classification tasks.</li>
</ul>
</section>
<section id="regression-algorithms" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="regression-algorithms">Regression algorithms</h3>
<ul>
<li><strong>Linear Regression</strong>: Models the relationship between variables by fitting a linear equation to observed data.</li>
<li><strong>Support Vector Regression (SVR)</strong>: Adaptation of SVM principles for predicting continuous values.</li>
<li><strong>Decision Trees</strong>: Can be adapted for regression by predicting numerical values at leaf nodes.</li>
<li><strong>Random Forests</strong>: Ensemble method that averages predictions from multiple regression trees.</li>
<li><strong>Neural Networks</strong>: Can output continuous values for regression problems when configured with appropriate activation functions.</li>
</ul>
</section>
<section id="versatile-approaches" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="versatile-approaches">Versatile approaches</h3>
<p>Many of these algorithms can be adapted for either classification or regression tasks:</p>
<ul>
<li><strong>Decision Trees and Random Forests</strong>: Change output from class labels to continuous values</li>
<li><strong>Neural Networks</strong>: Modify the output layer and loss function based on the problem type</li>
<li><strong>Support Vector Machines</strong>: Use standard SVM for classification or SVR for regression</li>
</ul>
</section>
</section>
<section id="practical-applications" class="level2">
<h2 data-anchor-id="practical-applications">Practical applications</h2>
<div class="notes">
<p><strong>Image classification</strong> ‚Äî inputs can be camera images, each one accompanied by an output saying, e.g., ‚Äúbus‚Äù or ‚Äúpedestrian‚Äù. An output like this is called a label. The agents learns a function that, when given a new image, predicts the appropriate label.</p>
</div>
<div class="medium">
<div class="incremental">
<ul class="incremental">
<li>Sentiment analysis</li>
<li>Spam detection</li>
<li>Loan approval prediction</li>
<li></li>
</ul>
</div>
</div>
</section>
</section>
<section id="unsupervised-learning" class="level1 headline-only page-columns page-full">
<h1 class="headline-only">Unsupervised learning</h1>
<section id="visualization-2" class="level2">
<h2 data-anchor-id="visualization-2">Visualization</h2>
<div id="fig-usl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/usl-training.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Training phase of unsupervised learning
</figcaption>
</figure>
</div>
<hr>
<p>The model is then used as follows:</p>
<div id="fig-usl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/usl-application.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Application phase of unsupervised learning
</figcaption>
</figure>
</div>
<div class="notes">
<p>Unsupervised learning mirrors how we naturally discover patterns in the world around us. Just as children learn to categorize objects without being explicitly taught every category, unsupervised algorithms find structure in unlabeled data. This approach reflects human intuition ‚Äî we recognize similarities, identify outliers, and group related items without requiring prior labels. The absence of predetermined outputs makes unsupervised learning both powerful and challenging. Unlike supervised learning, these algorithms must determine what‚Äôs important within the data itself, similar to how humans can walk into an unfamiliar environment and instinctively organize what they perceive. Unsupervised methods excel at revealing hidden structures that might never be discovered through directed approaches, though their results can sometimes be more difficult to validate objectively.</p>
</div>
</section>
<section id="key-challenges-1" class="level2">
<h2 data-anchor-id="key-challenges-1">Key challenges</h2>
<div class="medium">
<div class="incremental">
<ul class="incremental">
<li>Evaluating the quality of results without ground truth</li>
<li>Determining the optimal number of groups or patterns</li>
<li>Interpreting the discovered patterns meaningfully</li>
<li>Dealing with high-dimensional data</li>
</ul>
</div>
</div>
<div class="notes">
<p>The open-ended nature of unsupervised learning creates unique considerations. Without labeled examples to guide the process, these algorithms must rely on inherent data properties like density, distance metrics, or statistical distributions. This raises fundamental questions: How do we know if discovered patterns are meaningful rather than arbitrary? What makes one clustering better than another? The absence of clear right or wrong answers means evaluation often relies on domain expertise and business context. Additionally, many unsupervised techniques struggle with the ‚Äúcurse of dimensionality‚Äù<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> ‚Äî a phenomenon where data becomes increasingly sparse as dimensions increase. In high-dimensional spaces, points become nearly equidistant from each other, making similarity measures less meaningful. For example, in a 1,000-dimensional space, the difference between the closest and farthest points becomes negligible, undermining the foundation of distance-based clustering. This dramatically impacts algorithms that rely on distance metrics, as the concept of proximity becomes less informative. Even with large datasets, the available data points become insufficient to adequately represent the vastly increased volume of the feature space.</p>
</div>
</section>
<section id="approaches-1" class="level2" data-visibility="hidden">
<h2 data-visibility="hidden" data-anchor-id="approaches-1">Approaches</h2>
<p><strong>Clustering</strong> and <strong>dimensionality reduction</strong> represent core approaches in unsupervised learning. Clustering identifies natural groupings within data ‚Äî which customers behave similarly? What patterns exist in gene expression data? How do documents organize into topics? These techniques reveal structure without predefined categories. Dimensionality reduction transforms complex, high-dimensional data into simpler representations while preserving essential information. This helps visualize complex datasets, remove noise, and combat the curse of dimensionality. Both approaches serve as powerful tools for exploratory data analysis, helping analysts gain insights before applying more targeted methods. The insights generated often inform subsequent supervised learning problems by suggesting natural categories or revealing which features capture the most variance.</p>
<section id="clustering-algorithms" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="clustering-algorithms">Clustering algorithms</h3>
<ul>
<li><strong>K-Means</strong>: Partitions data into K clusters by minimizing the distance between points and their assigned cluster centers.</li>
<li><strong>Hierarchical Clustering</strong>: Builds nested clusters by either merging or splitting them successively (agglomerative or divisive).</li>
<li><strong>DBSCAN</strong>: Density-based approach that finds clusters of arbitrary shape and identifies outliers.</li>
<li><strong>Gaussian Mixture Models (GMM)</strong>: Models clusters as a mixture of multiple Gaussian distributions.</li>
<li><strong>Spectral Clustering</strong>: Leverages eigenvalues of similarity matrices to reduce dimensions before clustering.</li>
</ul>
</section>
<section id="dimensionality-reduction-algorithms" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="dimensionality-reduction-algorithms">Dimensionality reduction algorithms</h3>
<ul>
<li><strong>Principal Component Analysis (PCA)</strong>: Transforms data to a new coordinate system that maximizes variance along orthogonal axes.</li>
<li><strong>t-SNE</strong>: Visualizes high-dimensional data by giving each datapoint a location in a 2D or 3D map, particularly effective for visualization.</li>
<li><strong>UMAP</strong>: Manifold learning technique for dimension reduction that preserves more global structure than t-SNE.</li>
<li><strong>Autoencoders</strong>: Neural networks that compress data into a latent-space representation and then reconstruct it.</li>
<li><strong>Kernel PCA</strong>: Non-linear extension of PCA that works in transformed feature spaces.</li>
</ul>
</section>
</section>
<section id="practical-applications-1" class="level2 page-columns page-full">
<h2 data-anchor-id="practical-applications-1">Practical applications</h2>
<p><strong>Computer vision</strong> ‚Äî when shown millions of images, a computer vision system could identify large cluster of similar images (without ‚Äúknowing‚Äù what is shown on these).</p>
<div class="medium">
<div class="incremental">
<ul class="incremental">
<li>Customer segmentation</li>
<li>Anomaly detection</li>
<li>Topic modeling in text</li>
<li>Recommender systems</li>
<li>Image compression</li>
</ul>
</div>
</div>
<div class="notes page-columns page-full">
<div class="column-page-inset-right">
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We begin with the unlabeled data, representing customer purchases of different products. A value of 1 indicates a purchase, while 0 indicates no purchase.</p>
<p><span class="h4"><strong>Unlabeled data</strong></span></p>
<table class="table">
<caption>Unlabeled customer purchase data</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Customer</th>
<th>Product 1</th>
<th>Product 2</th>
<th>Product 3</th>
<th>Product 4</th>
<th>Product 5</th>
<th>Product 6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Customer 1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>Customer 3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>Customer 4</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Customer 5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>Customer 6</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Customer 7</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 8</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>First, we apply <strong>clustering</strong> to group customers with similar product purchasing behavior. Customers with similar rows (purchase patterns) are grouped together.</p>
<p>Customers 1, 6, 7, and 8 tend to buy products 1‚Äì3, often in combination.</p>
<table class="table">
<caption>Cluster A: customers 1, 6, 7, 8</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Customer</th>
<th>Product 1</th>
<th>Product 2</th>
<th>Product 3</th>
<th>Product 4</th>
<th>Product 5</th>
<th>Product 6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Customer 1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 6</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Customer 7</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 8</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Customers 2, 3, and 5 show a preference for product 6 and product 5.</p>
<table class="table">
<caption>Cluster B: customers 2, 3, 5</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Customer</th>
<th>Product 1</th>
<th>Product 2</th>
<th>Product 3</th>
<th>Product 4</th>
<th>Product 5</th>
<th>Product 6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Customer 2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td>Customer 3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td>Customer 5</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Customer 4 has a unique pattern and does not fit well into either cluster.</p>
<p>Second, we perform <strong>association rule mining</strong> to find relationships between product purchases, i.e., which products are frequently bought together.</p>
<table class="table">
<colgroup>
<col style="width: 14%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="header">
<th>Metric.</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Support</td>
<td>% of transactions that contain both items (how common is the combo?)</td>
</tr>
<tr class="even">
<td>Confidence</td>
<td>% of times Product B is bought when Product A is bought (A ‚Üí B)</td>
</tr>
<tr class="odd">
<td>Lift</td>
<td>How much more likely A and B are bought together vs.&nbsp;by chance<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Confidence: table of association rules</caption>
<colgroup>
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Rule</th>
<th>Support Count (X &amp; Y)</th>
<th>X Count</th>
<th>Confidence</th>
<th>Support(Y)</th>
<th>Lift</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>P1 ‚Üí P2</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>50.0%</td>
<td>1.00</td>
</tr>
<tr class="even">
<td>P1 ‚Üí P3</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>50.0%</td>
<td>0.50</td>
</tr>
<tr class="odd">
<td>P1 ‚Üí P4</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>37.5%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P1 ‚Üí P5</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>25.0%</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td>P1 ‚Üí P6</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>37.5%</td>
<td>1.33</td>
</tr>
<tr class="even">
<td>P2 ‚Üí P1</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>50.0%</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><strong>P2 ‚Üí P3</strong></td>
<td><strong>3</strong></td>
<td><strong>4</strong></td>
<td><strong>75.0%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.50</strong></td>
</tr>
<tr class="even">
<td>P2 ‚Üí P4</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>37.5%</td>
<td>0.67</td>
</tr>
<tr class="odd">
<td>P2 ‚Üí P5</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>25.0%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P2 ‚Üí P6</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>37.5%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P3 ‚Üí P1</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>50.0%</td>
<td>0.50</td>
</tr>
<tr class="even">
<td><strong>P3 ‚Üí P2</strong></td>
<td><strong>3</strong></td>
<td><strong>4</strong></td>
<td><strong>75.0%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.50</strong></td>
</tr>
<tr class="odd">
<td>P3 ‚Üí P4</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>37.5%</td>
<td>1.33</td>
</tr>
<tr class="even">
<td>P3 ‚Üí P5</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>25.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P3 ‚Üí P6</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>37.5%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P4 ‚Üí P1</td>
<td>0</td>
<td>3</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P4 ‚Üí P2</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>50.0%</td>
<td>0.67</td>
</tr>
<tr class="even">
<td><strong>P4 ‚Üí P3</strong></td>
<td><strong>2</strong></td>
<td><strong>3</strong></td>
<td><strong>66.7%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.33</strong></td>
</tr>
<tr class="odd">
<td>P4 ‚Üí P5</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>25.0%</td>
<td>1.33</td>
</tr>
<tr class="even">
<td>P4 ‚Üí P6</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>37.5%</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td>P5 ‚Üí P1</td>
<td>1</td>
<td>2</td>
<td>50.0%</td>
<td>50.0%</td>
<td>1.00</td>
</tr>
<tr class="even">
<td>P5 ‚Üí P2</td>
<td>0</td>
<td>2</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P5 ‚Üí P3</td>
<td>0</td>
<td>2</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P5 ‚Üí P4</td>
<td>1</td>
<td>2</td>
<td>50.0%</td>
<td>37.5%</td>
<td>1.33</td>
</tr>
<tr class="odd">
<td><strong>P5 ‚Üí P6</strong></td>
<td><strong>2</strong></td>
<td><strong>2</strong></td>
<td><strong>100.0%</strong></td>
<td><strong>37.5%</strong></td>
<td><strong>2.67</strong></td>
</tr>
<tr class="even">
<td><strong>P6 ‚Üí P1</strong></td>
<td><strong>2</strong></td>
<td><strong>3</strong></td>
<td><strong>66.7%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.33</strong></td>
</tr>
<tr class="odd">
<td>P6 ‚Üí P2</td>
<td>0</td>
<td>3</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P6 ‚Üí P3</td>
<td>0</td>
<td>3</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P6 ‚Üí P4</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>37.5%</td>
<td>0.89</td>
</tr>
<tr class="even">
<td><strong>P6 ‚Üí P5</strong></td>
<td><strong>2</strong></td>
<td><strong>3</strong></td>
<td><strong>66.7%</strong></td>
<td><strong>25.0%</strong></td>
<td><strong>2.67</strong></td>
</tr>
</tbody>
</table>
<p><span class="h4"><strong>Insights</strong></span></p>
<p>Based on the association rules analysis, we can derive the following insights:</p>
<ol type="1">
<li><strong>Strong product pairings</strong>:
<ul>
<li>Products 5 and 6 have the strongest association with the highest lift value (2.67) in both directions. Customers who buy either one are much more likely to buy the other, suggesting these products strongly complement each other.</li>
<li>Products 2 and 3 also show a strong positive association (lift = 1.50), with 75% of product 2 buyers also purchasing product 3.</li>
</ul></li>
<li><strong>One-way associations</strong>:
<ul>
<li>The rule P4 ‚Üí P3 shows that 66.7% of customers who buy product 4 also buy product 3 (lift = 1.33), but the reverse isn‚Äôt as strong (P3 ‚Üí P4 has only 50% confidence).</li>
<li>This suggests Product 4 buyers are a subset of product 3 buyers, but not vice versa.</li>
</ul></li>
<li><strong>Product clustering</strong>:
<ul>
<li>Group 1: Products 5 and 6 (strongest association)</li>
<li>Group 2: Products 2 and 3 (strong association)</li>
<li>Group 3: Products 1 and 6 (moderate association)</li>
</ul></li>
<li><strong>Product Independence and Negative Associations</strong>:
<ul>
<li>Several products never appear together (lift = 0), such as P1 and P4, P2 and P5, P3 and P5.</li>
<li>This suggests potential product incompatibility or different customer segments.</li>
</ul></li>
<li><strong>Product Popularity</strong>:
<ul>
<li>Products 1, 2, and 3 have the highest support (each purchased by 50% of customers)</li>
<li>Product 5 has the lowest support (only 25%)</li>
</ul></li>
<li><strong>Business Applications</strong>:
<ul>
<li>Bundle marketing: The P5 ‚Üí P6 rule with 100% confidence and 2.67 lift suggests these products could be effectively bundled.</li>
<li>Recommendation systems: When a customer buys product 4, recommending product 3 would be logical (66.7% confidence).</li>
</ul></li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="reinforcement-learning" class="level1 headline-only">
<h1 class="headline-only">Reinforcement learning</h1>
<section id="visualization-3" class="level2">
<h2 data-anchor-id="visualization-3">Visualization</h2>
<div id="fig-sl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/rf-learning.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Reinforcement learning
</figcaption>
</figure>
</div>
<div class="notes">
<p>The goal of reinforcement learning is to learn an optimal policy. A policy defines for each state <span class="math inline">\(S\)</span> of the environment an action <span class="math inline">\(A\)</span>, which shall be executed in this state. The optimal policy is the policy for which the expected cumulative future reward is maximal.</p>
<p>Reinforcement-Learning is Trial-and-Error learning. The agent selects an action <span class="math inline">\(A_t\)</span> in it‚Äôs current state <span class="math inline">\(S_t\)</span>. After the execution of this action the environment state changes, the new state is <span class="math inline">\(S_{t+1}\)</span>. Moreover, the agent may receive a positive or negative reward <span class="math inline">\(R_{t+1}\)</span> for his previous action. These received rewards are applied to adapt the future action-selection. Since the reward is only available after performing actions, this type of learning is also called learning with a critic - in contrast to learning with a teacher (i.e.&nbsp;supervised learning).</p>
<p>Reinforcement-Learning works in non-deterministic environments (i.e.&nbsp;for a given state-action pair the successive state is not known for sure). Reinforcement-Learning can also be applied, if the environment is totally unknown to the agent (i.e.&nbsp;the agent doesn‚Äôt know the set of possible successive states and the set of possible rewards).</p>
<p>During the iterative training process in unknown environments the agent must explore. The challenge is to find a good explore-exploit trade off. Explore means going along new, not yet visited paths. Exploit means applying for the best action learned so far.</p>
<p>Reinforcement learning embodies how we learn through interaction with our environment. Just as children learn by exploring their surroundings and receiving feedback, reinforcement learning agents improve behavior through trial and error. This approach reflects natural learning processes ‚Äî we take actions, observe consequences, and adjust future decisions accordingly. The dynamic interplay between exploration (trying new things) and exploitation (leveraging known rewards) mirrors how humans navigate unfamiliar situations. Unlike supervised or unsupervised learning, reinforcement learning incorporates the concept of time ‚Äî actions influence not just immediate rewards but also future states and opportunities. This sequential decision-making aspect makes it particularly suitable for complex tasks where long-term strategy matters more than immediate outcomes. While powerful, this approach requires careful formulation of reward mechanisms that truly reflect desired behaviors rather than exploitable shortcuts.</p>
</div>
</section>
<section id="key-challenges-2" class="level2">
<h2 data-anchor-id="key-challenges-2">Key challenges</h2>
<div class="medium">
<div class="incremental">
<ul class="incremental">
<li>Designing appropriate reward functions</li>
<li>Balancing exploration vs.&nbsp;exploitation</li>
<li>Dealing with delayed rewards and credit assignment</li>
<li>Sample efficiency in real-world applications</li>
<li>Transferring learning across different environments</li>
</ul>
</div>
</div>
<div class="notes">
<p>The reward-driven nature of reinforcement learning presents unique complexities. Since the agent learns entirely from environmental feedback, the design of reward signals fundamentally shapes what is learned. An improperly specified reward function can lead to unexpected or undesired behaviors ‚Äî a phenomenon known as ‚Äúreward hacking<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.‚Äù Additionally, reinforcement learning algorithms must decide when to explore new possibilities versus when to exploit known effective strategies. Too much exploration wastes resources; too little risks getting stuck in suboptimal solutions. Perhaps most challenging is the temporal credit assignment problem: when a positive outcome follows a long sequence of actions, how do we determine which actions were responsible? This difficulty increases with longer time horizons and more complex action spaces.</p>
</div>
</section>
<section id="approaches-2" class="level2" data-visibility="hidden">
<h2 data-visibility="hidden" data-anchor-id="approaches-2">Approaches</h2>
<p><strong>Value-based methods</strong> and <strong>policy-based methods</strong> represent fundamental approaches in reinforcement learning. Value-based approaches focus on estimating the expected utility of states or state-action pairs ‚Äî essentially asking ‚Äúhow good is it to be in this situation?‚Äù These methods indirectly derive behaviors by selecting actions that lead to states with higher estimated values. Policy-based methods directly model the agent‚Äôs behavior strategy, learning a mapping from states to actions without necessarily estimating intermediate values. The choice between these approaches influences everything from sample efficiency to exploration strategy. Many modern algorithms combine elements of both approaches, learning both value functions and explicit policies simultaneously to leverage their complementary strengths. The distinctions become especially important when tackling problems with continuous action spaces or when the optimal policy is stochastic rather than deterministic.</p>
<section id="value-based-algorithm-example" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="value-based-algorithm-example">Value-based algorithm example</h3>
<p><strong>Q-Learning</strong> learns the value of state-action pairs (Q-values) through iterative updates based on experienced rewards. In a real-world application, smart thermostats use Q-learning to optimize temperature settings based on occupancy patterns. The thermostat learns the value of adjusting temperature (actions) at different times and conditions (states) by observing energy consumption and user comfort feedback (rewards). Over time, it discovers which temperature adjustments maximize comfort while minimizing energy use, adapting to the specific household‚Äôs patterns without requiring explicit programming.</p>
</section>
<section id="policy-based-algorithm-example" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="policy-based-algorithm-example">Policy-based algorithm example</h3>
<p><strong>Proximal Policy Optimization (PPO)</strong> constrains policy updates to prevent destructively large changes while maintaining sample efficiency. Boston Dynamics‚Äô robotic dogs employ PPO to learn stable walking gaits across diverse terrains. The robot directly learns a policy mapping sensor readings (states) to joint movements (actions). PPO ensures that learning progresses steadily without catastrophic forgetting or instability - critical when a physical robot is learning through actual interactions with its environment. The algorithm makes conservative updates to movement policies, improving performance while preventing the robot from ‚Äúunlearning‚Äù previously mastered skills.</p>
</section>
</section>
<section id="practical-applications-2" class="level2">
<h2 data-anchor-id="practical-applications-2">Practical applications</h2>
<p>Game playing ‚Äî imagine, it is told at the end of a game that it has won (a reward) or lost (a punishment). Based on that feedback, it has to decide which of the actions prior to the reinforcement were most responsible for it, and to alter its actions to aim towards more rewards in future.</p>
<div class="medium">
<div class="incremental">
<ul class="incremental">
<li>Game playing (Chess, Go, video games)</li>
<li>Robotics and control systems</li>
<li>Resource management and scheduling</li>
<li>Recommendation systems</li>
</ul>
</div>
</div>
</section>
</section>
<section id="the-learning-process" class="level1 headline-only page-columns page-full">
<h1 class="headline-only">The learning process</h1>
<section id="phases" class="level2 page-columns page-full">
<h2 data-anchor-id="phases">Phases</h2>
<div class="notes page-columns page-full">
<div class="column-page-inset">
<div class="cell" data-layout-align="left">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    TD[(Training Data)] --&gt; T[Training]
    T --&gt; M[Model]
    VD[(Validation Data)] --&gt; V[Validation]
    M --&gt; V
    V --&gt; |"Hyperparameter Tuning"| T
    V --&gt; |"Model Selection"| SM[Selected Model]
    TestD[(Test Data)] --&gt; TE[Testing]
    SM --&gt; TE
    TE --&gt; |"Performance Estimation"| FM[Final Model]
    ND[(New Data)] --&gt; AP[Application]
    FM --&gt; AP
    AP --&gt; PR[Predictions]
    
    style TD fill:#f9f9f9,stroke:#333,stroke-width:1px
    style VD fill:#f9f9f9,stroke:#333,stroke-width:1px
    style TestD fill:#f9f9f9,stroke:#333,stroke-width:1px
    style ND fill:#f9f9f9,stroke:#333,stroke-width:1px
    style M fill:#c0f0c0,stroke:#333,stroke-width:1px
    style SM fill:#c0f0c0,stroke:#333,stroke-width:1px
    style FM fill:#c0f0c0,stroke:#333,stroke-width:1px
    style PR fill:#ffe0c0,stroke:#333,stroke-width:1px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<p>Machine learning projects follow a systematic workflow with distinct phases, each serving a critical purpose in developing reliable and effective models. Understanding these phases helps ensure robust model development and deployment.</p>
<p><span class="h4"><strong>Training phase</strong></span></p>
<p>During the training phase, we apply a carefully selected dataset to learn a general model. The nature of this model varies by learning paradigm ‚Äî in unsupervised learning, it describes the inherent structure of the data (such as clusters or reduced dimensions), while in supervised and reinforcement learning, it captures functional relationships that map inputs to outputs or states to actions. This phase involves iterative optimization of model parameters to minimize error or maximize reward according to a specific objective function. The choice of training algorithm significantly impacts both computational efficiency and the quality of the resulting model. While the model aims to fit training data well, excessive focus on perfect training performance often leads to overfitting ‚Äî a critical pitfall where the model essentially memorizes training examples rather than learning generalizable patterns.</p>
<p><span class="h4"><strong>Validation phase</strong></span></p>
<p>The validation phase addresses a fundamental challenge in machine learning: we don‚Äôt simply want models that excel on training data; we need models that generalize well to new, unseen data. To assess generalization capacity, we apply the model to a validation dataset that remains completely separate from training data. For each input in the validation set, we calculate the model‚Äôs prediction and compare it against the true output (for supervised learning) or evaluate its performance under defined metrics (for unsupervised and reinforcement learning). This creates an error statistic or performance measure that serves multiple crucial purposes: evaluating individual models, comparing different approaches, tuning hyperparameters, and ultimately selecting the most promising candidate. The validation phase essentially simulates real-world performance in a controlled environment, helping identify issues like overfitting or underfitting before deployment.</p>
<p><span class="h4"><strong>Test phase</strong></span></p>
<p>The test phase provides the final performance assessment before real-world deployment. After model selection and tuning in the validation phase, we evaluate the chosen model on a completely separate test dataset ‚Äî one that hasn‚Äôt influenced any aspect of model development. This rigorous separation ensures an unbiased estimate of operational performance. The test dataset should closely mirror the distribution of data the model will encounter in production, making test results a reliable predictor of real-world effectiveness. Lower performance on test data compared to validation data often signals potential distribution shifts or overfitting to the validation set itself ‚Äî critical issues to address before deployment. The test phase represents our last opportunity to detect problems in a controlled environment, making it an essential safeguard against deploying underperforming models.</p>
<p><span class="h4"><strong>Operational mode</strong></span></p>
<p>Once a model demonstrates satisfactory performance in the test phase, it transitions to operational mode ‚Äî deployment in real-world environments to fulfill its intended purpose. In this phase, the model processes new inputs to generate outputs (classifications, predictions, actions) that drive decision-making or insights. Operational deployment introduces new considerations beyond accuracy: computational efficiency, latency requirements, integration with existing systems, and monitoring mechanisms all become crucial factors. Even after deployment, the learning process doesn‚Äôt end; production models require ongoing monitoring for performance degradation, which often occurs as real-world data distributions gradually shift away from training distributions. Many sophisticated deployments incorporate feedback loops that capture new operational data, enabling periodic retraining to maintain or improve performance over time. This continuous improvement cycle helps ensure models remain effective as the environments they operate in evolve.</p>
</div>
</section>
</section>
<section id="model-complexity" class="level1 headline-only">
<h1 class="headline-only">Model complexity</h1>
<section id="the-bias-variance-tradeoff" class="level2">
<h2 data-anchor-id="the-bias-variance-tradeoff">The Bias-variance tradeoff</h2>
<p>In ML, selecting the appropriate model complexity is a fundamental challenge. Here this principle is demonstrated through polynomial curve fitting ‚Äì one of the simplest yet most illustrative examples of the bias-variance tradeoff.</p>
<p>When building a machine learning model, we must balance two competing concerns:</p>
<div class="incremental">
<ol class="incremental" type="1">
<li><strong>Bias</strong>: The error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss relevant relations between features and outputs (underfitting).</li>
<li><strong>Variance</strong>: The error from sensitivity to small fluctuations in the training set. High variance models can fit the training data very well but perform poorly on new, unseen data (overfitting).</li>
</ol>
</div>
</section>
<section id="polynomial-curve-fitting-example" class="level2">
<h2 data-anchor-id="polynomial-curve-fitting-example">Polynomial curve fitting example</h2>
<p>In this visualization, we‚Äôll see how polynomials of different degrees fit a dataset generated from a true quadratic function with some added noise:</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'dplyr'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:stats':

    filter, lag</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-curve-fitting-all" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-curve-fitting-all-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-curve-fitting-all-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-curve-fitting-all-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Comparison of linear underfitting, quadratic good fit, and high-degree overfitting to noisy data generated from a quadratic function.
</figcaption>
</figure>
</div>
</div>
</div>
<section id="underfitting" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="underfitting">Underfitting</h3>
<p>The linear model (blue line) is too simple to capture the underlying pattern. It has:</p>
<ul>
<li><strong>High bias</strong>:<br>
The model makes strong assumptions about the data structure (linearity)</li>
<li><strong>Low variance</strong>:<br>
Different training sets would produce similar models</li>
<li><strong>High training and test error</strong>:<br>
The model fails to capture the fundamental pattern</li>
</ul>
</section>
<section id="good-fit" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="good-fit">Good fit</h3>
<p>The quadratic model (purple line) captures the underlying pattern well. It has:</p>
<ul>
<li><strong>Balanced bias and variance</strong>:<br>
The model makes appropriate assumptions</li>
<li><strong>Low training and test error</strong>:<br>
Performs well on both seen and unseen data</li>
<li><strong>Good generalization</strong>:<br>
Likely to predict new data points accurately</li>
</ul>
</section>
<section id="overfitting" class="level3" data-visibility="hidden">
<h3 data-visibility="hidden" data-anchor-id="overfitting">Overfitting</h3>
<p>The high-degree polynomial (red line) fits training data closely but wiggles excessively. It has:</p>
<ul>
<li><strong>Low bias</strong>:<br>
Makes few assumptions about the data structure</li>
<li><strong>High variance</strong>:<br>
Would change dramatically with different training sets</li>
<li><strong>Low training error but high test error</strong>:<br>
Memorizes the training data rather than learning the pattern</li>
</ul>
</section>
</section>
<section id="the-learning-principle" class="level2">
<h2 data-anchor-id="the-learning-principle">The learning principle</h2>
<div class="medium">
<p>This example illustrates <strong>Ockham‚Äôs razor</strong> in action.</p>
</div>
<p>The simplest model that adequately explains the data is likely to have the best predictive power. While we could create a complex polynomial that passes through every training point perfectly, such a model would likely perform poorly on new data.</p>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Ockham‚Äôs razor
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ockham‚Äôs razor is a choice between more complex, low-bias hypotheses that fit the training data well and simple, low-variance hypotheses that may generalize better. Wililiam of Ockham stated in the first century the principle that ‚Äúplurality [of entities] should not be posited without necessity ‚Äî the so-called Ockham‚Äôs razor that‚Äùshaves off‚Äù dubious explanations.</p>
</div>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<div class="incremental">
<ul class="incremental">
<li>Machine learning fundamentally changes how we approach problem-solving with computers</li>
<li>Instead of explicit programming, we design systems that learn from data and experience</li>
<li>The field combines statistics, optimization, and domain knowledge</li>
<li>Understanding the core concepts helps in developing effective learning systems</li>
<li>Key tradeoffs include:
<ul class="incremental">
<li>Bias vs.&nbsp;variance</li>
<li>Model complexity vs.&nbsp;generalization</li>
<li>Exploration vs.&nbsp;exploitation</li>
<li>Accuracy vs.&nbsp;interpretability</li>
</ul></li>
</ul>
</div>
</section>
<section id="exercises" class="level1 headline-only">
<h1 class="headline-only">Exercises</h1>
<section id="learning-scenarios" class="level2">
<h2 data-anchor-id="learning-scenarios">Learning scenarios</h2>
<p>Consider following problems:</p>
<ol type="1">
<li>Me learning to play tennis</li>
<li>An infant learning to speak</li>
</ol>
<p>Discuss following questions:</p>
<ul>
<li>Explain how this process fits into the general learning model.</li>
<li>Describe the percepts and actions of the player.</li>
<li>What types of learning I must do?</li>
<li>What example data is available?</li>
</ul>
</section>
<section id="learning-types" class="level2">
<h2 data-anchor-id="learning-types">Learning types</h2>
<p>Describe the differences between supervised, unsupervised, and reinforcement learning.</p>
</section>
<section id="ockhams-razor-1" class="level2">
<h2 data-anchor-id="ockhams-razor-1">Ockham‚Äôs razor</h2>
<p>In your own words, explain to us what Ockham‚Äôs razor is. Find an example that you can use to enrich your explanation of the concept.</p>
</section>
<section id="ml-concepts" class="level2">
<h2 data-anchor-id="ml-concepts">ML concepts</h2>
<p>Define the following machine-learning terms in your own words</p>
<ol type="a">
<li>Inductive learning</li>
<li>Training set</li>
<li>Hypothesis</li>
<li>Bias</li>
<li>Variance</li>
<li>Curve fitting</li>
</ol>
</section>
<section id="qualification-problem" class="level2">
<h2 data-anchor-id="qualification-problem">Qualification problem</h2>
<p>Draw a decision tree for the problem of deciding whether to move forward at a road intersection, given that the light has just turned green.</p>
<p>What problems do you see? Argue based on the qualification problem discussed in <a href="../6/#motivation">chapter probability</a>.</p>
<p>Generalize your findings and describe for which kind of problems decision trees are not suitable.</p>
</section>
</section>
<section id="literature" class="level1">
<h1>Literature</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-mitchel1997machine" class="csl-entry" role="listitem">
Mitchel, T. (1997). <em>Machine learning (mcgraw-hill international edit).</em> McGraw-Hill Education. <a href="https://books.google.de/books?id=dMp2uwEACAAJ">https://books.google.de/books?id=dMp2uwEACAAJ</a>
</div>
<div id="ref-RusselNorvig2022AIMA" class="csl-entry" role="listitem">
Russel, S., &amp; Norvig, P. (2022). <em>Artificial intelligence: A modern approach</em>. Pearson Education.
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Examples for Goodhart‚Äôs Law in ML: A recommendation system optimized solely for clicks might discover that clickbait titles and thumbnails maximize this metric, even if the content quality suffers and user satisfaction decreases long-term. If a content filter is optimized only to minimize false negatives (letting harmful content through), it might become overly restrictive and block large amounts of legitimate content.<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>To illustrate the curse of dimensionality: imagine a unit hypercube (with sides of length 1) in different dimensions. In 2D, it has area 1. In 3D, volume 1. In 100D, to capture just 1% of the hypercube‚Äôs volume, you‚Äôd need to extend 0.955 units along each dimension ‚Äî meaning 99% of the volume is in the ‚Äúcorners.‚Äù This explains why data points become increasingly distant from each other and distance metrics become less useful as dimensions increase.] When implementing unsupervised methods, success depends on careful feature selection, appropriate distance metrics, and clear alignment with the underlying questions you‚Äôre trying to answer.<a href="#fnref2" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn3"><p>Lift measures how much more likely the consequent (Y) is when the antecedent (X) is present, compared to when the antecedent is absent.</p>
<p><span class="math display">\[\text{Lift}(X \rightarrow Y) = \frac{\text{Confidence}(X \rightarrow Y)}{\text{Support}(Y)}\]</span></p>
<p>Where:</p>
<p><span class="math display">\[\text{Confidence}(X \rightarrow Y) = \frac{\text{Support}(X \text{ and } Y)}{\text{Support}(X)}\]</span> <span class="math display">\[\text{Support}(Y) = \frac{\text{Count}(Y)}{\text{Total Transactions}}\]</span></p>
<p>Interpretation:<br>
Lift &gt; 1: Positive correlation (products appear together more than expected by chance)<br>
Lift = 1: No correlation (independence)<br>
Lift &lt; 1: Negative correlation (products appear together less than expected by chance)<a href="#fnref3" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn4"><p>Example for reward hackin:, a reinforcement learning agent tasked with playing a video game might discover an unintended bug that produces high scores without completing the actual objective. Rather than learning the intended gameplay strategy, it optimizes for exploiting this glitch.<a href="#fnref4" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/awe-hnu\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2025, Andy Weeger
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../../index.html">
<p>Start</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://www.hnu.de" target="_blank">
<p>HNU</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../../imprint.html">
<p>Imprint</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>