<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andy Weeger">
<meta name="dcterms.date" content="2023-01-01">

<title>awe.lectures - Games</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../../../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta property="og:title" content="awe.lectures - Games">
<meta property="og:description" content="üß† Introduction to AI ‚Äî I2AI_4">
<meta property="og:image" content="https://awe-hnu.github.io/lectures/I2AI/22ST/4/images/adversarial-game-tree.svg">
<meta property="og:site-name" content="awe.lectures">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">awe:lectures</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Games</h1>
            <p class="subtitle lead">üß† Introduction to AI ‚Äî I2AI_4</p>
                      </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Organisation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author">Andy Weeger </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Applied Sciences Neu-Ulm
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 1, 2023</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">May 23, 2023</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#competitive-environments" id="toc-competitive-environments" class="nav-link active" data-scroll-target="#competitive-environments">Competitive environments</a></li>
  <li><a href="#minimax-search" id="toc-minimax-search" class="nav-link" data-scroll-target="#minimax-search">Minimax search</a></li>
  <li><a href="#monte-carlo-tree-search" id="toc-monte-carlo-tree-search" class="nav-link" data-scroll-target="#monte-carlo-tree-search">Monte Carlo tree search</a></li>
  <li><a href="#wrap-up" id="toc-wrap-up" class="nav-link" data-scroll-target="#wrap-up">Wrap-up</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">‚úèÔ∏è Exercises</a></li>
  <li><a href="#literature" id="toc-literature" class="nav-link" data-scroll-target="#literature">Literature</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="slides.html"><i class="bi bi-file-slides"></i>RevealJS (presentation)</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-page-left" id="quarto-document-content">




<section id="competitive-environments" class="level1 vertical-center page-columns page-full" data-background-color="#0333ff" data-background-image="images/bg.jpeg">
<h1 class="vertical-center" data-background-color="#0333ff" data-background-image="images/bg.jpeg">Competitive environments</h1>
<section id="playful-superiority" class="level2 unlisted html-hidden" data-background-color="#0333ff" data-background-image="images/alphaGo.jpeg">
<h2 class="unlisted html-hidden" data-background-color="#0333ff" data-background-image="images/alphaGo.jpeg" data-anchor-id="playful-superiority">Playful superiority</h2>
</section>
<section id="adversarial-search" class="level2">
<h2 data-anchor-id="adversarial-search">Adversarial search</h2>
<p>In <strong>competitive</strong> environments, two or more agents have conflicting goals.</p>
<div class="fragment">
<p>This gives rise to <strong>adversarial search</strong> problems.</p>
</div>
<div class="fragment">
<p>The AI community is particularly interested in games of a simplified nature (e.g., chess, go, and poker).</p>
</div>
<div class="incremental">
<ul class="incremental">
<li>State of a game is easy to represent</li>
<li>Agents are restricted to a few actions</li>
<li>Effects of actions are defined by precise rules</li>
</ul>
</div>
</section>
<section id="deterministic-games" class="level2 page-columns page-full">
<h2 data-anchor-id="deterministic-games">Deterministic games</h2>
<p class="page-columns page-full">The games most commonly studied within AI are deterministic <em class="page-columns page-full">(two-player, turn-taking, fully observable, zero-sum<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>)<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Means that what is good for one player is just as bad for the other: there is no ‚Äúwin-win‚Äù outcome</p></li></div></em> <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 192</a>)</span>.</p>
<div class="fragment page-columns page-full">
<p><strong>Possible formalization</strong></p>
<div class="incremental page-columns page-full">
<ul class="incremental">
<li><strong>States</strong>: <span class="math inline">\(S\)</span> (start at <span class="math inline">\(S_0\)</span>)</li>
<li><strong>Player</strong>: <span class="math inline">\(TO-MOVE(s)\)</span> (defines which player has the move in state <span class="math inline">\(s\)</span>)</li>
<li><strong>Actions</strong>: <span class="math inline">\(ACTIONS(s)\)</span> (the set of legal moves in state <span class="math inline">\(s\)</span>)</li>
<li><strong>Transition model</strong>: <span class="math inline">\(RESULT(s,a)\)</span> (defines the state resulting from action <span class="math inline">\(a\)</span> in state <span class="math inline">\(s\)</span>)</li>
<li><strong>Terminal test</strong>: <span class="math inline">\(IS-TERMINAL(s)\)</span> (is true when the game is over<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>)</li>
<li><strong>Utility function</strong>: <span class="math inline">\(UTILITY(s,p)\)</span> (defines the final numeric value to player <span class="math inline">\(p\)</span> when the game ends in terminal state <span class="math inline">\(s\)</span>)</li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;States where the game has ended are called <strong>terminal states</strong></p></li></div></div>
</div>
<div class="notes">
<p>The initial state, <span class="math inline">\(ACTIONS(s)\)</span>, and <span class="math inline">\(RESULT(s,a)\)</span> define the <strong>state space graph</strong>, where the vertices are states, the edges are moves and the state might be reached by multiple paths.</p>
</div>
</section>
<section id="optimal-decisions" class="level2 page-columns page-full">
<h2 data-anchor-id="optimal-decisions">Optimal decisions</h2>
<p>Players (here <code>MIN</code> and <code>MAX</code>, alternate turns) need to have a conditional plan‚Äîa contingent strategy specifying a response to each move of the opponent.</p>
<div class="incremental page-columns page-full">
<ul class="incremental">
<li>For games with binary outcomes (win or lose), <em>AND-OR</em><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> search tree can be used<br>
<span class="citation" data-cites="RusselNorvig2022AIMA">(see <a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 143</a>)</span></li>
<li>For games with multiple outcome scores, the <strong>minimax search</strong> algorithm is used</li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;The search tree consists of <em>AND nodes</em> and <em>OR nodes</em>. AND nodes reflect the environment‚Äôs choice of action (which all need to be considers), OR nodes the agent‚Äôs own choices in each state (where only one needs to be considered). AND and OR nodes alternate. A solution is a conditional plan that considers every nondeterministic outcome and makes a plan for each one.</p></li></div></div>
</section>
</section>
<section id="minimax-search" class="level1 vertical-center" data-background-color="#0333ff" data-background-image="images/bg.jpeg">
<h1 class="vertical-center" data-background-color="#0333ff" data-background-image="images/bg.jpeg">Minimax search</h1>
<section id="minimax-value" class="level2">
<h2 data-anchor-id="minimax-value">Minimax value</h2>
<p>Given a state-space search tree, each node‚Äôs <strong>minimax value</strong> is calculated.</p>
<div class="fragment">
<p>The minimax value is the best achievable utility of being in a given sate (against a rational adversary).</p>
<div class="incremental">
<ul class="incremental">
<li><code>MAX</code> prefers to move to a state of maximum value<br>
</li>
<li><code>MIN</code> prefers to move to a state of minimum value<br>
</li>
</ul>
</div>
</div>
</section>
<section id="adversarial-game-tree" class="level2">
<h2 data-anchor-id="adversarial-game-tree">Adversarial game tree</h2>
<div id="fig-adversarial-game-tree" class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="images/adversarial-game-tree.svg" class="lightbox" title="Example: A adversarial game tree; based on @RusselNorvig2022AIMA [p.195]" data-gallery="quarto-lightbox-gallery-1"><img src="images/adversarial-game-tree.svg" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">Figure&nbsp;1: Example: A adversarial game tree; based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 195</a>)</span></figcaption>
</figure>
</div>
<div class="notes">
<p>The ‚ñ≥ nodes are ‚Äú<em>MAX</em> nodes‚Äù, in which it is <em>MAX‚Äôs</em> turn to move; the ‚ñΩ nodes are ‚Äú<em>MIN</em> nodes‚Äù. <em>MAX‚Äôs</em> best move at the root is Œ±‚ÇÅ (the highest minimax value), <em>MIN‚Äôs</em> best move is Œ≤‚ÇÅ (the lowest minimax value).</p>
</div>
</section>
<section id="minimax-search-algorithm" class="level2">
<h2 data-anchor-id="minimax-search-algorithm">Minimax search algorithm</h2>
<p>The <strong>minimax algorithm</strong> performs a complete depth-first exploration of the game tree <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 196‚Äì96</a>)</span>.</p>
<div class="incremental">
<ul class="incremental">
<li>Assumes that the adversary plays optimal</li>
<li>Returns action whose terminal state has the optimal <span class="math inline">\(MINIMAX\)</span> value
<ul class="incremental">
<li>If the state is a terminal state (<span class="math inline">\(IS-TERMINAL(s) = true\)</span>):<br>
return the state‚Äôs utility (<span class="math inline">\(UTILITY(s,p)\)</span>)</li>
<li>If the next agent is <span class="math inline">\(MAX\)</span> (<span class="math inline">\(TO-MOVE(s) = MAX\)</span>): return <span class="math inline">\(MAX-VALUE(s)\)</span></li>
<li>If the next agent is <span class="math inline">\(MIN\)</span> (<span class="math inline">\(TO-MOVE(s) = MIN\)</span>): return <span class="math inline">\(MIN-VALUE(s)\)</span></li>
</ul></li>
</ul>
</div>
<div class="fragment">
<p>The exponential complexity makes the miminmax algorithm impractical for complex games (even with alpha-beta pruning applied; chess game tree size &gt; atoms in the universe).</p>
</div>
<div class="notes">
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pruning to reduce computing complexity <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 198‚Äì99</a>)</span>.
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pruning stops the search at the moment when it is determined that the value of a subtree is worse than the best solution already identified.</p>
<p>The general principle is as follows: consider a node <em>n</em> somewhere in the tree, such that Player has a choice of moving to <em>n</em>. If Player has a better choice either at the same level or at any point higher up in the tree, then Player will never move to <em>n</em>. So enough about <em>n</em> is found out (by examining some of its descendants) to reach this conclusion, it can be pruned <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 198</a>)</span>.</p>
<p>Alpha-beta pruning gets its name from the two extra parameters in <em>MAX-VALUE(state,Œ±,Œ≤)</em> that describe the bounds on the backed-up values that appear anywhere along the path:</p>
<ul>
<li>Œ± = the value of the best choice for <code>MAX</code> found so far (‚Äúat least‚Äù)</li>
<li>Œ≤ = the value of the bast choice for <code>MIN</code> found so far (‚Äúat most‚Äù)</li>
</ul>
<p>Alpha-beta search updates the values of Œ± and Œ≤ as it goes along and prunes the remaining branches at a node as soon as the value of the current node is known to be worse than the current Œ± and Œ≤ for <code>MAX</code> or <code>MIN</code>, respectively.</p>
</div>
</div>
</div>
</section>
</section>
<section id="monte-carlo-tree-search" class="level1 page-columns page-full">
<h1>Monte Carlo tree search</h1>
<div class="page-columns page-full"><p><strong>Monte Carlo tree search</strong> (MCTS) does estimate the value of a state as the <strong>average utility</strong><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> over a number of simulations of complete games starting from the current state <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 207‚Äì9</a>)</span>.</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;guided by the <strong>selection policy</strong></p></li></div></div>
<div class="fragment page-columns page-full">
<p>Each iteration follows four steps:</p>
<div class="incremental page-columns page-full">
<ul class="incremental">
<li><strong>Selection</strong> (choosing a move<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, leading to a successor node, and repeat that process, moving down the tree to a leaf)</li>
<li><strong>Expansion</strong> (one to several new children are created for the selected node)</li>
<li><strong>Simulation</strong> (a simulation for the newly generated child node is performed)</li>
<li><strong>Back-propagation</strong> (the result of the simulation is used to update all the search tree nodes going up to the root)</li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;For games with binary outcomes, <strong>average utility</strong> equals <em>win percentage</em></p></li></div></div>
</div>
<div class="fragment">
<p>Repeats for a set number of iterations or until a given time is over. At the end the successor with the hightest utily is chosen.</p>
</div>
<section id="selection" class="level2">
<h2 data-anchor-id="selection">Selection</h2>
<div class="columns">
<div class="column">
<div id="fig-mcts-selection" class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="images/mcts-selection.svg" class="lightbox" title="Example: MCTS ‚Äî selection; based on @RusselNorvig2022AIMA [p.208]" data-gallery="quarto-lightbox-gallery-2"><img src="images/mcts-selection.svg" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">Figure&nbsp;2: Example: MCTS ‚Äî selection; based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 208</a>)</span></figcaption>
</figure>
</div>
</div><div class="column">
<div class="fragment">
<p><a href="#fig-mcts-selection">Figure&nbsp;2</a> shows a tree with the root representing a state where <code>P-A</code> has won 37/100 playouts done</p>
<div class="incremental">
<ul class="incremental">
<li><code>P-A</code> has just moved to the root node</li>
<li><code>P-B</code> selects a move to a node where it has won 60/79 playouts; this is the best win percentage among the available moves</li>
<li><code>P-A</code> will select a move to a node where it has won 16/53 playouts (assuming it plays optimally)</li>
<li><code>P-B</code> then continues on the leeaf node marked 27/35</li>
<li>‚Ä¶ until a terminal state is reached</li>
</ul>
</div>
</div>
</div>
</div>
<div class="notes">
<p>It would also have been reasonable to select the 2/11 node for the sake of exploration‚Äîwith only 11 playouts, the node still has high uncertainty in its valuation, and might end up being the best option if more information about it is gained. So it makes sense to use a selection policy that balances exploitation and exploration.</p>
</div>
</section>
<section id="selection-policy-example" class="level2 page-columns page-full">
<h2 data-anchor-id="selection-policy-example">Selection policy example</h2>
<p><strong>Upper confidence bounds applied to trees</strong> (UCT) is a very effective selection policy ranking possible moves based on an upper confidence bound formula (UCB1)</p>
<div class="fragment">
<p><span class="math display">\[
UCB1(n) = \frac{U(n)}{N(n)} + C * \sqrt{\frac{\log{N(PARENT(n))}}{N(n)}}
\]</span></p>
<div class="incremental">
<ul class="incremental">
<li><span class="math inline">\(U(n)\)</span> is the total utility of all playouts that went through node <span class="math inline">\(n\)</span></li>
<li><span class="math inline">\(N(n)\)</span> is the number of playouts through node <span class="math inline">\(n\)</span></li>
<li><span class="math inline">\(PARENT(n)\)</span> is the parent node of <span class="math inline">\(n\)</span> in the tree</li>
<li><span class="math inline">\(\frac{U(n)}{N(n)}\)</span> is the average utility of <span class="math inline">\(n\)</span> <em>(exploitation term, ‚Äúhow good are the stats?‚Äù)</em></li>
<li><span class="math inline">\(\frac{\log{N(PARENT(n))}}{N(n)}\)</span> is higher for <span class="math inline">\(n\)</span> only explored a few times<br>
<em>(exploration term, ‚Äúhow much has the child be ‚Äòignored‚Äô?‚Äù)</em></li>
<li><span class="math inline">\(C\)</span> is a constant that balance exploitation and exploration (theoretically <span class="math inline">\(\sqrt{2}\)</span>)</li>
</ul>
</div>
</div>
<div class="notes page-columns page-full">
<p>With <span class="math inline">\(C=1.4\)</span>, the 60/79 node in <a href="#fig-mcts-selection">Figure&nbsp;2</a> has the highest UCB1 score, but with <span class="math inline">\(C=1.5\)</span>, it would be the 2/11 node.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Utiliy of MCTS
</div>
</div>
<div class="callout-body-container callout-body">
<p>The conventional wisdom has been that Monte Carlo search has an advantage over heuristic alpha-beta tree search (not discussed here, see <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">Russel and Norvig 2022, 202ff</a>)</span>) for games where the branching factor is very high (and thus alpha-beta can‚Äôt search deep enough), or when it is difficult to define a good evaluation function <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
</div>
</div>
<div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;A heuristic evaluation function returns an estimate of the expected utility of state <span class="math inline">\(s\)</span> to player <span class="math inline">\(p\)</span>.</p></li></div></div>
</section>
<section id="expansion-and-simulation" class="level2 page-columns page-full">
<h2 data-anchor-id="expansion-and-simulation">Expansion and simulation</h2>
<div class="columns page-columns page-full">
<div class="column">
<div id="fig-mcts-expansion" class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="images/mcts-expansion-simulation.svg" class="lightbox" title="Example: MCTS ‚Äî expansion and simulation; based on @RusselNorvig2022AIMA [p.208]" data-gallery="quarto-lightbox-gallery-3"><img src="images/mcts-expansion-simulation.svg" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">Figure&nbsp;3: Example: MCTS ‚Äî expansion and simulation; based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 208</a>)</span></figcaption>
</figure>
</div>
</div><div class="column page-columns page-full">
<div class="fragment">
<p><a href="#fig-mcts-expansion">Figure&nbsp;3</a> shows a tree where a new child of the selected node is generated and marked with <code>0/0</code> <em>(expansion)</em>.</p>
</div>
<div class="fragment page-columns page-full">
<p>A playout for the newly generated child node is performed <em>(simulation)</em>.</p>
<div class="incremental page-columns page-full">
<ul class="incremental">
<li>Moves for both players according the playout policy<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> are chosen</li>
<li>The moves are not recorded in the search tree</li>
<li>In <a href="#fig-mcts-expansion">Figure&nbsp;3</a>, the simulation results in a win for <code>P-B</code></li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn7"><p><sup>7</sup>&nbsp;Playout policies biases the moves toward good ones. For Go and other games, playout policies have been successfully learned from self-play by using neural networks. Sometimes also game-specific heuristics are used (e.g., take the corner square in Othello)</p></li></div></div>
</div>
</div>
</div>
</section>
<section id="back-propagation" class="level2">
<h2 data-anchor-id="back-propagation">Back-propagation</h2>
<div class="columns">
<div class="column">
<div id="fig-mcts-propagation" class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="images/mcts-back-propagation.svg" class="lightbox" title="Example: MCTS ‚Äî selection; based on @RusselNorvig2022AIMA [p.208]" data-gallery="quarto-lightbox-gallery-4"><img src="images/mcts-back-propagation.svg" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">Figure&nbsp;4: Example: MCTS ‚Äî selection; based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022, 208</a>)</span></figcaption>
</figure>
</div>
</div><div class="column">
<div class="fragment">
<p>The result of the simulation is used to update all the search tree nodes going up to the root.</p>
<div class="incremental">
<ul class="incremental">
<li><code>P-B's</code> nodes are incremented in both the number of wins and the number of playouts</li>
<li><code>P-A's</code> nodes are incremented in the number of playouts only</li>
</ul>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="wrap-up" class="level1 vertical-center" data-background-color="#0333ff" data-background-image="images/bg.jpeg">
<h1 class="vertical-center" data-background-color="#0333ff" data-background-image="images/bg.jpeg">Wrap-up</h1>
<section id="summary" class="level2">
<h2 data-anchor-id="summary">Summary</h2>
<div class="incremental">
<ul class="incremental">
<li>In two-player, discrete, deterministic, turn-taking zero-sum games with perfect information, the <strong>minimax algorithm</strong> can select optimal moves by a depth-first search in the game tree</li>
<li>Efficiency can be improved by using the <strong>alpha-beta</strong> search algorithm, which eliminates subtrees that are shown to be irrelevant.</li>
<li><strong>Monte Carlo tree search</strong> evaluates states by playing out the game all the way to the end to see who won. This playout <strong>simulation</strong> is repeated multiple times. The evaluation is an average of the results.</li>
</ul>
</div>
</section>
<section id="xkcd" class="level2">
<h2 data-anchor-id="xkcd">xkcd</h2>
<div id="fig-xkcd" class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="images/xkcd.png" class="lightbox" title="xkcd 1263: reassuring" data-gallery="quarto-lightbox-gallery-5"><img src="images/xkcd.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">Figure&nbsp;5: xkcd 1263: reassuring</figcaption>
</figure>
</div>
</section>
</section>
<section id="exercises" class="level1 vertical-center" data-background-color="#0333ff" data-background-image="images/bg.jpeg">
<h1 class="vertical-center" data-background-color="#0333ff" data-background-image="images/bg.jpeg">‚úèÔ∏è Exercises</h1>
<section id="i2ai_4-e1" class="level2">
<h2 data-anchor-id="i2ai_4-e1">I2AI_4 E1</h2>
<p>Explain in your own words the following terms:</p>
<ul>
<li>Zero-sum</li>
<li>Terminal test</li>
<li>Minimax value</li>
<li>Selection policy</li>
<li>Playout policy</li>
<li>Monte Carlo tree</li>
<li>Back-propagation</li>
</ul>
</section>
<section id="i2ai_4-e2" class="level2">
<h2 data-anchor-id="i2ai_4-e2">I2AI_4 E2</h2>
<p>Explain if the <code>MINIMAX</code> algorithm is complete and optimal.</p>
<p>Can it be beaten by an opponent playing suboptimally? Why (not)?</p>
<p>Come up with a game tree in which MAX will beat a suboptimal MIN.</p>
<section id="solution-notes" class="level3">
<h3 data-anchor-id="solution-notes">Solution notes</h3>
<section id="completeness" class="level4">
<h4 data-anchor-id="completeness">Completeness</h4>
<p>Explain if the <code>MINIMAX</code> algorithm is complete and optimal.</p>
<p>In two-player, discrete, deterministic, turn-taking zero-sum gamges with perfect information, the <code>MINIMAX</code> algorithm can select optimal moves by a depth-first emuration, the algorithm is also guaranteed to find a solution when there is one.</p>
<p>The algorithm performas a complete depth-first exploration of the game tree. If the maximum depth of the tree is <span class="math inline">\(m\)</span> and there are <span class="math inline">\(b\)</span> legal moves at each point, then the time complexity is <span class="math inline">\(O(b^m)\)</span> for an algorithm that generates all actions at once, or <span class="math inline">\(O(m)\)</span> for an algorithm that generates actions on at a time. The exponential complexity makes <code>MINIMAX</code> impractical for complex games. <code>MINIMAX</code> does, however, serve as a basis for the mathematical analysis for games. By approximating the minimax analysis in various ways, we can derive more practical algorithms.</p>
</section>
<section id="suboptimally-play" class="level4">
<h4 data-anchor-id="suboptimally-play">Suboptimally play</h4>
<p>Can it be beaten by an opponent playing suboptimally? Why (not)?</p>
<p>If <em>MIN</em> does not play optimally, then <em>MAX</em> will do at least as well as against an optimal player, possibly better.</p>
</section>
</section>
</section>
<section id="i2ai_4-e3" class="level2">
<h2 data-anchor-id="i2ai_4-e3">I2AI_4 E3</h2>
<p>Read the note about pruning (and consult <span class="citation" data-cites="RusselNorvig2022AIMA">Russel and Norvig (<a href="#ref-RusselNorvig2022AIMA" role="doc-biblioref">2022</a>)</span> if necessary).</p>
<p>Explain in your own words, under what conditions a subtree is skipped using Alpha-beta pruning.</p>
<p>Draw an example (game search tree, 3 levels depth).</p>
</section>
</section>
<section id="literature" class="level1">
<h1>Literature</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-RusselNorvig2022AIMA" class="csl-entry" role="listitem">
Russel, Stuart, and Peter Norvig. 2022. <em>Artificial Intelligence: A Modern Approach</em>. Harlow: Pearson Education.
</div>
</div>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/awe-hnu\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"descPosition":"bottom","closeEffect":"zoom","loop":true,"selector":".lightbox","openEffect":"zoom"});</script>



</body></html>