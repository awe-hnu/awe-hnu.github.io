<!DOCTYPE html>
<html lang="en"><head>
<link href="../../../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Andy Weeger">
  <meta name="dcterms.date" content="2025-03-12">
  <title>awe.lectures – Environments &amp; Agents</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/theme/quarto-38905d13cb9cc007a76808dad09f60e2.css">
  
  <script type="text/javascript" charset="UTF-8">
  document.addEventListener('DOMContentLoaded', function () {
  cookieconsent.run({
    "notice_banner_type":"interstitial",
    "consent_type":"express",
    "palette":"dark",
    "language":"en",
    "page_load_consent_levels":["strictly-necessary"],
    "notice_banner_reject_button_hide":false,
    "preferences_center_close_button_hide":false,
    "website_name":""
    ,
  "language":"en"
    });
  });
  </script> 
    
  <link href="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Environments &amp; Agents – awe.lectures">
<meta property="og:description" content="Introduction to AI (I2AI)">
<meta property="og:site_name" content="awe.lectures">
</head>
<body class="quarto-light">
<div class="footer custom">

    <div class="version">
        V1.2
    </div>

    <div class="footnote">
        Andy Weeger / Neu-Ulm University of Applied Sciences Neu-Ulm / Introduction to Artificial Intelligence (AI)
   </div>

    <div class="logo">
        <svg viewbox="0 0 125 39" xmlns="http://www.w3.org/2000/svg" version="1.1" space="preserve">
            <g>
             <title>HNU</title>
             <path d="m8.58222,0l7.5,0l0,12.7l-7.5,0l0,-12.7zm7.4,24.1l6.5,0l0,-3l-13.9,0l0,15.4l-3.9,0l0,2.3l11.3,0l0,-14.7zm24,-24.1l-7.4,0l0,36.5l-3.9,0l0,2.3l11.3,0l0,-38.8zm60.2,28.4c1.1,0 2.1,-0.1 2.9,-0.4c-1.3,-1.2 -1.9,-3.2 -1.9,-6.4l0,-21.6l-7.4,0l0,19.3c0,5.9 1.5,9.1 6.4,9.1z" id="svg_1"></path>
             <path d="m96.78222,37c2.8,1.6 6.4,2.5 10.6,2.5c11.2,0 17.7,-6 17.7,-16.3l0,-23.2l-7.4,0l0,21.1c0,11.3 -7.7,16.1 -17.6,16.1c-1.1,0 -2.2,-0.1 -3.3,-0.2zm-30.8,-27l-7.1,-10l-7.3,0l14.4,20.4l0,-10.4zm17,28.8l0,-38.8l-7.5,0l0,36.5l-3.5,0l1.7,2.3l9.3,0zm-24,-14.8l-8,-10.8l0,23.3l-3,0l0,2.3l11,0l0,-14.8z" id="svg_2"></path>
            </g>   
        </svg>
    </div>

</div>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#0333ff" data-background-image="../assets/bg.jpeg" data-background-opacity="1" data-background-size="cover" class="quarto-title-block">
  <h1 class="title">Environments &amp; Agents</h1>
  <p class="subtitle">Introduction to AI (I2AI)</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Andy Weeger 
</div>
        <p class="quarto-title-affiliation">
            Neu-Ulm University of Applied Sciences
          </p>
    </div>
</div>

  <p class="date">March 12, 2025</p>
</section>
<section>
<section id="agents" class="title-slide slide level1 headline-only">
<h1>Agents</h1>

</section>
<section id="rational-agents" class="title-slide slide level2">
<h2>Rational agents</h2>
<div id="fig-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/actor.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Rational agents interact with environments through sensors and actuators
</figcaption>
</figure>
</div>
<aside class="notes">
<p>A rational agent is anything that is</p>
<ul>
<li>perceiving its environment through <strong>sensors</strong>,</li>
<li>thinking and deciding on the next actions<br>
(mapping given percepts to actions),</li>
<li>and acting through <strong>actuators</strong></li>
</ul>
<p>Rational means, that the agent acts in a way that is expected to maximize its performance measure, given it’s</p>
<ul>
<li>built-in knowledge (i.e., the agent function<a href="#/footnotes" class="footnote-ref" id="fnref1" role="doc-noteref" data-footnote-href="#/fn1" onclick=""><sup>1</sup></a>),</li>
<li>perceived experience (i.e., the percep sequence<a href="#/footnotes" class="footnote-ref" id="fnref2" role="doc-noteref" data-footnote-href="#/fn2" onclick=""><sup>2</sup></a>),</li>
<li>and acting capabilities</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>A robotic vacuum cleaner moves around a grid of squares, some of which are dirty and some of which are clean. The vacuum cleaner <em>perceives</em> where it is and if there is dirt there. It’s <em>actions</em> are move to the right or left, suck up the dirt, or do nothing. The <em>agent function</em> prescribes that if the current square is dirty, it should suck up the dirt; otherwise, it should move to the other square.</p>
<p>Under following circumstances, the vacuum cleaning agent is rational <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022</a>)</span>:</p>
<ul>
<li>The <em>performance measure</em> of the vacuum cleaner awards one point for each clean square at each time step</li>
<li>The only available actions are <em>right</em>, <em>left</em>, and <em>suck</em>.</li>
<li>The “geography” of the environment is known <em>a priori</em> but the dirt distribution and the initial location of the agent are not. Clean squares stay clean and sucking cleans the current square.</li>
<li>The <em>right</em> and <em>left</em> actions move the agent one square except when this would take the agent outside the environment. Then it remains where it is.</li>
<li>The robot correctly perceives its location and whether the square is dirty.</li>
</ul>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside></aside></section>

<section id="exercise" class="title-slide slide level2 html-hidden unlisted discussion-slide">
<h2>Exercise</h2>
<div class="large">
<p>Under which circumstances does a <strong>vacuum cleaning agent</strong> act rational?</p>
</div>
</section>

<section id="performance-measure" class="title-slide slide level2">
<h2>Performance measure</h2>
<blockquote>
<p>If we use, to achieve our purposes, a mechanical agency with those operation we cannot interfere once we have started it […] we had better be quite sure that the purpose built into the machine is the purpose which we really desire <em><span class="citation" data-cites="Wiener1960Some">Wiener (<a href="#/literature" role="doc-biblioref" onclick="">1960, p. 1358</a>)</span></em></p>
</blockquote>
<div class="fragment">
<div class="medium">
<p>It is difficult to formulate a performance measure correctly.<br>
<strong>This is a reason to be careful.</strong></p>
</div>
</div>
</section>

<section id="rationality-vs.-perfection" class="title-slide slide level2">
<h2>Rationality vs.&nbsp;perfection</h2>
<div class="large">
<p>Rationality is not the same as perfection.</p>
</div>
<ul>
<li class="fragment">Rationality maximizes <em>expected</em> performance.</li>
<li class="fragment">Perfection maximizes <em>actual</em> performance.</li>
<li class="fragment">Perfection requires omniscience.</li>
<li class="fragment">Rational choice depends only on the percept sequence <em>to date</em>.</li>
</ul>
<aside class="notes">
<p>As the environment is usually not completely known <em>a priori</em> and completely predictable (or stable), information gathering and learning are important parts of rationality <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 59</a>)</span>.</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>The vacuum cleaner needs to explore an initially unknown environment (i.e., exploration) to maximize its expected performance. In addition, a vacuum cleaner that learns to predict where and when additional dirt will appear will do better than one that does not.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section>
<section id="environments" class="title-slide slide level1 headline-only">
<h1>Environments</h1>

</section>
<section id="components" class="title-slide slide level2">
<h2>Components</h2>
<p>Before designing an agent (i.e., <em>the solution</em>), the task environment (i.e., <em>the problem</em>) must be specified as fully as possible, including</p>
<div class="medium">
<ul>
<li class="fragment">the <strong>p</strong>erformance measure,</li>
<li class="fragment">the <strong>e</strong>nvironment,</li>
<li class="fragment">the <strong>a</strong>ctuators, and</li>
<li class="fragment">the <strong>s</strong>ensors</li>
</ul>
</div>
<div class="fragment">
<p><span class="smaller"><span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022</a>)</span> uses the short form PEAS to describe these parts of the task environment.</span></p>
<aside class="notes">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example of an PEAS description</strong></p>
</div>
<div class="callout-content">
<p>Task environment of a taxi driver agent:</p>
<ul>
<li><strong>P</strong>: Safe, fast, legal, comfortable, maximize profits, minimize impact on other road users</li>
<li><strong>E</strong>: Roads, other road users, police, pedestrians, customers, weather</li>
<li><strong>A</strong>: Steering, accelerator, brake, signal horn, display, speech</li>
<li><strong>S</strong>: Cameras, radar, speedometer, GPS, engine, sensors, accelerometer, microphones, touchscreen</li>
</ul>
<p>Source: <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022, p. 61</a>)</span></p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>

<section id="properties" class="title-slide slide level2">
<h2>Properties</h2>
<p>Task environments can be categorized along following dimensions:</p>
<div class="hmtl-hidden">
<ul>
<li class="fragment">Fully observable ↔︎ partially observable</li>
<li class="fragment">Single agent ↔︎ multi-agent</li>
<li class="fragment">Deterministic ↔︎ nondeterministic</li>
<li class="fragment">Episodic ↔︎ sequential</li>
<li class="fragment">Static ↔︎ dynamic</li>
<li class="fragment">Discrete ↔︎ continuous</li>
<li class="fragment">Known ↔︎ unknown</li>
</ul>
</div>
<aside class="notes">
<dl>
<dt>Fully observable ↔︎ partially observable</dt>
<dd>
In a <em>fully observable</em> task environment, the agent has access to the complete state of the environment at all times. There is no hidden information, and the agent can make decisions based on full knowledge of the current state (e.g., chess). In a partially observable task environment, the agent does not have access to the complete state of the environment. Some information is hidden or uncertain, and the agent must make decisions based on incomplete or noisy data (e.g., poker).
</dd>
<dt>Single agent ↔︎ multi-agent</dt>
<dd>
In a <em>single-agent</em> task environment, there is only one agent interacting with the environment. The agent’s actions are solely based on its own goals and perceptions (e.g., crossword puzzles). In a multi-agent task environment, multiple agents interact with each other and the environment. The agents may cooperate, compete, or have mixed interactions.
</dd>
<dt>Deterministic ↔︎ nondeterministic</dt>
<dd>
When the environment is completely determined by the current state and the actions performed by the agent(s), it is called a <em>deterministic</em> environment (e.g., crossword puzzle). When a model of the environment explicitly uses probabilities, it is called a <em>stochastic</em> environment (e.g., poker).
</dd>
<dt>Episodic ↔︎ sequential</dt>
<dd>
In an <em>episodic</em> task environment, each task or episode is independent of the others. The agent’s actions in one episode do not affect future episodes (e.g., spam email filtering). In a sequential task environment, the current task is dependent on previous tasks. The agent’s actions have long-term consequences and affect future states (e.g., chess game).
</dd>
<dt>Static ↔︎ dynamic</dt>
<dd>
In a <em>static</em> task environment, the environment does not change while the agent is deliberating. The agent can take its time to make decisions without worrying about the environment changing (e.g., chess game). In a <em>dynamic</em> task environment, the environment can change while the agent is deliberating. The agent must account for changes and adapt its actions accordingly (e.g., stock-trading).
</dd>
<dt>Discrete ↔︎ continuous</dt>
<dd>
In a <em>discrete</em> task environment, the state space, actions, and time are all distinct and separate. The environment can be broken down into a finite number of states and actions. (e.g., chess). In a continuous task environment, the state space, actions, and time are continuous. The environment cannot be broken down into a finite number of states and actions (e.g., driving).
</dd>
<dt>Known ↔︎ unknown</dt>
<dd>
In a <em>known</em> task environment, the agent has complete information about the environment and the outcomes of its actions. The rules, states, and effects of actions are fully understood. (e.g., solitaire card game). In an <em>unknown</em> task environment, the agent lacks complete information about the environment or the outcomes of its actions. The agent must learn or infer the rules and effects through interaction.
</dd>
</dl>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<p>The hardest case is partially observable, multi-agent, nondeterministic, sequential, dynamic, and continuous <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, pp. 62–64</a>)</span>.</p>
</div>
</section>

<section id="exercise-1" class="title-slide slide level2 html-hidden unlisted discussion-slide">
<h2>Exercise</h2>
<div class="large">
<p>Describe the task environment of a <strong>taxi driver agent</strong>.</p>
</div>
</section>
</section>
<section>
<section id="agent-types" class="title-slide slide level1 headline-only">
<h1>Agent types</h1>

</section>
<section id="simple-reflex-agents" class="title-slide slide level2">
<h2>Simple reflex agents</h2>
<div id="fig-sr-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-sr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/simple-reflex-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: A simple reflex agent<a href="#/footnotes" class="footnote-ref" id="fnref3" role="doc-noteref" data-footnote-href="#/fn3" onclick=""><sup>3</sup></a>
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Simple reflex agents select actions on the basis of the <em>current</em> percept, ignoring the rest of the percept history. Thus, these agents work only if the correct decision can be made on the basis of just the current percept. The environment needs to be fully observable <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 68</a>)</span>.</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>A <strong>thermostat</strong> makes decisions based solely on the current temperature reading, without considering past temperatures or future predictions.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside></aside></section>

<section id="model-based-reflex-agents" class="title-slide slide level2">
<h2>Model-based reflex agents</h2>
<div id="fig-mr-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-mr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/model-based-reflex-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mr-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: A model-based reflex agent
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Model-based reflex agents maintain an internal models of the world, which helps them keep track of the current state and make decisions based on this model. This allows them to handle partially observable environments more effectively <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 70</a>)</span>.</p>
<ul>
<li>The <strong>transition model</strong> reflects how the world evolves (a) independently of the agent and (b) depending on the agent’s actions.</li>
<li>The <strong>sensor model</strong> reflects how the state of the world is reflected in the agent’s percepts (i.e., by its sensors).</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>A <strong>self-driving car</strong> uses its transition model to predict the state of the environment reflected in the sensor model and make decisions accordingly.</p>
</div>
</div>
</div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Types of representation of states</strong></p>
</div>
<div class="callout-content">
<p>The representations of states can be placed along an axis of increasing complexity and expressive power <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, pp. 76–77</a>)</span>:</p>
<ul>
<li>An <strong>atomic representation</strong> is one in which each state is treated as a black box with not internal structure, meaning the state either does or does not match what you’re looking for. In a sliding tile puzzle, for instance, you either have the correct alignment of tiles or you do not.</li>
<li>A <strong>factored representation</strong> is one in which the states are defined by set of features (e.g., Boolean, real-valued, or one of a fixed set of symbols). In a sliding puzzle, this might be a simple heuristic like “number of tiles out of place”.</li>
<li>A <strong>structured representation</strong> is one in which the states are expressed in form of objects and relations between them (e.g., expressed by logic or probability). Such knowledge about relations called facts.</li>
</ul>
<p>The more expressive language is much more concise, but makes reasoning and learning more complex.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="goal-based-agents" class="title-slide slide level2">
<h2>Goal-based agents</h2>
<div id="fig-gb-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-gb-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/goal-based-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gb-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: A model-based, goal-based agent
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Goal-based agents make decisions based on a set of goals they aim to achieve. They consider the current state, possible actions, and the outcomes of these actions to determine the best path to reach their goals <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 72</a>)</span>.</p>
<p>Goal-based agents often use search and planning algorithms to find the optimal sequence of actions to achieve their goals, best-case considering both immediate and long-term consequences.</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>A <strong>delivery robot</strong> is designed to navigate from a starting point to a destination within an environment, often avoiding obstacles and optimizing its route.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="utility-based-agents" class="title-slide slide level2">
<h2>Utility-based agents</h2>
<div id="fig-ub-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-ub-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/utility-based-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ub-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: A model-based, utility-based agent
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Utility-based agents make decisions by evaluating the utility (or value) of different possible actions and choosing the one that maximizes their overall utility. These agents consider not only the goals but also the trade-offs and preferences to achieve the best possible outcome <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 73</a>)</span>.</p>
<p>The <strong>utility function</strong> is a mathematical function that calculates <strong>expected utility</strong> for all possible states, weighted by the probability of the outcome. The agent evaluates the utility of different actions and selects the one that <strong>maximizes its expected utility</strong>.</p>
<p>A utility-based agent has many advantages in terms of flexibility and learning, which are particularly helpful in environments characterized by partial observability and nondeterminism. In addition, there are cases where the goals are insufficient but a utility-based agent can still make rational decisions based on the probabilities and the utilities of the outcomes:</p>
<ul>
<li>When there are conflicting goals, the utility function specifies the appropriate tradeoff.</li>
<li>Likelihood of success (i.e., goal achievement) can be weighed against the importance of the goals</li>
</ul>
<p>Model- and utility-based agents are difficult to implement. They need to model and keep track of the task environment, which requires ingenious sensors, sophisticated algorithms, and a high computational complexity. There are also utility-based agents that are not model-based. These agents just learn what action is best in a particular situation without any “understanding” of its impact on the environment (e.g., based on reinforcement learning).</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>A <strong>smart thermostat</strong> continuously evaluates the utility of different temperature settings and adjusts accordingly to maximize overall utility, balancing comfort and energy savings.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>


<section id="recap" class="title-slide slide level2 html-hidden unlisted discussion-slide">
<h2>Recap</h2>
<div class="large">
<p>What are the <strong>main differences</strong> between the agents?</p>
</div>
</section>

<section id="learning-agents" class="title-slide slide level2">
<h2>Learning agents</h2>
<div id="fig-l-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/learning-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: A learning agent
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Learning agents are AI systems designed to improve their performance over time by learning from their environment and experiences. Unlike traditional AI systems that operate with fixed programming, learning agents adapt, evolve, and refine their actions based on feedback and data. Thus, learning agents have greater <strong>autonony</strong>.</p>
<p>A learning agent consists of four conceptual components <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022</a>, p- 74-75)</span>, as shown in <a href="#/fig-l-agent" class="quarto-xref">Figure&nbsp;6</a>:</p>
<ul>
<li><strong>Learning element</strong>: Acquires knowledge and improves performance by analyzing data, interactions, and feedback. Uses techniques such as supervised, unsupervised, and reinforcement learning.</li>
<li><strong>Performance element</strong>: Executes tasks based on the knowledge acquired by the learning element.</li>
<li><strong>Performance standard</strong> or critic: Evaluates the actions taken by the performance element and provides feedback.</li>
<li><strong>Problem generator</strong>: Identifies opportunities for further learning and exploration. Exploratory actions may be suboptimal in the short term, but can lead to the discovery of better actions in the long term.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="on-rationality" class="title-slide slide level2">
<h2>On rationality</h2>
<div class="html-hidden">
<div class="large">
<p>A rational agent is one<br>
that does <strong>the right thing</strong>.</p>
</div>
</div>
<div class="fragment">
<p>Utility-based learning agents are rational agents as they act so as to achieve the best outcome or, when there is uncertainty, <strong>the best expected outcome</strong>. <span class="fragment">This means that for each possible percept sequence,</span> <span class="fragment">a rational agent should select an <strong>action</strong> that is expected to maximize its <strong>performance measure</strong>,</span> <span class="fragment">given the evidence provided by the <strong>percept sequence</strong></span> <span class="fragment">and whatever built-in <strong>knowledge</strong> the agent has,</span> <span class="fragment">which evolves over time <span class="citation" data-cites="RusselNorvig2022AIMA">(<a href="#/literature" role="doc-biblioref" onclick="">Russel &amp; Norvig, 2022, p. 58</a>)</span>.</span></p>
</div>
</section>

<section id="evolution-of-agents" class="title-slide slide level2">
<h2>Evolution of agents</h2>
<div class="html-hidden">
<div class="r-stack">
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/evolution-1.svg" height="420"></p>
<figcaption>The evolution of AI agents</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/evolution-2.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/evolution-3.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/evolution.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
</div>
</div>
<aside class="notes">
<div id="fig-evolution" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/evolution.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: The evolution of AI agents
</figcaption>
</figure>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section>
<section id="agentic-ai" class="title-slide slide level1 headline-only">
<h1>Agentic AI</h1>

</section>
<section id="definition" class="title-slide slide level2">
<h2>Definition</h2>
<div class="medium">
<blockquote>
<p>Agentic AI is an emerging paradigm in AI that refers to <strong>autonomous systems</strong> designed to pursue complex goals with <strong>minimal human intervention.</strong> <em><span class="citation" data-cites="acharya2025agentic">Acharya et al. (<a href="#/literature" role="doc-biblioref" onclick="">2025, p. 18912</a>)</span></em></p>
</blockquote>
</div>
<div class="fragment">
<p>Core characteristics of Agentic AI are</p>
<div class="html-hidden">
<ul>
<li class="fragment">higher autonomy and goal complexity,</li>
<li class="fragment">ability to adapt to environmental and situational unpredictabilities, and</li>
<li class="fragment">independent decision-making.</li>
</ul>
</div>
<aside class="notes">
<ul>
<li><strong>Autonomy and goal complexity</strong>, as agentic AI systems
<ul>
<li>can handle multiple complex goals simultaneously,</li>
<li>can operate independently over extended periods,</li>
<li>can shift between tasks to achieve higher-order objectives, and</li>
<li>makes decisions with minimal human supervision</li>
</ul></li>
<li><strong>Environmental and situational adaptability</strong>, as agentic AI systems
<ul>
<li>opperate effectively in dynamic and unpredictable environments</li>
<li>adapt to changing conditions in real-time</li>
<li>make decisions with incomplete information</li>
<li>handle uncertainty effectively</li>
</ul></li>
<li><strong>Independent decision-making</strong>, as agentic AI systems
<ul>
<li>can learn from experience and improve over time</li>
<li>use reinforcement learning and meta-learning</li>
<li>demonstrate flexibility in strategy selection</li>
<li>reconceptualizes approaches based on new information</li>
</ul></li>
</ul>
<p>Agentic AI systems need to have the ability to</p>
<ul>
<li>gather information from the environment,</li>
<li>maintaining the execution context over long periods,</li>
<li>develop strategies to achieve goals (i.e, independent decision-making),</li>
<li>communicate plans and goals at appropriate abstraction levels,</li>
<li>perform operations that can influence the environment’s state,</li>
<li>learn and adapt to their environment, and</li>
<li>coordinate with other agents or humans in response to current situations <span class="citation" data-cites="agenticAI2024">(<a href="#/literature" role="doc-biblioref" onclick="">Anthrophic, 2024</a>)</span>.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>



<section id="comparison-with-traditional-ai" class="title-slide slide level2">
<h2>Comparison with traditional AI</h2>
<table>
<caption>Comparison of traditional AI and Agentic AI based on <span class="citation" data-cites="acharya2025agentic">Acharya et al. (<a href="#/literature" role="doc-biblioref" onclick="">2025</a>)</span></caption>
<colgroup>
<col style="width: 27%">
<col style="width: 33%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Traditional AI</th>
<th>Agentic AI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Primary purpose</td>
<td>Task-specific automation</td>
<td>Goal-oriented autonomy</td>
</tr>
<tr class="even">
<td>Human intervention</td>
<td>High (predefined parameters)</td>
<td>Low (autonomous adaptability)</td>
</tr>
<tr class="odd">
<td>Adaptability</td>
<td>Limited</td>
<td>High</td>
</tr>
<tr class="even">
<td>Environment interaction</td>
<td>Static or limited context</td>
<td>Dynamic and context-aware</td>
</tr>
<tr class="odd">
<td>Learning type</td>
<td>Primarily supervised</td>
<td>Reinforcement and self-supervised</td>
</tr>
<tr class="even">
<td>Decision-making</td>
<td>Data-driven, static rules</td>
<td>Autonomous, contextual reasoning</td>
</tr>
</tbody>
</table>
</section>

<section id="comparison-of-agent-types" class="title-slide slide level2">
<h2>Comparison of agent types</h2>
<table>
<caption>Comparison between classical agents, reinforcement learning agents, and agentic AI based on <span class="citation" data-cites="acharya2025agentic">Acharya et al. (<a href="#/literature" role="doc-biblioref" onclick="">2025</a>)</span></caption>
<colgroup>
<col style="width: 17%">
<col style="width: 22%">
<col style="width: 27%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Classical Agents</th>
<th>Learning Agents</th>
<th>Agentic AI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Primary Purpose</strong></td>
<td>Fixed-task automation</td>
<td>Reward-driven optimization</td>
<td>Goal-oriented autonomy</td>
</tr>
<tr class="even">
<td><strong>Adaptability</strong></td>
<td>Low</td>
<td>Moderate</td>
<td>High</td>
</tr>
<tr class="odd">
<td><strong>Learning Type</strong></td>
<td>Supervised</td>
<td>Reinforcement Learning</td>
<td>Hybrid, including RAG and Memory</td>
</tr>
<tr class="even">
<td><strong>Applications</strong></td>
<td>Static systems</td>
<td>Dynamic environments</td>
<td>Complex, multi-objective tasks</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="qa" class="title-slide slide level1 html-hidden unlisted headline-only">
<h1>Q&amp;A</h1>

</section>

<section>
<section id="exercises" class="title-slide slide level1 headline-only" data-background-color="black">
<h1>Exercises</h1>

</section>
<section id="concepts" class="title-slide slide level2">
<h2>Concepts</h2>
<p>Define in your own words the following terms:</p>
<ul>
<li>Rationality</li>
<li>Autonomy</li>
<li>Agent</li>
<li>Environment</li>
<li>Sensor</li>
<li>Actuator</li>
<li>Percept</li>
<li>Agent function</li>
<li>Agent program</li>
</ul>
</section>

<section id="agent-types-1" class="title-slide slide level2">
<h2>Agent types</h2>
<p>Explain the differences between the following agent types in your own words. Describe the component(s) that is/are specific for each type.</p>
<ul>
<li>Reflex agent</li>
<li>Model-based agent</li>
<li>Goal-based agent</li>
<li>Utility-based agent</li>
<li>Learning agent</li>
</ul>
</section>

<section id="vacuum-cleaner" class="title-slide slide level2">
<h2>Vacuum cleaner</h2>
<p>Under which circumstances does a <strong>robotic vacuum cleaner</strong> act rational?</p>
<p>Describe the task environment of such an agent.</p>
</section>

<section id="peas" class="title-slide slide level2">
<h2>PEAS</h2>
<p>For each of the following agents, specify the performance measure, the environment, the actuators, and the sensors.</p>
<ul>
<li>Microwave oven</li>
<li>Chess program</li>
<li>Autonomous supply delivery</li>
</ul>
</section>

<section id="performance-measure-1" class="title-slide slide level2">
<h2>Performance measure</h2>
<p>Describe a task environment in which the performance measure is easy to specify completely and correctly, and a in which it is not.</p>
</section>

<section id="assertions" class="title-slide slide level2">
<h2>Assertions</h2>
<p>For each of the following assertions, say whether it is true or false and support your answer with examples or counterexamples where appropriate.</p>
<ol type="1">
<li>An agent that senses only partial information about the state cannot be perfectly rational.</li>
<li>There exist task environments in which no pure reflex agent can behave rationally.</li>
<li>There exists a task environment in which every agent is rational.</li>
<li>Every agent is rational in an unobservable environment.</li>
<li>A perfectly rational poker-playing agent never loses.</li>
</ol>
<aside class="notes">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Solution notes</strong></p>
</div>
<div class="callout-content">
<ol type="1">
<li><strong>False.</strong> Perfect rationality refers to the ability to make gooddecisions given the sensor information received.</li>
<li><strong>True.</strong> A pure reflex agent ignores previous percepts and cannot obtain an optimal state estimate in a partially observable environment</li>
<li><strong>True.</strong> For example, in an environment with a single state, such that all actions have the same reward, it does not matter which action is taken.</li>
<li><strong>False.</strong> Some actions are stupid (and the agent may know this if it has a model) even if it has no environment input.</li>
<li><strong>False.</strong> Unless it draws the perfect hand, the agent can lose if an opponent has better cards.</li>
</ol>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="task-environment" class="title-slide slide level2">
<h2>Task environment</h2>
<p>For each of the following activities characterize the task environment it in terms of the properties discussed in the lecture notes.</p>
<ul>
<li>Playing soccer</li>
<li>Exploring the subsurface oceans of Titan</li>
<li>Shopping for used AI books on the internet</li>
<li>Playing a tennis match</li>
</ul>
</section>

<section id="task-environment-2" class="title-slide slide level2">
<h2>Task environment #2</h2>
<p>For each of the following task environment properties, rank the example task environments from most to least according to how well the environment satisfies the property.</p>
<p>Lay out any assumptions you make to reach your conclusions.</p>
<ol type="a">
<li>Fully observable: driving; document classification; tutoring a student in calculus; skin cancer diagnosis from images</li>
<li>Continuous: driving; spoken conversation; written conversation; climate engineering by stratospheric aerosol injection</li>
<li>Stochastic: driving; sudoku; poker; soccer</li>
<li>Static: chat room; checkers; tax planning; tennis</li>
</ol>
</section>
</section>
<section id="literature" class="title-slide slide level1 smaller scrollable">
<h1>Literature</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-acharya2025agentic" class="csl-entry" role="listitem">
Acharya, D. B., Kuppan, K., &amp; Divya, B. (2025). Agentic AI: Autonomous intelligence for complex goals–a comprehensive survey. <em>IEEE Access</em>.
</div>
<div id="ref-agenticAI2024" class="csl-entry" role="listitem">
Anthrophic. (2024). <em>Building effective agents</em>. Anthropic Research Team; <a href="https://www.anthropic.com/engineering/building-effective-agents" class="uri">https://www.anthropic.com/engineering/building-effective-agents</a>.
</div>
<div id="ref-RusselNorvig2022AIMA" class="csl-entry" role="listitem">
Russel, S., &amp; Norvig, P. (2022). <em>Artificial intelligence: A modern approach</em>. Pearson Education.
</div>
<div id="ref-Wiener1960Some" class="csl-entry" role="listitem">
Wiener, N. (1960). Some moral and technical consequences of automation. <em>Science</em>, <em>131</em>(3410), 1355–1358.
</div>
</div>


</section>

<section id="footnotes" class="footnotes footnotes-end-of-document smaller scrollable" role="doc-endnotes"><h3>Footnotes</h3>

<ol>
<li id="fn1"><p>The <strong>agent function</strong> maps any given percept sequence to an action (an abstract mathematical description).</p></li>
<li id="fn2"><p>The term <strong>percept</strong> refers to the content an agent’s sensors are perceiving. The <strong>percept sequence</strong> is the complete history of everything an agent has ever perceived.</p></li>
<li id="fn3"><p>Rectangles are used to denote the current internal state of the agent’s decision process, rectangles with rounded corners to represent the background information used in the process.</p></li>
</ol>
</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: false,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1080,

        height: 640,

        // Factor of the display size that should remain empty around the content
        margin: 0,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script>
    // Copy over background colors to new div
    divs = document.querySelectorAll('[data-background-color]');

    Array.from(divs).map(function (x) {
      const color = x.dataset.backgroundColor;

      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-color-div");
      new_div.style.backgroundColor = color;
      x.appendChild(new_div);
      x.removeAttribute("data-background-color");
    })

    // Remove background colors from backgrounds div
    Array.from(
      document.querySelectorAll("[data-background-hash]")
    ).map(function (x) {
      x.removeAttribute("data-background-hash");
      x.style.backgroundColor = null;
    })
    </script>

    <script>
    // Copy over background images to new div
    divs = document.querySelectorAll('[data-background-image]');

    Array.from(divs).map(function (x) {
      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-image-div");

      if (x.dataset.backgroundImage != undefined) {
        new_div.style.backgroundImage = "url(" + x.dataset.backgroundImage + ")";
        x.removeAttribute("data-background-image");
      }
      if (x.dataset.backgroundSize != undefined) {
        new_div.style.backgroundSize = x.dataset.backgroundSize;
        x.removeAttribute("data-background-size");
      }
      if (x.dataset.backgroundPosition != undefined) {
        new_div.style.backgroundPosition = x.dataset.backgroundPosition;
        x.removeAttribute("data-background-position");
      }
      if (x.dataset.backgroundRepeat != undefined) {
        new_div.style.backgroundRepeat = x.dataset.backgroundRepeat;
        x.removeAttribute("data-background-repeat");
      }
      if (x.dataset.backgroundOpacity != undefined) {
        new_div.style.backgroundOpacity = x.dataset.backgroundOpacity;
        x.removeAttribute("data-background-opacity");
      }

      x.appendChild(new_div);
    })
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var video_div = document.querySelectorAll(".backgrounds video");
    var slide_div = document.querySelectorAll("[data-background-video]");

    for (let i = 0; i < video_div.length; i++) {
      video_div[i].setAttribute("class", "background-video-div");

      slide_div[i].appendChild(video_div[i]);
      slide_div[i].removeAttribute("data-background-video");
    }

    Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var video_div = document.querySelectorAll(".backgrounds video");
      var slide_div = document.querySelectorAll("[data-background-video]");

      for (let i = 0; i < video_div.length; i++) {
        video_div[i].setAttribute("class", "background-video-div");

        slide_div[i].appendChild(video_div[i]);
        slide_div[i].removeAttribute("data-background-video");
      }

      Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());
    });
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var iframe_div = document.querySelectorAll(".backgrounds iframe");
    var slide_div = document.querySelectorAll("[data-background-iframe]");

    for (let i = 0; i < iframe_div.length; i++) {
      iframe_div[i].setAttribute("class", "background-iframe-div");

      slide_div[i].appendChild(iframe_div[i]);
      slide_div[i].removeAttribute("data-background-iframe");
    }

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var iframe_div = document.querySelectorAll(".backgrounds iframe");
      var slide_div = document.querySelectorAll("[data-background-iframe]");

      for (let i = 0; i < iframe_div.length; i++) {
        iframe_div[i].setAttribute("class", "background-iframe-div");

        slide_div[i].appendChild(iframe_div[i]);
        slide_div[i].removeAttribute("data-background-iframe");
      }
    });
    </script>

    <script>
    // Clean up slide background styles
    divs = document.querySelectorAll('.slide-background-content');
    Array.from(divs).map(function (x) {
      x.style = null;
    })
    </script>

    <script>

      // Move menu button
      menu_div = document.querySelector(".slide-menu-button");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move progress bar
      menu_div = document.querySelector(".progress");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move slide number
      slide_number = document.querySelector(".slide-number");
      document.querySelector(".slides").appendChild(slide_number);
      
      // Move custom footer
      footer = document.querySelector(".footer.custom");
      document.querySelector(".slides").appendChild(footer);

    </script>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/awe-hnu\.github\.io");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>