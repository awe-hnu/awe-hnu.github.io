<!DOCTYPE html>
<html lang="en"><head>
<link href="../../../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Andy Weeger">
  <meta name="dcterms.date" content="2025-04-15">
  <title>awe.lectures – Introduction to ML</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/theme/quarto-38905d13cb9cc007a76808dad09f60e2.css">
  
  <script type="text/javascript" charset="UTF-8">
  document.addEventListener('DOMContentLoaded', function () {
  cookieconsent.run({
    "notice_banner_type":"interstitial",
    "consent_type":"express",
    "palette":"dark",
    "language":"en",
    "page_load_consent_levels":["strictly-necessary"],
    "notice_banner_reject_button_hide":false,
    "preferences_center_close_button_hide":false,
    "website_name":""
    ,
  "language":"en"
    });
  });
  </script> 
    
  <link href="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <meta name="mermaid-theme" content="neutral">
  <script src="../../../../site_libs/quarto-diagram/mermaid.min.js"></script>
  <script src="../../../../site_libs/quarto-diagram/mermaid-init.js"></script>
  <link href="../../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<meta property="og:title" content="Introduction to ML – awe.lectures">
<meta property="og:description" content="🧠 Introduction to AI">
<meta property="og:site_name" content="awe.lectures">
</head>
<body class="quarto-light">
<div class="footer custom">

    <div class="version">
        V1.2
    </div>

    <div class="footnote">
        Andy Weeger / Neu-Ulm University of Applied Sciences Neu-Ulm / Introduction to Artificial Intelligence (AI)
   </div>

    <div class="logo">
        <svg viewbox="0 0 125 39" xmlns="http://www.w3.org/2000/svg" version="1.1" space="preserve">
            <g>
             <title>HNU</title>
             <path d="m8.58222,0l7.5,0l0,12.7l-7.5,0l0,-12.7zm7.4,24.1l6.5,0l0,-3l-13.9,0l0,15.4l-3.9,0l0,2.3l11.3,0l0,-14.7zm24,-24.1l-7.4,0l0,36.5l-3.9,0l0,2.3l11.3,0l0,-38.8zm60.2,28.4c1.1,0 2.1,-0.1 2.9,-0.4c-1.3,-1.2 -1.9,-3.2 -1.9,-6.4l0,-21.6l-7.4,0l0,19.3c0,5.9 1.5,9.1 6.4,9.1z" id="svg_1"></path>
             <path d="m96.78222,37c2.8,1.6 6.4,2.5 10.6,2.5c11.2,0 17.7,-6 17.7,-16.3l0,-23.2l-7.4,0l0,21.1c0,11.3 -7.7,16.1 -17.6,16.1c-1.1,0 -2.2,-0.1 -3.3,-0.2zm-30.8,-27l-7.1,-10l-7.3,0l14.4,20.4l0,-10.4zm17,28.8l0,-38.8l-7.5,0l0,36.5l-3.5,0l1.7,2.3l9.3,0zm-24,-14.8l-8,-10.8l0,23.3l-3,0l0,2.3l11,0l0,-14.8z" id="svg_2"></path>
            </g>   
        </svg>
    </div>

</div>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#0333ff" data-background-image="../assets/bg.jpeg" data-background-opacity="1" data-background-size="cover" class="quarto-title-block">
  <h1 class="title">Introduction to ML</h1>
  <p class="subtitle">🧠 Introduction to AI</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Andy Weeger 
</div>
        <p class="quarto-title-affiliation">
            Neu-Ulm University of Applied Sciences
          </p>
    </div>
</div>

  <p class="date">April 15, 2025</p>
</section>
<section>
<section id="introduction" class="title-slide slide level1 headline-only">
<h1>Introduction</h1>

</section>
<section id="characteristics" class="title-slide slide level2">
<h2>Characteristics</h2>
<blockquote>
<p>Learning agents are those that can improve their behavior through diligent study of past experiences and predictions of the future. <em><span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022, p. 668</a>)</span></em></p>
</blockquote>
<div class="fragment">
<p>At its core, a learning agent (LA):</p>
<ul>
<li class="fragment">Uses <strong>machine learning</strong> (ML) when it’s a computer system</li>
<li class="fragment">Improves performance based on experience (observations)</li>
<li class="fragment">Is necessary when designers lack complete knowledge of environments</li>
<li class="fragment">Solves problems that are difficult to program explicitly (e.g., face recognition)</li>
</ul>
<aside class="notes">
<p>This definition from <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022</a>)</span> emphasizes the key aspect of learning: <strong>improvement through experience</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>

<section id="definition" class="title-slide slide level2">
<h2>Definition</h2>
<blockquote>
<p>A computer is said to learn from <strong>experience E</strong> with respect to some <strong>task T</strong> and some <strong>performance measure P</strong>, if its performance on T, as measured by P, improves with experience E. <em><span class="citation" data-cites="mitchel1997machine">Mitchel (<a href="#/literature" role="doc-biblioref" onclick="">1997, p. 2</a>)</span></em></p>
</blockquote>
<div class="fragment">
<p>Any ML project needs to clearly specify:</p>
<ul>
<li class="fragment">The <strong>task T</strong> (what problem are we solving?)</li>
<li class="fragment">The <strong>experience E</strong> (what data will the system learn from?)</li>
<li class="fragment">The <strong>performance measure P</strong> (how will we evaluate success?)</li>
</ul>
<aside class="notes">
<p>The <strong>performance measure</strong> component is arguably the most critical component to define correctly. Poorly defined performance measures lead to misaligned systems that optimize for the wrong objectives, creating several serious problems:</p>
<ul>
<li><strong>Goal misalignment</strong>: The system optimizes for metrics that don’t actually capture what humans value or need</li>
<li><strong>Unexpected behaviors</strong>: The system may find unexpected or undesirable ways to maximize the specified metric</li>
<li><strong>Goodhart’s Law</strong>: Once a measure becomes the explicit target for optimization, it often loses its value as an accurate representation of what we actually care about<a href="#/footnotes" class="footnote-ref" id="fnref1" role="doc-noteref" data-footnote-href="#/fn1" onclick=""><sup>1</sup></a>.</li>
<li><strong>Neglect of unmeasured factors</strong>: Important considerations that aren’t explicitly measured may be ignored or sacrificed</li>
</ul>
<p>Thus, the careful definition of performance measures is essential for ensuring ML systems solve the intended problems and align with human values.</p>
<p>The <strong>experience component</strong> is what fundamentally distinguishes machine learning from traditional programming. In traditional programming, humans encode rules that the computer follows, while in machine learning, the computer discovers rules from data.</p>
<div class="columns">
<div class="column">
<p><strong>Traditional programming</strong></p>
<ul>
<li>Rules are explicitly coded by humans</li>
<li>System behavior is predetermined by these rules</li>
<li>Changes require manual reprogramming</li>
<li>No ability to improve from data</li>
</ul>
</div><div class="column">
<p><strong>Machine Learning</strong></p>
<ul>
<li>Rules are derived from data (the “experience”)</li>
<li>System behavior emerges from patterns in the data</li>
<li>Changes can occur automatically with new data</li>
<li>Continuous improvement through additional experience</li>
</ul>
</div></div>
<p>This shift represents a profound change in how problem-solving with computers is approached. Rather than trying to encode all possible rules and scenarios, ML allows to let systems discover patterns themselves through exposure to relevant experiences.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<aside></aside></section>

<section id="exercise" class="title-slide slide level2 discussion-slide html-hidden unlisted unnumbered">
<h2>Exercise</h2>
<div class="medium">
<p>Select one of the specific applications for ML below and define T, E, and P.</p>
</div>
<ol type="1">
<li>Face recognition system</li>
<li>Language translation service</li>
<li>Credit card fraud detection</li>
</ol>
</section>

<section id="why-learning-works" class="title-slide slide level2">
<h2>Why learning works</h2>
<p>How can we be sure that our learned hypothesis will predict well for previously unseen inputs? I.e., how do we know that the hypothesis <span class="math inline">\(h\)</span> is close to the target function <span class="math inline">\(f\)</span> when <span class="math inline">\(f\)</span> is unknown?</p>
<div class="fragment">
<p>The underlying principle of <strong>computational learning theory</strong> is, that any hypothesis that is seriously wrong will almost certainly be “found out” with high probability after a small number of examples.</p>
</div>
<div class="fragment">
<p>Thus, any hypothesis that is consistent with a sufficiently large set of training examples is unlikely to be seriously wrong: that is, it must be <strong>probably approximately correct</strong> (PAC).</p>
</div>
</section>

<section id="ml-x-ai" class="title-slide slide level2">
<h2>ML x AI</h2>
<p>ML constitutes one of the 4 categories of AI and is currently dominant in AI applications.</p>
<div class="cell" data-reveal="true" data-layout-align="left">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    AI[Artificial Intelligence] --&gt; ML[Machine Learning]
    AI --&gt; SP[Search and Planning]
    AI --&gt; KI[Knowledge and Inference]
    AI --&gt; MU[Modeling of Uncertainty]
    
    ML --&gt; SL[Supervised Learning]
    ML --&gt; UL[Unsupervised Learning]
    ML --&gt; RL[Reinforcement Learning]
    
    style AI fill:#000,stroke:#000,stroke-width:1px,color:#fff
    style ML fill:#0333ff,stroke:#0333ff,stroke-width:1px,color:#fff
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<aside class="notes">
<p>However, the other branches have important historical significance and <strong>complementary roles</strong>:</p>
<ul>
<li><strong>Machine learning</strong> excels at pattern recognition, handling messy real-world data, adapting to new situations</li>
<li><strong>Search and planning</strong> is concerned with finding <strong>optimal solutions</strong>, guaranteeing results, and handling combinatorial problems. It encompasses algorithms like A*, minimax, and planning systems.</li>
<li><strong>Knowledge and inference</strong> excels at <strong>explicit reasoning</strong>, incorporating human expertise, and transparency. It includes expert systems, knowledge graphs, and logical reasoning.</li>
<li><strong>Modeling of uncertainty</strong> is concerned with handling incomplete information, quantifying confidence, and risk assessment. It covers Bayesian networks, fuzzy logic, and probabilistic reasoning</li>
</ul>
<p>Consequently, the most powerful AI systems often combine techniques from multiple branches. For example:</p>
<ul>
<li>Autonomous vehicles use ML for perception, planning algorithms for navigation, and uncertainty modeling for safety decisions</li>
<li>Medical diagnosis systems might combine knowledge graphs of medical facts with ML-based pattern recognition from patient data</li>
<li>Game AI like AlphaGo combines reinforcement learning with tree search algorithms</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section>
<section id="la-architecture" class="title-slide slide level1 headline-only">
<h1>LA architecture</h1>

</section>
<section id="visualization" class="title-slide slide level2">
<h2>Visualization</h2>
<div id="fig-l-agent" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/learning-agent.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-l-agent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A learning agent based on <span class="citation" data-cites="RusselNorvig2022AIMA">Russel &amp; Norvig (<a href="#/literature" role="doc-biblioref" onclick="">2022, p. 74</a>)</span>
</figcaption>
</figure>
</div>
</section>

<section id="building-blocks" class="title-slide slide level2">
<h2>Building blocks</h2>
<p><strong>Performance element:</strong> Processes percepts and chooses actions (relates to the basics of AI we have studied so far).</p>
<div class="fragment">
<p><strong>Learning element:</strong> Carries out improvements — requires awareness and feedback on how the agent is doing in the environment.</p>
</div>
<div class="fragment">
<p><strong>Critic:</strong> Evaluation of the agent’s behavior based on a given external behavioral measure (i.e., feedback).</p>
</div>
<div class="fragment">
<p><strong>Problem generator:</strong> Suggests explorative actions that lead the agent to new experiences.</p>
<aside class="notes">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Performance element</strong></p>
</div>
<div class="callout-content">
<p>The <strong>performance elements</strong> of the agent designs described in chapter <a href="../2/">Intelligent agents</a> are composed of</p>
<ul>
<li>a direct mapping from conditions to the current state of actions;</li>
<li>a means to infer relevant properties of the world from the percept sequence;</li>
<li>information about the way the world evolves and about the results of possible actions the agent can take;</li>
<li>utility information indicating the desirability of actions; and/or</li>
<li>goals that describe the most desirable states;</li>
</ul>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>

<section id="the-learning-element" class="title-slide slide level2">
<h2>The learning element</h2>
<p>The design of the learning element is influenced by four important aspects:</p>
<ul>
<li class="fragment">Which <strong>component</strong> of the performance element is to be improved?</li>
<li class="fragment">What <strong>representation</strong> should be chosen (i.e., model type)?</li>
<li class="fragment">What <strong>prior information</strong> is available (i.e., prior knowledge that influences the model)?</li>
<li class="fragment">What form of <strong>feedback</strong> is available?</li>
</ul>
</section>


</section>
<section>
<section id="supervised-learning" class="title-slide slide level1 headline-only">
<h1>Supervised learning</h1>

</section>
<section id="visualization-1" class="title-slide slide level2">
<h2>Visualization</h2>
<div id="fig-sl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/sl-training.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Training phase of supervised learning
</figcaption>
</figure>
</div>
</section>
<section class="slide level3">

<p>The model is then used as follows:</p>
<div id="fig-sl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/sl-application.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Application phase of supervised learning
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Supervised learning resonates with our natural understanding of teaching. Just as we teach children by showing examples and providing feedback, supervised learning algorithms learn from labeled data. This approach mirrors human education — we demonstrate correct answers and expect learners to generalize from specific examples to broader concepts. The clear relationship between inputs and desired outputs makes supervised learning conceptually straightforward. However, unlike humans who can often understand concepts from just a few examples, machine learning models typically require hundreds or thousands of labeled instances to perform well, and they lack the contextual understanding that humans bring to learning tasks.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="key-challenges" class="title-slide slide level2">
<h2>Key challenges</h2>
<div class="medium">
<ul>
<li class="fragment">Getting enough labeled data</li>
<li class="fragment">Ensuring labels are accurate</li>
<li class="fragment">Dealing with imbalanced data classes</li>
<li class="fragment">Feature selection and engineering</li>
</ul>
</div>
<aside class="notes">
<p>“Garbage in, garbage out” is especially relevant in supervised learning. Your training data quality directly determines the ceiling of your model’s performance — no algorithm can overcome fundamentally flawed data. This creates several critical considerations: data must be representative of real-world applications; inconsistent labels introduce confusion into the learning process; and edge cases must be adequately represented. The process of collecting, cleaning, and verifying training data often consumes the majority of time in practical ML projects. When evaluating supervised learning results, always consider whether performance limitations stem from the algorithm or from the underlying data quality.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>






<section id="practical-applications" class="title-slide slide level2">
<h2>Practical applications</h2>
<aside class="notes">
<p><strong>Image classification</strong> — inputs can be camera images, each one accompanied by an output saying, e.g., “bus” or “pedestrian”. An output like this is called a label. The agents learns a function that, when given a new image, predicts the appropriate label.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="medium">
<ul>
<li class="fragment">Sentiment analysis</li>
<li class="fragment">Spam detection</li>
<li class="fragment">Loan approval prediction</li>
<li class="fragment"><span class="html-hidden">Image classification</span></li>
</ul>
</div>
</section>
</section>
<section>
<section id="unsupervised-learning" class="title-slide slide level1 headline-only">
<h1>Unsupervised learning</h1>

</section>
<section id="visualization-2" class="title-slide slide level2">
<h2>Visualization</h2>
<div id="fig-usl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/usl-training.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Training phase of unsupervised learning
</figcaption>
</figure>
</div>
</section>
<section class="slide level3">

<p>The model is then used as follows:</p>
<div id="fig-usl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/usl-application.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-usl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Application phase of unsupervised learning
</figcaption>
</figure>
</div>
<aside class="notes">
<p>Unsupervised learning mirrors how we naturally discover patterns in the world around us. Just as children learn to categorize objects without being explicitly taught every category, unsupervised algorithms find structure in unlabeled data. This approach reflects human intuition — we recognize similarities, identify outliers, and group related items without requiring prior labels. The absence of predetermined outputs makes unsupervised learning both powerful and challenging. Unlike supervised learning, these algorithms must determine what’s important within the data itself, similar to how humans can walk into an unfamiliar environment and instinctively organize what they perceive. Unsupervised methods excel at revealing hidden structures that might never be discovered through directed approaches, though their results can sometimes be more difficult to validate objectively.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="key-challenges-1" class="title-slide slide level2">
<h2>Key challenges</h2>
<div class="medium">
<ul>
<li class="fragment">Evaluating the quality of results without ground truth</li>
<li class="fragment">Determining the optimal number of groups or patterns</li>
<li class="fragment">Interpreting the discovered patterns meaningfully</li>
<li class="fragment">Dealing with high-dimensional data</li>
</ul>
</div>
<aside class="notes">
<p>The open-ended nature of unsupervised learning creates unique considerations. Without labeled examples to guide the process, these algorithms must rely on inherent data properties like density, distance metrics, or statistical distributions. This raises fundamental questions: How do we know if discovered patterns are meaningful rather than arbitrary? What makes one clustering better than another? The absence of clear right or wrong answers means evaluation often relies on domain expertise and business context. Additionally, many unsupervised techniques struggle with the “curse of dimensionality”<a href="#/footnotes" class="footnote-ref" id="fnref2" role="doc-noteref" data-footnote-href="#/fn2" onclick=""><sup>2</sup></a> — a phenomenon where data becomes increasingly sparse as dimensions increase. In high-dimensional spaces, points become nearly equidistant from each other, making similarity measures less meaningful. For example, in a 1,000-dimensional space, the difference between the closest and farthest points becomes negligible, undermining the foundation of distance-based clustering. This dramatically impacts algorithms that rely on distance metrics, as the concept of proximity becomes less informative. Even with large datasets, the available data points become insufficient to adequately represent the vastly increased volume of the feature space.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside></aside></section>





<section id="practical-applications-1" class="title-slide slide level2">
<h2>Practical applications</h2>
<p><strong>Computer vision</strong> — when shown millions of images, a computer vision system could identify large cluster of similar images (without “knowing” what is shown on these).</p>
<div class="medium">
<ul>
<li class="fragment">Customer segmentation</li>
<li class="fragment">Anomaly detection</li>
<li class="fragment">Topic modeling in text</li>
<li class="fragment">Recommender systems</li>
<li class="fragment">Image compression</li>
</ul>
</div>
<aside class="notes">
<div class="column-page-inset-right">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example</strong></p>
</div>
<div class="callout-content">
<p>We begin with the unlabeled data, representing customer purchases of different products. A value of 1 indicates a purchase, while 0 indicates no purchase.</p>
<p><span class="h4"><strong>Unlabeled data</strong></span></p>
<table style="width:100%;">
<caption>Unlabeled customer purchase data</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Customer</th>
<th>Product 1</th>
<th>Product 2</th>
<th>Product 3</th>
<th>Product 4</th>
<th>Product 5</th>
<th>Product 6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Customer 1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>Customer 3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>Customer 4</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Customer 5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>Customer 6</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Customer 7</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 8</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>First, we apply <strong>clustering</strong> to group customers with similar product purchasing behavior. Customers with similar rows (purchase patterns) are grouped together.</p>
<p>Customers 1, 6, 7, and 8 tend to buy products 1–3, often in combination.</p>
<table style="width:100%;">
<caption>Cluster A: customers 1, 6, 7, 8</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Customer</th>
<th>Product 1</th>
<th>Product 2</th>
<th>Product 3</th>
<th>Product 4</th>
<th>Product 5</th>
<th>Product 6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Customer 1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 6</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Customer 7</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>Customer 8</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Customers 2, 3, and 5 show a preference for product 6 and product 5.</p>
<table style="width:100%;">
<caption>Cluster B: customers 2, 3, 5</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Customer</th>
<th>Product 1</th>
<th>Product 2</th>
<th>Product 3</th>
<th>Product 4</th>
<th>Product 5</th>
<th>Product 6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Customer 2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td>Customer 3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td>Customer 5</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Customer 4 has a unique pattern and does not fit well into either cluster.</p>
<p>Second, we perform <strong>association rule mining</strong> to find relationships between product purchases, i.e., which products are frequently bought together.</p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="header">
<th>Metric.</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Support</td>
<td>% of transactions that contain both items (how common is the combo?)</td>
</tr>
<tr class="even">
<td>Confidence</td>
<td>% of times Product B is bought when Product A is bought (A → B)</td>
</tr>
<tr class="odd">
<td>Lift</td>
<td>How much more likely A and B are bought together vs.&nbsp;by chance<a href="#/footnotes" class="footnote-ref" id="fnref3" role="doc-noteref" data-footnote-href="#/fn3" onclick=""><sup>3</sup></a></td>
</tr>
</tbody>
</table>
<table>
<caption>Confidence: table of association rules</caption>
<colgroup>
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Rule</th>
<th>Support Count (X &amp; Y)</th>
<th>X Count</th>
<th>Confidence</th>
<th>Support(Y)</th>
<th>Lift</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>P1 → P2</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>50.0%</td>
<td>1.00</td>
</tr>
<tr class="even">
<td>P1 → P3</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>50.0%</td>
<td>0.50</td>
</tr>
<tr class="odd">
<td>P1 → P4</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>37.5%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P1 → P5</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>25.0%</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td>P1 → P6</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>37.5%</td>
<td>1.33</td>
</tr>
<tr class="even">
<td>P2 → P1</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>50.0%</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><strong>P2 → P3</strong></td>
<td><strong>3</strong></td>
<td><strong>4</strong></td>
<td><strong>75.0%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.50</strong></td>
</tr>
<tr class="even">
<td>P2 → P4</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>37.5%</td>
<td>0.67</td>
</tr>
<tr class="odd">
<td>P2 → P5</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>25.0%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P2 → P6</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>37.5%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P3 → P1</td>
<td>1</td>
<td>4</td>
<td>25.0%</td>
<td>50.0%</td>
<td>0.50</td>
</tr>
<tr class="even">
<td><strong>P3 → P2</strong></td>
<td><strong>3</strong></td>
<td><strong>4</strong></td>
<td><strong>75.0%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.50</strong></td>
</tr>
<tr class="odd">
<td>P3 → P4</td>
<td>2</td>
<td>4</td>
<td>50.0%</td>
<td>37.5%</td>
<td>1.33</td>
</tr>
<tr class="even">
<td>P3 → P5</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>25.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P3 → P6</td>
<td>0</td>
<td>4</td>
<td>0.0%</td>
<td>37.5%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P4 → P1</td>
<td>0</td>
<td>3</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P4 → P2</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>50.0%</td>
<td>0.67</td>
</tr>
<tr class="even">
<td><strong>P4 → P3</strong></td>
<td><strong>2</strong></td>
<td><strong>3</strong></td>
<td><strong>66.7%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.33</strong></td>
</tr>
<tr class="odd">
<td>P4 → P5</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>25.0%</td>
<td>1.33</td>
</tr>
<tr class="even">
<td>P4 → P6</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>37.5%</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td>P5 → P1</td>
<td>1</td>
<td>2</td>
<td>50.0%</td>
<td>50.0%</td>
<td>1.00</td>
</tr>
<tr class="even">
<td>P5 → P2</td>
<td>0</td>
<td>2</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P5 → P3</td>
<td>0</td>
<td>2</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P5 → P4</td>
<td>1</td>
<td>2</td>
<td>50.0%</td>
<td>37.5%</td>
<td>1.33</td>
</tr>
<tr class="odd">
<td><strong>P5 → P6</strong></td>
<td><strong>2</strong></td>
<td><strong>2</strong></td>
<td><strong>100.0%</strong></td>
<td><strong>37.5%</strong></td>
<td><strong>2.67</strong></td>
</tr>
<tr class="even">
<td><strong>P6 → P1</strong></td>
<td><strong>2</strong></td>
<td><strong>3</strong></td>
<td><strong>66.7%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>1.33</strong></td>
</tr>
<tr class="odd">
<td>P6 → P2</td>
<td>0</td>
<td>3</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="even">
<td>P6 → P3</td>
<td>0</td>
<td>3</td>
<td>0.0%</td>
<td>50.0%</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>P6 → P4</td>
<td>1</td>
<td>3</td>
<td>33.3%</td>
<td>37.5%</td>
<td>0.89</td>
</tr>
<tr class="even">
<td><strong>P6 → P5</strong></td>
<td><strong>2</strong></td>
<td><strong>3</strong></td>
<td><strong>66.7%</strong></td>
<td><strong>25.0%</strong></td>
<td><strong>2.67</strong></td>
</tr>
</tbody>
</table>
<p><span class="h4"><strong>Insights</strong></span></p>
<p>Based on the association rules analysis, we can derive the following insights:</p>
<ol type="1">
<li><strong>Strong product pairings</strong>:
<ul>
<li>Products 5 and 6 have the strongest association with the highest lift value (2.67) in both directions. Customers who buy either one are much more likely to buy the other, suggesting these products strongly complement each other.</li>
<li>Products 2 and 3 also show a strong positive association (lift = 1.50), with 75% of product 2 buyers also purchasing product 3.</li>
</ul></li>
<li><strong>One-way associations</strong>:
<ul>
<li>The rule P4 → P3 shows that 66.7% of customers who buy product 4 also buy product 3 (lift = 1.33), but the reverse isn’t as strong (P3 → P4 has only 50% confidence).</li>
<li>This suggests Product 4 buyers are a subset of product 3 buyers, but not vice versa.</li>
</ul></li>
<li><strong>Product clustering</strong>:
<ul>
<li>Group 1: Products 5 and 6 (strongest association)</li>
<li>Group 2: Products 2 and 3 (strong association)</li>
<li>Group 3: Products 1 and 6 (moderate association)</li>
</ul></li>
<li><strong>Product Independence and Negative Associations</strong>:
<ul>
<li>Several products never appear together (lift = 0), such as P1 and P4, P2 and P5, P3 and P5.</li>
<li>This suggests potential product incompatibility or different customer segments.</li>
</ul></li>
<li><strong>Product Popularity</strong>:
<ul>
<li>Products 1, 2, and 3 have the highest support (each purchased by 50% of customers)</li>
<li>Product 5 has the lowest support (only 25%)</li>
</ul></li>
<li><strong>Business Applications</strong>:
<ul>
<li>Bundle marketing: The P5 → P6 rule with 100% confidence and 2.67 lift suggests these products could be effectively bundled.</li>
<li>Recommendation systems: When a customer buys product 4, recommending product 3 would be logical (66.7% confidence).</li>
</ul></li>
</ol>
</div>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside></aside></section>
</section>
<section>
<section id="reinforcement-learning" class="title-slide slide level1 headline-only">
<h1>Reinforcement learning</h1>

</section>
<section id="visualization-3" class="title-slide slide level2">
<h2>Visualization</h2>
<div id="fig-sl-training" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/rf-learning.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Reinforcement learning
</figcaption>
</figure>
</div>
<aside class="notes">
<p>The goal of reinforcement learning is to learn an optimal policy. A policy defines for each state <span class="math inline">\(S\)</span> of the environment an action <span class="math inline">\(A\)</span>, which shall be executed in this state. The optimal policy is the policy for which the expected cumulative future reward is maximal.</p>
<p>Reinforcement-Learning is Trial-and-Error learning. The agent selects an action <span class="math inline">\(A_t\)</span> in it’s current state <span class="math inline">\(S_t\)</span>. After the execution of this action the environment state changes, the new state is <span class="math inline">\(S_{t+1}\)</span>. Moreover, the agent may receive a positive or negative reward <span class="math inline">\(R_{t+1}\)</span> for his previous action. These received rewards are applied to adapt the future action-selection. Since the reward is only available after performing actions, this type of learning is also called learning with a critic - in contrast to learning with a teacher (i.e.&nbsp;supervised learning).</p>
<p>Reinforcement-Learning works in non-deterministic environments (i.e.&nbsp;for a given state-action pair the successive state is not known for sure). Reinforcement-Learning can also be applied, if the environment is totally unknown to the agent (i.e.&nbsp;the agent doesn’t know the set of possible successive states and the set of possible rewards).</p>
<p>During the iterative training process in unknown environments the agent must explore. The challenge is to find a good explore-exploit trade off. Explore means going along new, not yet visited paths. Exploit means applying for the best action learned so far.</p>
<p>Reinforcement learning embodies how we learn through interaction with our environment. Just as children learn by exploring their surroundings and receiving feedback, reinforcement learning agents improve behavior through trial and error. This approach reflects natural learning processes — we take actions, observe consequences, and adjust future decisions accordingly. The dynamic interplay between exploration (trying new things) and exploitation (leveraging known rewards) mirrors how humans navigate unfamiliar situations. Unlike supervised or unsupervised learning, reinforcement learning incorporates the concept of time — actions influence not just immediate rewards but also future states and opportunities. This sequential decision-making aspect makes it particularly suitable for complex tasks where long-term strategy matters more than immediate outcomes. While powerful, this approach requires careful formulation of reward mechanisms that truly reflect desired behaviors rather than exploitable shortcuts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="key-challenges-2" class="title-slide slide level2">
<h2>Key challenges</h2>
<div class="medium">
<ul>
<li class="fragment">Designing appropriate reward functions</li>
<li class="fragment">Balancing exploration vs.&nbsp;exploitation</li>
<li class="fragment">Dealing with delayed rewards and credit assignment</li>
<li class="fragment">Sample efficiency in real-world applications</li>
<li class="fragment">Transferring learning across different environments</li>
</ul>
</div>
<aside class="notes">
<p>The reward-driven nature of reinforcement learning presents unique complexities. Since the agent learns entirely from environmental feedback, the design of reward signals fundamentally shapes what is learned. An improperly specified reward function can lead to unexpected or undesired behaviors — a phenomenon known as “reward hacking<a href="#/footnotes" class="footnote-ref" id="fnref4" role="doc-noteref" data-footnote-href="#/fn4" onclick=""><sup>4</sup></a>.” Additionally, reinforcement learning algorithms must decide when to explore new possibilities versus when to exploit known effective strategies. Too much exploration wastes resources; too little risks getting stuck in suboptimal solutions. Perhaps most challenging is the temporal credit assignment problem: when a positive outcome follows a long sequence of actions, how do we determine which actions were responsible? This difficulty increases with longer time horizons and more complex action spaces.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside></aside></section>





<section id="practical-applications-2" class="title-slide slide level2">
<h2>Practical applications</h2>
<p>Game playing — imagine, it is told at the end of a game that it has won (a reward) or lost (a punishment). Based on that feedback, it has to decide which of the actions prior to the reinforcement were most responsible for it, and to alter its actions to aim towards more rewards in future.</p>
<div class="medium">
<ul>
<li class="fragment">Game playing (Chess, Go, video games)</li>
<li class="fragment">Robotics and control systems</li>
<li class="fragment">Resource management and scheduling</li>
<li class="fragment">Recommendation systems</li>
</ul>
</div>
</section>
</section>
<section>
<section id="the-learning-process" class="title-slide slide level1 headline-only">
<h1>The learning process</h1>

</section>
<section id="phases" class="title-slide slide level2">
<h2>Phases</h2>
<div class="html-hidden">
<p><span class="large fragment">Training-phase</span><br>
<span class="large fragment">Validation-phase</span><br>
<span class="large fragment">Test-phase</span><br>
<span class="large fragment">Operational phase</span></p>
</div>
<aside class="notes">
<div class="column-page-inset">
<div class="cell" data-reveal="true" data-layout-align="left">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    TD[(Training Data)] --&gt; T[Training]
    T --&gt; M[Model]
    VD[(Validation Data)] --&gt; V[Validation]
    M --&gt; V
    V --&gt; |"Hyperparameter Tuning"| T
    V --&gt; |"Model Selection"| SM[Selected Model]
    TestD[(Test Data)] --&gt; TE[Testing]
    SM --&gt; TE
    TE --&gt; |"Performance Estimation"| FM[Final Model]
    ND[(New Data)] --&gt; AP[Application]
    FM --&gt; AP
    AP --&gt; PR[Predictions]
    
    style TD fill:#f9f9f9,stroke:#333,stroke-width:1px
    style VD fill:#f9f9f9,stroke:#333,stroke-width:1px
    style TestD fill:#f9f9f9,stroke:#333,stroke-width:1px
    style ND fill:#f9f9f9,stroke:#333,stroke-width:1px
    style M fill:#c0f0c0,stroke:#333,stroke-width:1px
    style SM fill:#c0f0c0,stroke:#333,stroke-width:1px
    style FM fill:#c0f0c0,stroke:#333,stroke-width:1px
    style PR fill:#ffe0c0,stroke:#333,stroke-width:1px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<p>Machine learning projects follow a systematic workflow with distinct phases, each serving a critical purpose in developing reliable and effective models. Understanding these phases helps ensure robust model development and deployment.</p>
<p><span class="h4"><strong>Training phase</strong></span></p>
<p>During the training phase, we apply a carefully selected dataset to learn a general model. The nature of this model varies by learning paradigm — in unsupervised learning, it describes the inherent structure of the data (such as clusters or reduced dimensions), while in supervised and reinforcement learning, it captures functional relationships that map inputs to outputs or states to actions. This phase involves iterative optimization of model parameters to minimize error or maximize reward according to a specific objective function. The choice of training algorithm significantly impacts both computational efficiency and the quality of the resulting model. While the model aims to fit training data well, excessive focus on perfect training performance often leads to overfitting — a critical pitfall where the model essentially memorizes training examples rather than learning generalizable patterns.</p>
<p><span class="h4"><strong>Validation phase</strong></span></p>
<p>The validation phase addresses a fundamental challenge in machine learning: we don’t simply want models that excel on training data; we need models that generalize well to new, unseen data. To assess generalization capacity, we apply the model to a validation dataset that remains completely separate from training data. For each input in the validation set, we calculate the model’s prediction and compare it against the true output (for supervised learning) or evaluate its performance under defined metrics (for unsupervised and reinforcement learning). This creates an error statistic or performance measure that serves multiple crucial purposes: evaluating individual models, comparing different approaches, tuning hyperparameters, and ultimately selecting the most promising candidate. The validation phase essentially simulates real-world performance in a controlled environment, helping identify issues like overfitting or underfitting before deployment.</p>
<p><span class="h4"><strong>Test phase</strong></span></p>
<p>The test phase provides the final performance assessment before real-world deployment. After model selection and tuning in the validation phase, we evaluate the chosen model on a completely separate test dataset — one that hasn’t influenced any aspect of model development. This rigorous separation ensures an unbiased estimate of operational performance. The test dataset should closely mirror the distribution of data the model will encounter in production, making test results a reliable predictor of real-world effectiveness. Lower performance on test data compared to validation data often signals potential distribution shifts or overfitting to the validation set itself — critical issues to address before deployment. The test phase represents our last opportunity to detect problems in a controlled environment, making it an essential safeguard against deploying underperforming models.</p>
<p><span class="h4"><strong>Operational mode</strong></span></p>
<p>Once a model demonstrates satisfactory performance in the test phase, it transitions to operational mode — deployment in real-world environments to fulfill its intended purpose. In this phase, the model processes new inputs to generate outputs (classifications, predictions, actions) that drive decision-making or insights. Operational deployment introduces new considerations beyond accuracy: computational efficiency, latency requirements, integration with existing systems, and monitoring mechanisms all become crucial factors. Even after deployment, the learning process doesn’t end; production models require ongoing monitoring for performance degradation, which often occurs as real-world data distributions gradually shift away from training distributions. Many sophisticated deployments incorporate feedback loops that capture new operational data, enabling periodic retraining to maintain or improve performance over time. This continuous improvement cycle helps ensure models remain effective as the environments they operate in evolve.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section>
<section id="model-complexity" class="title-slide slide level1 headline-only">
<h1>Model complexity</h1>

</section>
<section id="the-bias-variance-tradeoff" class="title-slide slide level2">
<h2>The Bias-variance tradeoff</h2>
<p>In ML, selecting the appropriate model complexity is a fundamental challenge. Here this principle is demonstrated through polynomial curve fitting – one of the simplest yet most illustrative examples of the bias-variance tradeoff.</p>
<div class="fragment">
<p>When building a machine learning model, we must balance two competing concerns:</p>
<ol type="1">
<li class="fragment"><strong>Bias</strong>: The error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss relevant relations between features and outputs (underfitting).</li>
<li class="fragment"><strong>Variance</strong>: The error from sensitivity to small fluctuations in the training set. High variance models can fit the training data very well but perform poorly on new, unseen data (overfitting).</li>
</ol>
</div>
</section>

<section id="polynomial-curve-fitting-example" class="title-slide slide level2">
<h2>Polynomial curve fitting example</h2>
<p>In this visualization, we’ll see how polynomials of different degrees fit a dataset generated from a true quadratic function with some added noise:</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-curve-fitting-all" class="quarto-float quarto-figure quarto-figure-left">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-curve-fitting-all-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="index_files/figure-revealjs/fig-curve-fitting-all-1.svg" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-curve-fitting-all-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Comparison of linear underfitting, quadratic good fit, and high-degree overfitting to noisy data generated from a quadratic function.
</figcaption>
</figure>
</div>
</div>
</div>
</section>




<section id="the-learning-principle" class="title-slide slide level2">
<h2>The learning principle</h2>
<div class="medium">
<p>This example illustrates <strong>Ockham’s razor</strong> in action.</p>
</div>
<p>The simplest model that adequately explains the data is likely to have the best predictive power. While we could create a complex polynomial that passes through every training point perfectly, such a model would likely perform poorly on new data.</p>
<aside class="notes">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Ockham’s razor</strong></p>
</div>
<div class="callout-content">
<p>Ockham’s razor is a choice between more complex, low-bias hypotheses that fit the training data well and simple, low-variance hypotheses that may generalize better. Wililiam of Ockham stated in the first century the principle that “plurality [of entities] should not be posited without necessity — the so-called Ockham’s razor that”shaves off” dubious explanations.</p>
</div>
</div>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section id="conclusion" class="title-slide slide level1">
<h1>Conclusion</h1>
<ul>
<li class="fragment">Machine learning fundamentally changes how we approach problem-solving with computers</li>
<li class="fragment">Instead of explicit programming, we design systems that learn from data and experience</li>
<li class="fragment">The field combines statistics, optimization, and domain knowledge</li>
<li class="fragment">Understanding the core concepts helps in developing effective learning systems</li>
<li class="fragment">Key tradeoffs include:
<ul>
<li class="fragment">Bias vs.&nbsp;variance</li>
<li class="fragment">Model complexity vs.&nbsp;generalization</li>
<li class="fragment">Exploration vs.&nbsp;exploitation</li>
<li class="fragment">Accuracy vs.&nbsp;interpretability</li>
</ul></li>
</ul>
</section>

<section>
<section id="exercises" class="title-slide slide level1 headline-only">
<h1>Exercises</h1>

</section>
<section id="learning-scenarios" class="title-slide slide level2">
<h2>Learning scenarios</h2>
<p>Consider following problems:</p>
<ol type="1">
<li>Me learning to play tennis</li>
<li>An infant learning to speak</li>
</ol>
<p>Discuss following questions:</p>
<ul>
<li>Explain how this process fits into the general learning model.</li>
<li>Describe the percepts and actions of the player.</li>
<li>What types of learning I must do?</li>
<li>What example data is available?</li>
</ul>
</section>

<section id="learning-types" class="title-slide slide level2">
<h2>Learning types</h2>
<p>Describe the differences between supervised, unsupervised, and reinforcement learning.</p>
</section>

<section id="ockhams-razor-1" class="title-slide slide level2">
<h2>Ockham’s razor</h2>
<p>In your own words, explain to us what Ockham’s razor is. Find an example that you can use to enrich your explanation of the concept.</p>
</section>

<section id="ml-concepts" class="title-slide slide level2">
<h2>ML concepts</h2>
<p>Define the following machine-learning terms in your own words</p>
<ol type="a">
<li>Inductive learning</li>
<li>Training set</li>
<li>Hypothesis</li>
<li>Bias</li>
<li>Variance</li>
<li>Curve fitting</li>
</ol>
</section>

<section id="qualification-problem" class="title-slide slide level2">
<h2>Qualification problem</h2>
<p>Draw a decision tree for the problem of deciding whether to move forward at a road intersection, given that the light has just turned green.</p>
<p>What problems do you see? Argue based on the qualification problem discussed in <a href="../6/#motivation">chapter probability</a>.</p>
<p>Generalize your findings and describe for which kind of problems decision trees are not suitable.</p>
</section>
</section>
<section id="literature" class="title-slide slide level1 smaller scrollable">
<h1>Literature</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-mitchel1997machine" class="csl-entry" role="listitem">
Mitchel, T. (1997). <em>Machine learning (mcgraw-hill international edit).</em> McGraw-Hill Education. <a href="https://books.google.de/books?id=dMp2uwEACAAJ">https://books.google.de/books?id=dMp2uwEACAAJ</a>
</div>
<div id="ref-RusselNorvig2022AIMA" class="csl-entry" role="listitem">
Russel, S., &amp; Norvig, P. (2022). <em>Artificial intelligence: A modern approach</em>. Pearson Education.
</div>
</div>


</section>

<section id="footnotes" class="footnotes footnotes-end-of-document smaller scrollable" role="doc-endnotes"><h3>Footnotes</h3>

<ol>
<li id="fn1"><p>Examples for Goodhart’s Law in ML: A recommendation system optimized solely for clicks might discover that clickbait titles and thumbnails maximize this metric, even if the content quality suffers and user satisfaction decreases long-term. If a content filter is optimized only to minimize false negatives (letting harmful content through), it might become overly restrictive and block large amounts of legitimate content.</p></li>
<li id="fn2"><p>To illustrate the curse of dimensionality: imagine a unit hypercube (with sides of length 1) in different dimensions. In 2D, it has area 1. In 3D, volume 1. In 100D, to capture just 1% of the hypercube’s volume, you’d need to extend 0.955 units along each dimension — meaning 99% of the volume is in the “corners.” This explains why data points become increasingly distant from each other and distance metrics become less useful as dimensions increase.] When implementing unsupervised methods, success depends on careful feature selection, appropriate distance metrics, and clear alignment with the underlying questions you’re trying to answer.</p></li>
<li id="fn3"><p>Lift measures how much more likely the consequent (Y) is when the antecedent (X) is present, compared to when the antecedent is absent.</p>
<p><span class="math display">\[\text{Lift}(X \rightarrow Y) = \frac{\text{Confidence}(X \rightarrow Y)}{\text{Support}(Y)}\]</span></p>
<p>Where:</p>
<p><span class="math display">\[\text{Confidence}(X \rightarrow Y) = \frac{\text{Support}(X \text{ and } Y)}{\text{Support}(X)}\]</span> <span class="math display">\[\text{Support}(Y) = \frac{\text{Count}(Y)}{\text{Total Transactions}}\]</span></p>
<p>Interpretation:<br>
Lift &gt; 1: Positive correlation (products appear together more than expected by chance)<br>
Lift = 1: No correlation (independence)<br>
Lift &lt; 1: Negative correlation (products appear together less than expected by chance)</p></li>
<li id="fn4"><p>Example for reward hackin:, a reinforcement learning agent tasked with playing a video game might discover an unintended bug that produces high scores without completing the actual objective. Rather than learning the intended gameplay strategy, it optimizes for exploiting this glitch.</p></li>
</ol>
</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: false,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1080,

        height: 640,

        // Factor of the display size that should remain empty around the content
        margin: 0,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script>
    // Copy over background colors to new div
    divs = document.querySelectorAll('[data-background-color]');

    Array.from(divs).map(function (x) {
      const color = x.dataset.backgroundColor;

      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-color-div");
      new_div.style.backgroundColor = color;
      x.appendChild(new_div);
      x.removeAttribute("data-background-color");
    })

    // Remove background colors from backgrounds div
    Array.from(
      document.querySelectorAll("[data-background-hash]")
    ).map(function (x) {
      x.removeAttribute("data-background-hash");
      x.style.backgroundColor = null;
    })
    </script>

    <script>
    // Copy over background images to new div
    divs = document.querySelectorAll('[data-background-image]');

    Array.from(divs).map(function (x) {
      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-image-div");

      if (x.dataset.backgroundImage != undefined) {
        new_div.style.backgroundImage = "url(" + x.dataset.backgroundImage + ")";
        x.removeAttribute("data-background-image");
      }
      if (x.dataset.backgroundSize != undefined) {
        new_div.style.backgroundSize = x.dataset.backgroundSize;
        x.removeAttribute("data-background-size");
      }
      if (x.dataset.backgroundPosition != undefined) {
        new_div.style.backgroundPosition = x.dataset.backgroundPosition;
        x.removeAttribute("data-background-position");
      }
      if (x.dataset.backgroundRepeat != undefined) {
        new_div.style.backgroundRepeat = x.dataset.backgroundRepeat;
        x.removeAttribute("data-background-repeat");
      }
      if (x.dataset.backgroundOpacity != undefined) {
        new_div.style.backgroundOpacity = x.dataset.backgroundOpacity;
        x.removeAttribute("data-background-opacity");
      }

      x.appendChild(new_div);
    })
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var video_div = document.querySelectorAll(".backgrounds video");
    var slide_div = document.querySelectorAll("[data-background-video]");

    for (let i = 0; i < video_div.length; i++) {
      video_div[i].setAttribute("class", "background-video-div");

      slide_div[i].appendChild(video_div[i]);
      slide_div[i].removeAttribute("data-background-video");
    }

    Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var video_div = document.querySelectorAll(".backgrounds video");
      var slide_div = document.querySelectorAll("[data-background-video]");

      for (let i = 0; i < video_div.length; i++) {
        video_div[i].setAttribute("class", "background-video-div");

        slide_div[i].appendChild(video_div[i]);
        slide_div[i].removeAttribute("data-background-video");
      }

      Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());
    });
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var iframe_div = document.querySelectorAll(".backgrounds iframe");
    var slide_div = document.querySelectorAll("[data-background-iframe]");

    for (let i = 0; i < iframe_div.length; i++) {
      iframe_div[i].setAttribute("class", "background-iframe-div");

      slide_div[i].appendChild(iframe_div[i]);
      slide_div[i].removeAttribute("data-background-iframe");
    }

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var iframe_div = document.querySelectorAll(".backgrounds iframe");
      var slide_div = document.querySelectorAll("[data-background-iframe]");

      for (let i = 0; i < iframe_div.length; i++) {
        iframe_div[i].setAttribute("class", "background-iframe-div");

        slide_div[i].appendChild(iframe_div[i]);
        slide_div[i].removeAttribute("data-background-iframe");
      }
    });
    </script>

    <script>
    // Clean up slide background styles
    divs = document.querySelectorAll('.slide-background-content');
    Array.from(divs).map(function (x) {
      x.style = null;
    })
    </script>

    <script>

      // Move menu button
      menu_div = document.querySelector(".slide-menu-button");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move progress bar
      menu_div = document.querySelector(".progress");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move slide number
      slide_number = document.querySelector(".slide-number");
      document.querySelector(".slides").appendChild(slide_number);
      
      // Move custom footer
      footer = document.querySelector(".footer.custom");
      document.querySelector(".slides").appendChild(footer);

    </script>

    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/awe-hnu\.github\.io");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>