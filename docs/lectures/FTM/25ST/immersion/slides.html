<!DOCTYPE html>
<html lang="en"><head>
<link href="../../../../assets/favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Andy Weeger">
  <meta name="dcterms.date" content="2025-02-21">
  <title>awe.lectures – Multimodality and Immersion</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../../../site_libs/revealjs/dist/theme/quarto-206a2b3b200a6941b9e8d9db4436c6d1.css">
  
  <script type="text/javascript" charset="UTF-8">
  document.addEventListener('DOMContentLoaded', function () {
  cookieconsent.run({
    "notice_banner_type":"interstitial",
    "consent_type":"express",
    "palette":"dark",
    "language":"en",
    "page_load_consent_levels":["strictly-necessary"],
    "notice_banner_reject_button_hide":false,
    "preferences_center_close_button_hide":false,
    "website_name":""
    ,
  "language":"en"
    });
  });
  </script> 
    
  <link href="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Multimodality and Immersion – awe.lectures">
<meta property="og:description" content="Future Technologies &amp; Media (FTM)">
<meta property="og:site_name" content="awe.lectures">
</head>
<body class="quarto-light">
<div class="footer custom">

    <div class="version">
        V1.1
    </div>

    <div class="footnote">
        Andy Weeger / Neu-Ulm University of Applied Sciences Neu-Ulm / Future Technologies and Media (FTM)
   </div>

    <div class="logo">
        <svg viewbox="0 0 125 39" xmlns="http://www.w3.org/2000/svg" version="1.1" space="preserve">
            <g>
             <title>HNU</title>
             <path d="m8.58222,0l7.5,0l0,12.7l-7.5,0l0,-12.7zm7.4,24.1l6.5,0l0,-3l-13.9,0l0,15.4l-3.9,0l0,2.3l11.3,0l0,-14.7zm24,-24.1l-7.4,0l0,36.5l-3.9,0l0,2.3l11.3,0l0,-38.8zm60.2,28.4c1.1,0 2.1,-0.1 2.9,-0.4c-1.3,-1.2 -1.9,-3.2 -1.9,-6.4l0,-21.6l-7.4,0l0,19.3c0,5.9 1.5,9.1 6.4,9.1z" id="svg_1"></path>
             <path d="m96.78222,37c2.8,1.6 6.4,2.5 10.6,2.5c11.2,0 17.7,-6 17.7,-16.3l0,-23.2l-7.4,0l0,21.1c0,11.3 -7.7,16.1 -17.6,16.1c-1.1,0 -2.2,-0.1 -3.3,-0.2zm-30.8,-27l-7.1,-10l-7.3,0l14.4,20.4l0,-10.4zm17,28.8l0,-38.8l-7.5,0l0,36.5l-3.5,0l1.7,2.3l9.3,0zm-24,-14.8l-8,-10.8l0,23.3l-3,0l0,2.3l11,0l0,-14.8z" id="svg_2"></path>
            </g>   
        </svg>
    </div>

</div>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-color="#0333ff" data-background-image="../assets/bg.jpg" data-background-opacity="1" data-background-size="cover" class="quarto-title-block">
  <h1 class="title">Multimodality and Immersion</h1>
  <p class="subtitle">Future Technologies &amp; Media (FTM)</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Andy Weeger 
</div>
        <p class="quarto-title-affiliation">
            Neu-Ulm University of Applied Sciences
          </p>
    </div>
</div>

  <p class="date">February 21, 2025</p>
</section>
<section>
<section id="revision" class="title-slide slide level1 headline-only vertical-center" data-background-color="#0333ff">
<h1>Revision</h1>
<!--

Schedule:

- Warm-up         10 min
- Recap           10 min
- Multimodality   60 min

PAUSE

- Immersion Part 1
- Homework       30 min (20 + 10)
- Immersion Part 2

PAUSE

- Immersion final exercise

For preparation watch:
https://www.youtube.com/watch?v=HMdFK-53z1w&t=13s

-->
</section>
<section id="characteristics-of-emerging-technologies" class="title-slide slide level2">
<h2>Characteristics of emerging technologies</h2>
<p><span class="citation" data-cites="rotolo2015emerging">Rotolo, Hicks, and Martin (<a href="#/literature" role="doc-biblioref" onclick="">2015</a>)</span> outlines five attributes that classify emerging technologies and differentiate them from other technologies:</p>
<div class="medium">
<div>
<ol type="1">
<li class="fragment">Radical novelty<br>
</li>
<li class="fragment">Relatively fast growth<br>
</li>
<li class="fragment">Coherence<br>
</li>
<li class="fragment">Prominent impact<br>
</li>
<li class="fragment">Uncertainty and ambiguity<br>
</li>
</ol>
</div>
</div>
</section>

<section id="stages-of-emergence" class="title-slide slide level2">
<h2>Stages of emergence</h2>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="../introduction/images/emergence.svg" height="420"></p>
<figcaption>Pre-emergence, emergence, and post-emergence: attributes and ’stylised’trends. <span class="citation" data-cites="rotolo2015emerging">(<a href="#/literature" role="doc-biblioref" onclick="">Rotolo, Hicks, and Martin 2015, 1833</a>)</span></figcaption>
</figure>
</div>
</section>

<section id="the-steam-enginge" class="title-slide slide level2">
<h2>The steam enginge</h2>
<div class="medium link-color">
<p>During the late 18th century and the early 19th century, the steam engine was considered an emerging technology.</p>
</div>
<div class="fragment">
<p><strong>Why?</strong></p>
<aside class="notes">
<ul>
<li><strong>Radical novelty:</strong> Steam enginges represented a significant departure from previous methods of power generation (e.g., such as human or animal labor).</li>
<li><strong>Relatively fast growth:</strong> Once the potential of steam power was realized, the adoption and diffusion of steam engines spread rapidly across various industries and regions.</li>
<li><strong>Coherence:</strong> The development of the steam engine was part of a coherent technological trajectory.</li>
<li><strong>Prominent impact:</strong> The steam engine had a profound impact on society, economy, and culture (i.e., the Industrial Revolution)</li>
<li><strong>Uncertainty and ambiguity:</strong> In its early stages of development, the steam engine faced uncertainty and ambiguity regarding its reliability, efficiency, and practical applications.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>

<section id="artificial-intelligence" class="title-slide slide level2">
<h2>Artificial Intelligence</h2>
<div class="medium link-color">
<p>Tech classified as AI definitely qualify as emergent technologies.</p>
</div>
<div>
<ul>
<li class="fragment"><strong>Radical novelty:</strong> While the underlying concepts of AI have been around for decades, its current applications are truly groundbreaking.</li>
<li class="fragment"><strong>Relatively fast growth:</strong> New advancements and discoveries are happening at an incredible pace, pushing the boundaries of what’s possible.</li>
<li class="fragment"><strong>Coherence:</strong> AI research isn’t happening in isolation. It draws on various disciplines like computer science, mathematics, linguistics, and neuroscience.</li>
<li class="fragment"><strong>Prominent impact:</strong> AI is transforming industries and shaping the future in a significant way. Its influence is felt in healthcare, finance, entertainment, and countless other sectors.</li>
<li class="fragment"><strong>Uncertainty and ambiguity:</strong> The full potential and limitations of AI are still being explored as well as the manifold ethical concerns.</li>
</ul>
</div>
</section>

<section id="discussion" class="title-slide slide level2 discussion-slide">
<h2>Discussion</h2>
<div class="large">
<p>What are <strong>distinct characteristics</strong> of emerging technologies in the digital age?</p>
</div>
</section>
</section>
<section id="hypothesis-1" class="title-slide slide level1" data-background-color="#0333ff">
<h1>Hypothesis 1</h1>
<div class="large">
<p>Emerging information technologies enable <strong>multimodal</strong> and <strong>immersive</strong> experiences.</p>
</div>
</section>

<section>
<section id="multimodality" class="title-slide slide level1 headline-only">
<h1>Multimodality</h1>

</section>
<section id="discussion-1" class="title-slide slide level2 discussion-slide">
<h2>Discussion</h2>
<div class="medium">
<p>Which <strong>senses</strong> have you used when you have interacted with (information) technology?</p>
</div>
<p>Give examples.</p>
</section>

<section id="how-the-computer-sees-us." class="title-slide slide level2 headline-only" data-background-color="#f4f4f4" data-background-image="images/howComputerSeeUs.jpg">
<h2>How the <br> computer <br> sees us.</h2>
<div class="smaller">
<p>For traditional computers, humans are reduced to an eye and a finger.<br>
Courtesy Dan O’Sullivan and Tom Igoe.</p>
</div>
</section>

<section id="multimodality-definition" class="title-slide slide level2 no-headline vertical-center">
<h2>Multimodality — definition</h2>
<div class="xlarge">
<p><span class="fragment" data-fragment-index="1">Multi</span><span class="link-color fragment" data-fragment-index="2">modality</span></p>
</div>
<p><span class="fragment" data-fragment-index="1">Using more than one</span> <span class="link-color fragment" data-fragment-index="2">mode of communication to create meaning.</span></p>
<div class="fragment">
<p>Multimodality emphasizes the importance of multiple modes (e.g., verbal, visual, spatial) to form overall understanding of a message.</p>

</div>
<aside><div>
<p><span class="citation" data-cites="adami2016introducing">Adami (<a href="#/literature" role="doc-biblioref" onclick="">2016</a>)</span></p>
</div></aside></section>

<section id="multimedia-definition" class="title-slide slide level2 no-headline vertical-center">
<h2>Multimedia — definition</h2>
<div class="xlarge">
<p><span class="fragment" data-fragment-index="1">Multi</span><span class="link-color fragment" data-fragment-index="2">media</span></p>
</div>
<p><span class="fragment" data-fragment-index="1">Using more than one</span> <span class="fragment" data-fragment-index="2"><span class="link-color">media to express meaning</span>.</span></p>
<div class="fragment">
<p>Multimedia emphasizes the medium or technology used to present information.<br>
It refers to content that uses two or more media formats.</p>

<aside class="notes">
<p>Here’s an analogy: Think of multimedia like a toolbox with different tools (text, images, audio, etc.). Multimodal is about how you use those tools together to build something meaningful.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<aside><div>
<p><span class="citation" data-cites="adami2016introducing">Adami (<a href="#/literature" role="doc-biblioref" onclick="">2016</a>)</span></p>
</div></aside></section>

<section id="distinction" class="title-slide slide level2">
<h2>Distinction</h2>
<p><span class="large">Every <strong>multimodal</strong> project is multimedia</span><br>
<span class="fragment link-color">as it uses multiple methods.</span></p>
<p><span class="large">Not every <strong>multimedia</strong> project is multimodal</span><br>
<span class="fragment link-color">as it might just throw different media together without considering how they work together.</span></p>
</section>

<section id="reading" class="title-slide slide level2" data-background-color="#000" data-background-image="images/reading.jpg">
<h2>Reading</h2>

<aside><div>
<p>Image from unsplash</p>
</div></aside></section>

<section id="writing" class="title-slide slide level2" data-background-color="#000" data-background-image="images/writing.jpg">
<h2>Writing</h2>

<aside><div>
<p>Image from unsplash</p>
</div></aside></section>

<section id="texting" class="title-slide slide level2" data-background-color="#000" data-background-image="images/texting.jpg">
<h2>Texting</h2>

<aside><div>
<p>Image from unsplash</p>
</div></aside></section>

<section id="multimodal-interactions-are-natural" class="title-slide slide level2 headline-only">
<h2>Multimodal interactions <br> are natural</h2>

</section>

<section id="usage-of-modalities-in-current-computer-systems" class="title-slide slide level2 unlisted" data-background-image="images/computer-modalities-0.svg">
<h2>Usage of modalities in current computer systems</h2>

</section>

<section id="usage-of-modalities-in-current-computer-systems-1" class="title-slide slide level2" data-background-image="images/computer-modalities.svg">
<h2>Usage of modalities in current computer systems</h2>

</section>

<section id="advantages-of-multimodal-systems" class="title-slide slide level2">
<h2>Advantages of multimodal systems</h2>
<div class="medium">
<p><span class="fragment fade-in-then-semi-out">Improved accuracy and robustness,</span> <span class="fragment fade-in-then-semi-out">enhanced bandwidth,</span> <span class="fragment fade-in-then-semi-out">flexibility and user preference,</span> <span class="fragment fade-in-then-semi-out">naturalness and ease of use,</span> <span class="fragment fade-in-then-semi-out">redundancy and error correction,</span> <span class="fragment fade-in-then-semi-out">accessibility,</span> <span class="fragment fade-in-then-semi-out">support for complex tasks.</span></p>
</div>

<aside class="notes">
<dl>
<dt>Improved accuracy and robustness</dt>
<dd>
Multimodal systems can enhance accuracy and robustness by integrating multiple modalities, such as speech, gesture, and touch, which can compensate for limitations in individual modalities. Example: medical diagnosis assistant (verbal description, medical imaging, history, sensor data)
</dd>
<dt>Enhanced bandwidth</dt>
<dd>
By utilizing multiple modalities simultaneously, multimodal systems can provide users with a higher bandwidth of interaction, allowing for more efficient communication and interaction. Example: autonomous vehicle navigation (LIDAR, Radar, GPS, Camera Vision)
</dd>
<dt>Flexibility and user preference</dt>
<dd>
Multimodal systems offer users the flexibility to choose the most convenient modality for interaction based on their preferences, abilities, and the context of the task. Example: smart home assistant (voice, touch, gesture, mobile app)
</dd>
<dt>Naturalness and ease of use</dt>
<dd>
Integrating multiple modalities can make interaction with technology more natural and intuitive, mimicking the way humans naturally communicate and interact with each other. Example: language learning application
</dd>
<dt>Redundancy and error correction</dt>
<dd>
Multiple modalities provide redundancy in input, allowing for error detection and correction. For example, if one modality fails or is misunderstood, other modalities can provide additional context or clarification. Example: speach recognition system (audio, lip reading, facial expression)
</dd>
<dt>Accessibility</dt>
<dd>
Multimodal systems can improve accessibility for users with diverse abilities and preferences by offering multiple modes of interaction that cater to different needs and capabilities.
</dd>
<dt>Support for complex tasks</dt>
<dd>
Combining multiple modalities can support complex tasks that require different types of input or involve multiple steps, allowing users to interact with technology in a more efficient and effective manner. Example: surgical robotic system (hand movement, 3D medical imaging, patien vital signs, AR)
</dd>
</dl>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="oviatt1999ten">Oviatt (<a href="#/literature" role="doc-biblioref" onclick="">1999</a>)</span></p>
</div></aside></section>

<section id="exercise" class="title-slide slide level2 discussion-slide">
<h2>Exercise</h2>
<div class="medium">
<p>Modality examples</p>
</div>
<p>Break down the multimodal interactions across visual, auditory, and haptic modalities for both input and output, distinguishing between data (i.e., the contents of the interaction) and control aspects (i.e., information that is needed to make the interaction happen).</p>
<p>Take 15 minutes to find examples for <strong>data input</strong>, <strong>control input</strong>, <strong>data output</strong>, and <strong>control output</strong> for each modality.</p>
<aside class="notes">
<p><span class="h4">Visual Modalities</span></p>
<p><strong>Data Input</strong></p>
<ul>
<li>Reading text from documents</li>
<li>Image recognition (identifying objects, faces, scenes)</li>
<li>Gesture recognition</li>
<li>Tracking eye movements</li>
<li>Scanning QR codes or barcodes</li>
</ul>
<p><strong>Control Input</strong></p>
<ul>
<li>Mouse pointer movement</li>
<li>Cursor selection</li>
<li>Touch screen gestures</li>
<li>Blinking to select</li>
<li>Gaze-based interface navigation</li>
</ul>
<p><strong>Data Output</strong></p>
<ul>
<li>Displaying text</li>
<li>Rendering images and graphics</li>
<li>Video playback</li>
<li>Data visualizations</li>
<li>Augmented reality overlays</li>
</ul>
<p><strong>Control Output</strong></p>
<ul>
<li>Highlighting selected items</li>
<li>Progress bars</li>
<li>Color-coded status indicators</li>
<li>Cursor changes</li>
<li>Visual feedback animations</li>
</ul>
<p><span class="h4">Auditory Modalities</span></p>
<p><strong>Data Input</strong></p>
<ul>
<li>Speech recognition</li>
<li>Voice commands</li>
<li>Musical input</li>
<li>Environmental sound detection</li>
<li>Language translation</li>
</ul>
<p><strong>Control Input</strong></p>
<ul>
<li>Volume control via voice</li>
<li>Selecting options through audio cues</li>
<li>Pitch and tone-based commands</li>
<li>Whisper or silent speech recognition</li>
<li>Audio-based authentication</li>
</ul>
<p><strong>Data Output</strong></p>
<ul>
<li>Text-to-speech conversion</li>
<li>Music playback</li>
<li>Sound effects</li>
<li>Audiobooks</li>
<li>Language pronunciation guidance</li>
</ul>
<p><strong>Control Output</strong></p>
<ul>
<li>Confirmation beeps</li>
<li>Error sounds</li>
<li>Navigation audio cues</li>
<li>Volume and pitch changes</li>
<li>Audio feedback for interactions</li>
</ul>
<p><span class="h4">Haptic Modalities</span></p>
<p><strong>Data Input</strong></p>
<ul>
<li>Touch screen interactions</li>
<li>Pressure-sensitive input</li>
<li>Gesture recognition</li>
<li>Handwriting recognition</li>
<li>Tactile sensing for object identification</li>
</ul>
<p><strong>Control Input</strong></p>
<ul>
<li>Swipe gestures</li>
<li>Pinch-to-zoom</li>
<li>Pressure-based selection</li>
<li>Vibration patterns for input</li>
<li>Tactile input for accessibility</li>
</ul>
<p><strong>Data Output</strong></p>
<ul>
<li>Vibration patterns representing information</li>
<li>Texture simulation</li>
<li>Force feedback in games</li>
<li>Medical training simulations</li>
<li>Braille displays</li>
</ul>
<p><strong>Control Output</strong></p>
<ul>
<li>Confirmation vibrations</li>
<li>Error alerts</li>
<li>Navigation guidance</li>
<li>Intensity-based feedback</li>
<li>Accessibility cues for visually impaired users</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="fundamental-problems" class="title-slide slide level2">
<h2>Fundamental problems</h2>
<div class="fragment">
<div class="medium">
<p><span class="link-color">Multimodal fusion</span></p>
</div>
<div class="fragment">
<p>The integration of communication modalities in interactive systems (Input)</p>
</div>
<div class="medium">
<p>and</p>
</div>
<div class="medium">
<p><span class="link-color">Multimodal fission</span></p>
</div>
<div class="fragment">
<p>The re-partitioning of information among several communication modalities (Output)</p>
</div>
</div>
</section>

<section id="human-machine-interaction-loop" class="title-slide slide level2">
<h2>Human-machine interaction loop</h2>
<div class="r-stack html-hidden">
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/mmi-1.svg" class="fragment" height="420"></p>
<figcaption>A representation of multimodal man machine interaction loop based on <span class="citation" data-cites="dumas2009multimodal">Dumas, Lalanne, and Oviatt (<a href="#/literature" role="doc-biblioref" onclick="">2009, 8</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/mmi-2.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/mmi-3.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/mmi-4.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/mmi-5.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/mmi-6.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/mmi.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
</div>
<aside class="notes">
<dl>
<dt>Data level</dt>
<dd>
e.g., combining 2 webcam video streams, multiple perspectives
</dd>
<dt>Feature level</dt>
<dd>
e.g., combining extracted features such as speech and lip movements
</dd>
<dt>Decision level</dt>
<dd>
e.g., combining interpretations such as gestures and sentiment of speech
</dd>
</dl>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>

<section id="exercise-1" class="title-slide slide level2 discussion-slide">
<h2>Exercise</h2>
<div class="medium">
<p>Find specific examples for multimodal technologies (i.e., products).</p>
</div>
<p>Take 10 minutes for your research. Prepare to present your findings.</p>
</section>

<section id="multimodal-ai-in-action" class="title-slide slide level2" data-background-color="#000">
<h2>Multimodal AI in action</h2>
<iframe width="900" height="400" src="https://www.youtube.com/embed/pEmCgIGpIoo?si=K4SUhMpx10G_dbus" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>

<section id="example-multimodal-ai" class="title-slide slide level2" data-background-color="#000">
<h2>Example: Multimodal AI</h2>
<iframe width="900" height="400" src="https://www.youtube.com/embed/UIZAiXYceBI?si=BiuG6ewTQKqigXXK" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
</section>
<section>
<section id="immersiveness" class="title-slide slide level1 headline-only">
<h1>Immersiveness</h1>

</section>
<section id="homework" class="title-slide slide level2" data-background-color="#f4f4f4">
<h2>Homework</h2>
<p>Form small groups and synthesize your findings from reading <span class="citation" data-cites="suh2018state">Suh and Prophet (<a href="#/literature" role="doc-biblioref" onclick="">2018</a>)</span> by findings answers to following questions:</p>
<ol type="1">
<li>How can immersive technology be defined?</li>
<li>What are examples of immersive technology provided in the paper?</li>
<li>What technological features are key to enhancing user experience in immersive environments?</li>
<li>How does immersiveness relate to multimodality?</li>
<li>What fields of application are revealed in the paper?</li>
</ol>
<p>Take 20 minutes to synthesize your findings and to create a short presentation.</p>
</section>

<section id="immersion" class="title-slide slide level2">
<h2>Immersion</h2>
<div class="medium">
<p>Immersion refers to the state of <span class="link-color">being deeply engaged, absorbed, or submerged in an environment</span>, either physically or mentally.</p>
</div>
<div class="fragment">
<p>Immersion implies that the consciousness of the immersed person is detached from their physical self. Immersiveness is the quality or degree of being immersive.</p>

</div>
<aside><div>
<p><span class="citation" data-cites="suh2018state">Suh and Prophet (<a href="#/literature" role="doc-biblioref" onclick="">2018</a>)</span>, <span class="citation" data-cites="lee2013presence">Lee, Chung, and Lee (<a href="#/literature" role="doc-biblioref" onclick="">2013</a>)</span></p>
</div></aside></section>

<section id="immersion-in-games" class="title-slide slide level2" data-background-color="#000" data-background-image="images/immersion.jpg">
<h2>Immersion in games</h2>

<aside><div>
<div class="medium">
<p>From <strong>engagement</strong> (e.g.: invest time, effort , and attention in the game) to<br>
<strong>engrossment</strong> (e.g.&nbsp;invest a high level of emotion in the game) to<br>
total <strong>immersion</strong> (e.g.fully present and empathize with the game) <span class="citation" data-cites="Sunyaev2020IC">(<a href="#/literature" role="doc-biblioref" onclick="">Sunyaev 2020</a>)</span>.</p>
</div>
<p>Image from unsplash</p>
</div></aside></section>

<section id="immersive-technology" class="title-slide slide level2">
<h2>Immersive technology</h2>
<div class="medium">
<p>Immersive technology <span class="link-color">blurs the line between the physical, virtual, and simulated worlds</span>, thereby creating a sense of immersion.</p>
</div>
<div class="fragment">
<p>Technology has different abilities to create a sense of presence and engagement in the user.</p>

</div>
<aside><div>
<p><span class="citation" data-cites="lee2013presence">Lee, Chung, and Lee (<a href="#/literature" role="doc-biblioref" onclick="">2013</a>)</span>, <span class="citation" data-cites="handa2012immersive">Handa, Aul, and Bajaj (<a href="#/literature" role="doc-biblioref" onclick="">2012</a>)</span></p>
</div></aside></section>

<section id="mechanisms" class="title-slide slide level2">
<h2>Mechanisms</h2>
<div class="medium">
<p>The feeling of immersion is created by <strong>temporarily altering a person’s sense of presence</strong> by tricking their cognitive and perceptual systems into believing they are in a place other than their actual physical location.</p>
</div>

<aside><div>
<p><span class="citation" data-cites="milgram1994taxonomy">Milgram and Kishino (<a href="#/literature" role="doc-biblioref" onclick="">1994</a>)</span></p>
</div></aside></section>

<section id="virtuality-continuum" class="title-slide slide level2">
<h2>Virtuality continuum</h2>
<div class="r-stack html-hidden">
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/virtuality-continuum-1.svg" class="fragment" height="420"></p>
<figcaption>Simplified representation of a “virtuality continuum” based on <span class="citation" data-cites="milgram1994taxonomy">Milgram and Kishino (<a href="#/literature" role="doc-biblioref" onclick="">1994</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/virtuality-continuum-2.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/virtuality-continuum.svg" class="fragment" height="420"></p>
<figcaption>&nbsp;</figcaption>
</figure>
</div>
</div>
</section>

<section id="stimuly" class="title-slide slide level2">
<h2>Stimuly</h2>
<p>Important stimuli that determine the immersiveness of environments created by technology are</p>
<div class="medium">
<p><span class="fragment fade-in-then-semi-out">Visual stimuly,</span> <span class="fragment fade-in-then-semi-out">auditory stimuly,</span> <span class="fragment fade-in-then-semi-out">tactile stimuli,</span> <span class="fragment fade-in-then-semi-out">olfactory stimuly, and</span> <span class="fragment fade-in-then-semi-out">interactive stimuly.</span></p>
</div>
<div class="fragment">
<p>In order to create these, technology needs <strong>visual display</strong> with hihg representational fidelity and media, <strong>auditory and haptic interfaces</strong> and the capability to <strong>track movements</strong>.</p>

</div>
<aside><div>
<p>Summary based on the findings on sensory and perceptual stimuly by <span class="citation" data-cites="suh2018state">Suh and Prophet (<a href="#/literature" role="doc-biblioref" onclick="">2018</a>)</span>.</p>
</div></aside></section>

<section id="augmented-reality-ar" class="title-slide slide level2">
<h2>Augmented reality (AR)</h2>
<div class="fragment" data-fragment-index="1">
<div class="medium">
<p>Augmented reality refers to the <span class="link-color">combination of a real scene</span> viewed by a user <span class="link-color">with a virtual scene</span> that augments the scene with additional information.</p>
</div>
</div>
<div class="fragment" data-fragment-index="2">
<p><span class="link-color">AR technology</span> superimposes virtual objects onto a live view of physical environments, helping users visualize how these objects fit into their physical world.</p>
</div>

<aside><div>
<div class="fragment" data-fragment-index="2">
<p><span class="citation" data-cites="milgram1994taxonomy">Milgram and Kishino (<a href="#/literature" role="doc-biblioref" onclick="">1994</a>)</span></p>
</div>
</div></aside></section>

<section id="hardware-components" class="title-slide slide level2">
<h2>Hardware components</h2>
<p>AR technologies require following hardware components:</p>
<div>
<ol type="1">
<li class="fragment">Devices for displaying the virtual objects</li>
<li class="fragment">Input devices to detect users’ interaction with the real and virtual object</li>
<li class="fragment">Sensors to capture users’ positions and movements</li>
<li class="fragment">Computing devices that combine the input data and create the virtual overlays</li>
</ol>
</div>
<div class="fragment">
<p>Advancements in mobile computing and telecommunications infrastructures (will) increase the mobility and, thus, usability of these devices significantly.</p>

</div>
<aside><div>
<p><span class="citation" data-cites="Sunyaev2020IC">Sunyaev (<a href="#/literature" role="doc-biblioref" onclick="">2020</a>)</span></p>
</div></aside></section>

<section id="exercise-2" class="title-slide slide level2 discussion-slide">
<h2>Exercise</h2>
<div class="medium">
<p>What are examples of AR technologies?</p>
</div>
<p>Briefly introduce the example and name application fields and benefits.</p>
</section>

<section id="virtual-reality-ar" class="title-slide slide level2">
<h2>Virtual reality (AR)</h2>
<div class="fragment" data-fragment-index="1">
<div class="medium">
<p>Virtual Reality refers to technology that <span class="link-color">generates an interactive virtual environment</span> that is designed to simulate a <span class="link-color">real life experience</span>.</p>
</div>
</div>
<div class="fragment" data-fragment-index="2">
<p><span class="link-color">VR technology</span> reveals different levels of immersion ranging from non-immersive VR (e.g., second life) to immersive VR (e.g., PlayStation VR2).</p>
</div>

<aside><div>
<div class="fragment" data-fragment-index="2">
<p><span class="citation" data-cites="suh2018state">Suh and Prophet (<a href="#/literature" role="doc-biblioref" onclick="">2018</a>)</span>, <span class="citation" data-cites="milgram1994taxonomy">Milgram and Kishino (<a href="#/literature" role="doc-biblioref" onclick="">1994</a>)</span></p>
</div>
</div></aside></section>

<section id="exercise-3" class="title-slide slide level2 discussion-slide">
<h2>Exercise</h2>
<div class="medium">
<p>Search for immersive technologies used in the healthcare context.</p>
</div>
<p>Take 15 minutes to research and portray a technology as well as to discuss the reasons for the prominent impact of immersive technologies in the healthcare context. Prepare yourself to present your findings.</p>
</section>
</section>
<section id="qa" class="title-slide slide level1 html-hidden unlisted headline-only vertical-center" data-background-color="#0333ff" data-background-image="../assets/bg.jpg">
<h1>Q&amp;A</h1>

</section>

<section id="literature" class="title-slide slide level1 smaller scrollable">
<h1>Literature</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-adami2016introducing" class="csl-entry" role="listitem">
Adami, Elisabetta. 2016. <span>“Introducing Multimodality.”</span> <em>The Oxford Handbook of Language and Society</em>, 451–72.
</div>
<div id="ref-dumas2009multimodal" class="csl-entry" role="listitem">
Dumas, Bruno, Denis Lalanne, and Sharon Oviatt. 2009. <span>“Multimodal Interfaces: A Survey of Principles, Models and Frameworks.”</span> In <em>Human Machine Interaction: Research Results of the Mmi Program</em>, 3–26. Springer.
</div>
<div id="ref-handa2012immersive" class="csl-entry" role="listitem">
Handa, Mandeep, Er Gagandeep Aul, and Shelja Bajaj. 2012. <span>“Immersive Technology–Uses, Challenges and Opportunities.”</span> <em>International Journal of Computing &amp; Business Research</em> 6 (2): 1–11.
</div>
<div id="ref-lee2013presence" class="csl-entry" role="listitem">
Lee, Hyuck-Gi, Sungwon Chung, and Won-Hee Lee. 2013. <span>“Presence in Virtual Golf Simulators: The Effects of Presence on Perceived Enjoyment, Perceived Value, and Behavioral Intention.”</span> <em>New Media &amp; Society</em> 15 (6): 930–46.
</div>
<div id="ref-milgram1994taxonomy" class="csl-entry" role="listitem">
Milgram, Paul, and Fumio Kishino. 1994. <span>“A Taxonomy of Mixed Reality Visual Displays.”</span> <em>IEICE TRANSACTIONS on Information and Systems</em> 77 (12): 1321–29.
</div>
<div id="ref-oviatt1999ten" class="csl-entry" role="listitem">
Oviatt, Sharon. 1999. <span>“Ten Myths of Multimodal Interaction.”</span> <em>Communications of the ACM</em> 42 (11): 74–81.
</div>
<div id="ref-rotolo2015emerging" class="csl-entry" role="listitem">
Rotolo, Daniele, Diana Hicks, and Ben R Martin. 2015. <span>“What Is an Emerging Technology?”</span> <em>Research Policy</em> 44 (10): 1827–43.
</div>
<div id="ref-suh2018state" class="csl-entry" role="listitem">
Suh, Ayoung, and Jane Prophet. 2018. <span>“The State of Immersive Technology Research: A Literature Analysis.”</span> <em>Computers in Human Behavior</em> 86: 77–90.
</div>
<div id="ref-Sunyaev2020IC" class="csl-entry" role="listitem">
Sunyaev, Ali. 2020. <em>Internet Computing: Principles of Distributed Systems and Emerging Internet-Based Technologies</em>. 1st ed. Springer Nature Switzerland AG.
</div>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: false,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1080,

        height: 640,

        // Factor of the display size that should remain empty around the content
        margin: 0,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script>
    // Copy over background colors to new div
    divs = document.querySelectorAll('[data-background-color]');

    Array.from(divs).map(function (x) {
      const color = x.dataset.backgroundColor;

      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-color-div");
      new_div.style.backgroundColor = color;
      x.appendChild(new_div);
      x.removeAttribute("data-background-color");
    })

    // Remove background colors from backgrounds div
    Array.from(
      document.querySelectorAll("[data-background-hash]")
    ).map(function (x) {
      x.removeAttribute("data-background-hash");
      x.style.backgroundColor = null;
    })
    </script>

    <script>
    // Copy over background images to new div
    divs = document.querySelectorAll('[data-background-image]');

    Array.from(divs).map(function (x) {
      var new_div = document.createElement('div');
      new_div.setAttribute("class", "background-image-div");

      if (x.dataset.backgroundImage != undefined) {
        new_div.style.backgroundImage = "url(" + x.dataset.backgroundImage + ")";
        x.removeAttribute("data-background-image");
      }
      if (x.dataset.backgroundSize != undefined) {
        new_div.style.backgroundSize = x.dataset.backgroundSize;
        x.removeAttribute("data-background-size");
      }
      if (x.dataset.backgroundPosition != undefined) {
        new_div.style.backgroundPosition = x.dataset.backgroundPosition;
        x.removeAttribute("data-background-position");
      }
      if (x.dataset.backgroundRepeat != undefined) {
        new_div.style.backgroundRepeat = x.dataset.backgroundRepeat;
        x.removeAttribute("data-background-repeat");
      }
      if (x.dataset.backgroundOpacity != undefined) {
        new_div.style.backgroundOpacity = x.dataset.backgroundOpacity;
        x.removeAttribute("data-background-opacity");
      }

      x.appendChild(new_div);
    })
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var video_div = document.querySelectorAll(".backgrounds video");
    var slide_div = document.querySelectorAll("[data-background-video]");

    for (let i = 0; i < video_div.length; i++) {
      video_div[i].setAttribute("class", "background-video-div");

      slide_div[i].appendChild(video_div[i]);
      slide_div[i].removeAttribute("data-background-video");
    }

    Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var video_div = document.querySelectorAll(".backgrounds video");
      var slide_div = document.querySelectorAll("[data-background-video]");

      for (let i = 0; i < video_div.length; i++) {
        video_div[i].setAttribute("class", "background-video-div");

        slide_div[i].appendChild(video_div[i]);
        slide_div[i].removeAttribute("data-background-video");
      }

      Reveal.getCurrentSlide().querySelectorAll(".background-video-div").forEach(x => x.play());
    });
    </script>

    <script>
    // Copy over background vidoes

    // Run once when we load
    var iframe_div = document.querySelectorAll(".backgrounds iframe");
    var slide_div = document.querySelectorAll("[data-background-iframe]");

    for (let i = 0; i < iframe_div.length; i++) {
      iframe_div[i].setAttribute("class", "background-iframe-div");

      slide_div[i].appendChild(iframe_div[i]);
      slide_div[i].removeAttribute("data-background-iframe");
    }

    // Each time we advance slides, as the background videos aren't loaded
    // unless they are a few slides away
    Reveal.on('slidechanged', event => {
      var iframe_div = document.querySelectorAll(".backgrounds iframe");
      var slide_div = document.querySelectorAll("[data-background-iframe]");

      for (let i = 0; i < iframe_div.length; i++) {
        iframe_div[i].setAttribute("class", "background-iframe-div");

        slide_div[i].appendChild(iframe_div[i]);
        slide_div[i].removeAttribute("data-background-iframe");
      }
    });
    </script>

    <script>
    // Clean up slide background styles
    divs = document.querySelectorAll('.slide-background-content');
    Array.from(divs).map(function (x) {
      x.style = null;
    })
    </script>

    <script>

      // Move menu button
      menu_div = document.querySelector(".slide-menu-button");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move progress bar
      menu_div = document.querySelector(".progress");
      document.querySelector(".slides").appendChild(menu_div);
      
      // Move slide number
      slide_number = document.querySelector(".slide-number");
      document.querySelector(".slides").appendChild(slide_number);
      
      // Move custom footer
      footer = document.querySelector(".footer.custom");
      document.querySelector(".slides").appendChild(footer);

    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/awe-hnu\.github\.io");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>