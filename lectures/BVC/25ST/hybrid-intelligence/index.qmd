---
title: "Hybrid Intelligence"  
subtitle: "Business Value Creation with IT (BVC)"
lang: en
categories: ["Lecture Notes"]

date: "02.21.2025"

bibliography: ../assets/literature.bib

format: 
  html:
    output-file: index.html
    margin-header: | 
      [Slides](slides.html){.btn .btn-primary target="blank"}
    format-links: false       
  presentation-revealjs:
    output-file: slides.html
    include-before-body: ../assets/footer.html
  
---


# Terms & definitions {.headline-only}

## Intelligence

:::medium
> Intelligence is the ability to accomplish complex goals, learn, reason, and adaptively perform effective actions within an environment. *@gottfredson1997mainstream*
:::

Or in short: think and act humanly and/or rationally.

## Human intelligence

> **Human intelligence** "covers the capacity to learn, reason, and adaptively perform effective actions within an environment, based on existing knowledge. This allows humans to adapt to changing environments and act towards achieving their goals." *@dellermann2019hybrid [p. 632]*

. . .

@sternberg1985beyond proposes three distinctive dimensions:

:::{.incremental}
- **Componential intelligence** refers to the ability to take apart problems and being able to see solutions not often seen. 
- **Experiential intelligence** refers to the ability to learn and adapt through evolutionary experience.
- **Contextual intelligence** refers to the capacity to create an ideal fit between themselves and their environment by adaptation, shaping, and selection.
:::

## Thinking as a group {.html-hidden .unlisted background-color="black" background-image="images/fishes.jpg"}

## Collective intelligence

> **Collective intelligence** refers to  "[…] groups of individuals acting collectively in ways that seem intelligent." *@malone2015handbook [p. 3]* 

. . .

The concept implies that, under certain conditions, a (large) group of average, *homogeneous* individuals can outperform any individual of the group or even a single expert [@leimeister2010collective].

. . .

Originally, research studies how groups of people act and think “as a whole”, e.g. using various coordination and decision-making mechanisms.

. . .

Today, research increasingly focuses on **hybrid collective intelligence** to explore how of *heterogeneous* agents (i.e., humans and machines) can be connected so that they combine their complementary intelligence and act more intelligently  [@malone2015handbook].

## Artificial intelligence

> The term **artificial intelligence** is used to describe systems that perform "[...] activities that we associate with human thinking, activities such as decision-making, problem solving, learning [...]" *@bellman1978introduction [p. 3]*

. . .

The basic idea behind this concept is that systems becomes capable of analyzing their environment and adapting to new circumstances in this environment.

. . .

> AI can be defined as "[...] the art of creating machines that perform functions that require intelligence when performed by people […]" *@kurzweil1990age [p. 117]*

. . .

Or in short: think and act humanly and/or rationally.

# Hybrid intelligence  {.headline-only}

## Concept 

:::medium
> The idea is to combine the complementary capabilities of humans and computers to augment each other. *@dellermann2019hybrid*
:::

## Complementary strengths

![Complementary strengths of humans and machines [@dellermann2019hybrid, p. 640]](images/strengths.svg){#fig-strengths}

:::notes
Effective human-AI collaboration leverages the complementary strengths of both parties. AI systems excel at processing large datasets, recognizing patterns, maintaining consistency, and perfect recall of information. Humans, on the other hand, provide contextual understanding, creativity, ethical judgment, and social intelligence [@seeber2020machines].

By designing collaborative systems that allocate tasks according to these complementary strengths, teams can achieve outcomes superior to what either humans or AI could accomplish independently. For example, in medical diagnosis, AI might identify patterns in medical images or patient data, while human doctors integrate this information with patient context, ethical considerations, and treatment planning.

The concept of complementary intelligence reframes AI not as a replacement for humans but as a partner that enhances human capabilities while being enhanced by human input. However, there is also a technology-centric perspective that assumes that true intelligence can ultimately only be found in well-developed and mature (general) AI systems. Humans are biologically limited in their information processing and reasoning abilities and exhibit many types of cognitive biases, while computers offer virtually infinite possibilities to develop rational intelligence at human levels and beyond [@peeters2021hybrid].

:::callout-note

#### Model of human cognition

@kahneman2011thinking proposed a two-system model of human cognition, which he called System 1 and System 2.

System 1 is an intuitive, automatic, and fast mode of thinking that operates outside of our conscious awareness. It is responsible for generating impressions, making quick judgments, and executing routine tasks with minimal effort.

System 2, on the other hand, is a more analytical, controlled, and deliberate mode of thinking that requires conscious effort and attention. It is responsible for problem-solving, critical thinking, and decision-making.

While System 1 operates quickly and automatically, it can be prone to biases and errors, particularly in complex or unfamiliar situations. System 2, though slower and more effortful, can help us avoid these biases and make more accurate decisions.

:::
:::

## Definition

> **Hybrid intelligence** is defined as the ability to achieve complex goals by combining human and artificial intelligence, thereby reaching superior results to those each of them could have accomplished separately, and
continuously improve by learning from each other. *@dellermann2019hybrid [p. 640]*

. . .

Main characteristics of hybrid intelligence are:

:::incremental
- **Collectively** means that tasks are performed collectively and activities are conditionally dependent.
- **Superior results** means that neither AI nor humans could have achieved the outcome without the other.
- **Continuous learning** means that all components of the socio-technical system learn from each other through experience.
:::

## Visualization

![Distribution of roles in hybrid intelligence [@dellermann2019hybrid, p. 640]](images/visualization.svg){#fig-roles}

## Implications

According to @peeters2021hybrid following conclusions can be drawn:

:::{.incremental}
- Intelligence should not be studied at the level of individual humans or AI-machines, but **at the group level** of humans and AI-machines working together. 
- Increasing the intelligence of a system should be achieved by **increasing the quality of the interaction between its constituents** rather than the intelligence of the constituents themselves. 
- Both human as well as artificial intelligence can be regarded as very shallow when considered in isolation.
- No AI is an island.
:::

# Empirical evidence {.headline-only}

## General observations

@peeters2021hybrid see following evidence that support a hybrid intelligence perspective:

:::incremental
- In various domains, **unforeseen emergent effects** at the systemic level can be observed (e.g., sustaining biases with hiring software and other decision support systems)
- One of the biggest challenges is **how to seamlessly integrate AI systems** in human processes and workflows (e.g., autonomous cars and robots)
- Personal conversational assistants and other AI rely on many other webservices to create value (i.e., networked systems, maybe composed of multiple agents)
- At the level of teams, AI applications and humans together form human–agent teams
- **Observability**[^O], **predictability**[^P], **explainability**[^D], and **directability**[^E] are important requirements for the effective design of hybrid intelligence
:::

[^O]: Observability means that an actor should make its status, its knowledge of the team, task, and environment observable to others. 
[^P]: Predictability means that an actor should behave predictably such that others can rely on them when considering their own actions.
[^D]: Directability means that actors should have the opportunity to (re-)direct each other’s behavior. 
[^E]: Explainability means that agents should be capable of explaining their behavior to others

## Explainability impact

:::html-hidden

Different types of explanations serve different needs:

:::incremental
1. [How explanations]{.medium}\
   Descriptions of AI's process
2. [Why explanations]{.medium}\
   Justifications for AI's conclusions
3. [What-if explanations]{.medium}\
   How changes would affect outcomes
4. [Confidence indicators]{.medium}\
   Uncertainty in AI's assessment
:::
:::

:::notes
AI systems that can explain their reasoning processes lead to better collaboration outcomes, particularly in domains requiring high accountability such as healthcare or financial decisions.

Different types of explanations serve different needs [@miller2019explanation; @wang2019designing]:

- "How" explanations describe the process the AI used to reach a conclusion
- "Why" explanations justify the AI's reasoning
- "What-if" explanations help humans understand how changes in inputs would affect outcomes
- Confidence indicators communicate the AI's certainty about its recommendations

The most effective explanation approach depends on the context, user needs, and task requirements. For example, novice users might benefit from simpler explanations, while experts might prefer more technical details. Similarly, time-critical situations may require concise explanations, while complex decisions may warrant more comprehensive justifications [@miller2019explanation; @wang2019designing].

Effective explainability not only improves human understanding and trust but also enables humans to identify AI errors and provide feedback for improvement.
:::


## Impact on explainable AI on human cognition

@bauer2023expl show that **AI systems that provide explanations** (XAI) in addition to predictions [^XAI] may

:::incremental
- draw users’ attention excessively to the explanations (i.e., those that confirm their prior beliefs[^CB]) rather than adhering to the prediction,
- diminish employees' decision-making performance for the task at hand,
- lead individuals to carry over learned patterns to other domains (e.g., biased explanations),
- decrease individual level-noise in the decision-making process (i.e., an individual's decisions become more consistent),
- additionally foster differences in the decision-making process across subgroups of users that possess heterogeneous priors.
:::

. . .

A focus on the explanation as well as increased decision variance can substantially contribute to errors and ultimately harm business performance (see e.g., @kahneman2021noise.

[^XAI]: Will become a regulatory standard and many domains
[^CB]: A phenomenon called *confirmation bias*

## Examples

[Robots in de klas](https://www.robotsindeklas.nl/)
: A team consisting of a remedial teacher, an educational therapist, and a Nao robot collaborate to support a child with learning difficulties. The robot provides expertise and advice while also helping the child stay focused and engaged.

. . .

[Spawn](https://www.thefader.com/2019/05/21/holly-herndon-proto-ai-spawn-interview)
: The musician Holly Herndon created "Spawn," an AI system that generates unique music different from her usual style. By using Spawn as a tool, Holly is able to avoid creating music that repeats her previous works but to to expand the possibilities of their music.

. . .

[GitHub Copilot](https://github.com/features/copilot)
: In collaborative coding, Copilot can engage in back-and-forth dialogue about software design decisions, propose implementations, and explain reasoning about technical approaches - moving beyond simply generating code.

**What examples do come to your mind?**

# Q&A {.html-hidden .unlisted .headline-only background-image="../assets/bg.jpg"}

# Literature

::: {#refs}
:::
