---
title: "Wieland Group"  
subtitle: "Self-Service Data Intelligence"
lang: en
categories: ["Exam"]

author: "Michael Ruhland"

date: "02.10.2026"

bibliography: ../assets/literature.bib

format: 
  html:
    output-file: wieland.html
---


# General briefing

The **Wieland Group**, headquartered in Ulm, Germany, is a global leader in semi-finished copper and copper alloy products. Sustainability and innovation drives its strategy in a fast-evolving market.

Wieland uses Databricks as its central data warehouse for SAP business data. The platform consolidates extensive information from areas such as order management, materials management, financial accounting, and sales, making it available for analytics and data-driven decision-making.

While the data is centrally available, only technically proficient employees — data engineers and analysts with SQL or Python skills — can actively work with it today. Business users in procurement, logistics, controlling, or sales possess deep domain knowledge about which data validations, cross-references, and automations would be business-critical, but they depend on standard reports or requests to the IT department. This creates bottlenecks, long lead times, and untapped value creation potential.

# Challenge

Business users face a fundamental dilemma: they understand their business processes and know which data checks and automations would create value — but they cannot implement them independently. Typical scenarios include:

- **Inventory validation**: A sales manager wants to check daily whether booked order quantities are consistent with inventory levels and be automatically notified of discrepancies.
- **Production scheduling**: A production planner wants to scan the daily order backlog to identify schedule deviations and automatically notify stakeholders to negotiate earlier customer acceptance or prioritize alternative orders to reduce inventory or free capacity on bottleneck machines.
- **Inventory analysis**: An inventory manager wants to automatically identify slow-moving bolt items weekly and notify stakeholders to evaluate portfolio retention or technical alternatives.
- **Master data validation**: A data manager wants to automatically check dependent bill-of-material components and orphaned raw materials during deletions to ensure data consistency and trigger necessary updates.

Each of these tasks currently requires involvement of the IT department — or the potentials remain untapped. As the volume and complexity of available data continue to grow, this dependency becomes an increasingly critical bottleneck. Particularly as IT resources are scarce and should be focused on strategic initiatives rather than building individual reports and check routines.

Considering these challenges, Wieland raises the following question:

> How can (agentic) AI be leveraged to empower business users to independently create and operate data-driven logic and automations on a central data warehouse — without programming skills and while maintaining governance requirements?

## Questions to be explored

The following questions guide you in developing your concept and showcasing the value of your MVP:

- What are the specific unmet needs of business users when working with centralized business data? Which stakeholders are affected and how?
- What typical tasks do business users perform manually today — or not at all?
- (How) can AI agents serve as intermediaries between natural language or visual interaction and technical database operations?
- How can the solution ensure that logic created by business users is correct, traceable, and auditable?
- What governance and security requirements must be considered when enabling non-technical users to access and act on business data autonomously?
- How can the solution be integrated into existing Databricks infrastructure?
- What measurable business value does the solution create?
- How can Wieland scale the solution?
- How does the MVP demonstrate technical feasibility and value creation?
- What factors must be considered to ensure successful implementation and ongoing maintenance of the solution?
- How can the quality and reliability of user-created automations be continuously measured and improved?

## Requirements

Measure of impact
: It is essential to introduce metrics that allow to evaluate the effectiveness and performance of the solution.

Databricks as data source
: The solution must connect to a Databricks SQL Warehouse as its data source (Rest-API). No local file uploads are permitted.

No programming skills required
: Business users must be able to define data logic and automations without knowledge of SQL, Python, or other programming languages.

Automation capability
: Logic created by users should be executable on a scheduled or event-driven basis.

Traceability and auditability
: Results and logic definitions must be transparent, reproducible, and auditable.

Security and data governance
: The solution must implement appropriate access controls and security measures for handling sensitive business data.

Technology foundation
: The solution should utilize open-source technologies (e.g., google Blockly) and follow modern software architecture principles.

## Goals and outcome

The goal of this challenge is to develop an innovative AI-based solution that bridges the gap between business expertise and data capabilities, enabling domain experts to independently harness the potential of centralized business data. A successful solution will:

- Empower business users to create data-driven validations and automations without technical expertise
- Significantly reduce the dependency on IT departments for routine data checks and reports
- Improve data quality and process reliability through automated, recurring validations
- Demonstrate the value of (agentic) AI as an enabler for self-service data operations

The winning team will have the opportunity to present their solution at Wieland headquarters and discuss potential implementation with the data and innovation team.

## Knowledge base

Once you have decided for one use case, you will get details regarding the specific conditions (organizational, technical) as well as the APIs and data sources available (structure and contents). 

General information sources on the topic that might be helpful:

- [Databricks SQL Documentation](https://docs.databricks.com/en/sql/index.html)
- [Databricks REST API Reference](https://docs.databricks.com/api/workspace/introduction)
- [SAP Data Models — Overview of common SAP table structures](https://help.sap.com/docs/)


In addition, Michael Ruhland is available for Q&A sessions via teams at following time-slots:

- [CW 16]
- [CW 17]
- [CW 18]