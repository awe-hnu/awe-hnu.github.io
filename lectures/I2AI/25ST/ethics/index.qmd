---
title: "Ethics"
subtitle: "Introduction to AI (I2AI)"
lang: en
categories: ["Lecture Notes"]

bibliography: ../assets/literature.bib

date: "06.19.2025"

title-slide-attributes:
  data-background-image: ../assets/bg.jpeg
  data-background-size: cover
  data-background-opacity: "1"
  data-background-color: '#564ac6'
  
format:
  html:
    output-file: index.html
    margin-header: | 
      [Slides](slides.html){.btn .btn-primary target="blank"}
    format-links: false   
  presentation-revealjs:
    output-file: slides.html
    include-before-body: ../assets/footer.html
---

# Dualities of AI {.headline-only}

----

:::medium
> We have this incredible opportunity with AI, because of the way it’s trained to look at ourselves and our society. AI is a mirror, not a master. *Tim O’Reilly*
:::

## Bright side

:::medium
> We are not pursuing AI to beat humans at games. We are pursuing AI so that we can [empower every person and every institution]{.link-color} that people build with tools of AI, so that they can go on to solve the most pressing problems of our society and our economy. *Bill Gates [@ETMagazine2016]*
:::

## Exercise — Level-up {background-color="black"}

Read following article ["Everyone is above average"](https://www.oneusefulthing.org/p/everyone-is-above-average?utm_campaign=post&utm_medium=web) [@Mollick2023LevelUp].

Take 10 minutes to read the article.

Afterwards we will discuss following questions:

- Do you think that AI is rather an escalator or a king-maker? Why?
- What are risks of AI taking that role?
- What could be broader, long-term socioeconomic implications of AI leveling skills?
- What other effects might AI have on a societal level?
- What can be done to maximize the benefits and minimize the risks?

<!-- 

Equity of Access: Does the widespread adoption of AI tools for professional tasks create equitable opportunities for individuals across different skill levels and socioeconomic backgrounds, or does it exacerbate existing inequalities by favoring those with access to technology and training?
Fairness in Skill Enhancement: How can we ensure that AI-powered skill enhancement is distributed fairly among individuals, without privileging certain groups or disadvantaging others? Are there measures in place to address potential biases in AI algorithms that may disproportionately benefit or hinder specific demographics?
Impact on Human Creativity: To what extent does reliance on AI for tasks such as idea generation and creative writing impact human creativity and innovation? Are there risks of stifling originality and diversity of thought in favor of AI-generated solutions that conform to established patterns and norms?
Ethical Use of AI Assistance: What ethical considerations should guide the use of AI tools in professional tasks, particularly in fields where human judgment and ethical decision-making are critical? How can we ensure that AI assistance complements human skills and expertise, rather than substituting or diminishing them?
Worker Reskilling and Job Displacement: How should societies address the potential impact of AI on workforce dynamics, including job displacement and the need for continuous reskilling? Are there ethical responsibilities for employers, policymakers, and educational institutions to support workers in adapting to changing skill requirements and employment opportunities?
Transparency and Accountability: Who is responsible for ensuring transparency and accountability in the development and deployment of AI tools for professional tasks? What mechanisms should be in place to address concerns about algorithmic transparency, bias, and unintended consequences, particularly in fields where AI decisions can have significant real-world impacts?
Long-Term Socioeconomic Effects: What are the broader socioeconomic implications of AI leveling skills distribution across various professional tasks? How can societies mitigate potential negative effects on income inequality, job satisfaction, and overall well-being, while maximizing the benefits of AI-driven skill enhancement for individuals and communities?
Human-AI Collaboration and Autonomy: How can we foster meaningful collaboration between humans and AI systems in professional settings, while preserving human autonomy and agency? What ethical guidelines should govern the division of tasks and responsibilities between humans and AI, particularly in contexts where decisions have ethical or moral implications?

-->

## Dark side

:::medium
> It seems probable that once the machine thinking method had started, it would not take long to outstrip our feeble powers … They would be able to converse with each other to sharpen their wits. [At some stage therefore, we should have to expect the machines to take control.]{.link-color} *Alan Turing*
:::

# Case Study {background-color="black"}

Form groups of three, take 20 minutes to revisit the case study and work on following questions.

- Do you think that we will see something like artificial general intelligence in our lifetime? 
- Which of the aforementioned risks worries you the most? Why?
- What is your opinion on the design of the OpenAI organization regarding its ability to deal responsibly with AI?
- Do you think the self-regulation approaches taken by organizations like OpenAI, Microsoft, Meta, and Google are sufficient? Why (not)?
- What do you think about making LLM and other AI technologies available via open source?
- What are benefits and risks of legal regulations regarding the design and use of AI?

# Responsible AI governance

> I’m increasingly inclined to think that there should be some regulatory oversight, maybe at the national and international level, just to make sure that we don’t do something very foolish. I mean with artificial intelligence we’re summoning the demon. *Elon Musk*

Let's do some research to learn more about private sector-driven approaches to moving toward responsible AI.

## Exercise — Google and Microsoft  {background-color="black"}

Research about either

- [Microsoft Responsible AI Standard](https://www.microsoft.com/en-us/ai/principles-and-approach) or
- [Googles AI principles](https://ai.google/responsibility).

Take 20 minutes to understand the standards/principles, evaluate them critically and create a short summary of your learnings (approx. 3 minutes presentation)

# Exercises {.headline-only}

## EU AI Act {background-color="black"}

Research about the __Artificial Intelligence Act__ of the European Union.

Try to understand the risk-based approach and provide a short summary, also tackling following questions:.

- What are high risk AI systems?
- Which requirements should be mandatory requirements for these?

## Exercise — Fairspeech {background-color="black"}

Have a look at the [fairspeech website](https://fairspeech.stanford.edu/) (and at the [research paper](https://www.pnas.org/doi/full/10.1073/pnas.1915768117) [@koenecke2020racial]).

Tackle following questions:

- What is the issue with current __automated speech recognition (ASR) systems __?
- Which ethical issues do they cause?
- What should be done to mitigate the risks?

# Literature
::: {#refs}
:::