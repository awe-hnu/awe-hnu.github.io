---
title: "Learning"
subtitle: "üß† Introduction to AI ‚Äî I2AI_7"
lang: en

format: 
  html:
    output-file: index.html
  revealjs:
    output-file: slides.html
    include-after-body: ../assets/footer.html
---

# Top{visibility="hidden" .slide-link-hidden .unlisted .unnumbered}

{{< include ../assets/_top.qmd >}}

# Introduction {.vertical-center background-color=blue background-image="images/bg.jpeg"}

No intelligence without learning.

## Definition

> Learning agents are those that can improve their behavior through diligent study of past experiences and predictions of the future *@RusselNorvig2022AIMA [p. 668]*

. . .

A learning agent

:::{.incremental}
- uses so-called __machine learning__ (ML), if it is a computer;
- improves performance based on experience (i.e., observations of the world);
- is required when the designer lacks omniscience (i.e., in unknown environments) and/or
- have no idea how to program a solution themselves (e.g., recognizing faces)
:::

# The learning agent {.vertical-center background-color=blue background-image="images/bg.jpeg"}

:::{.notes}
So far an agent‚Äôs percepts have only served to help the agent choose its actions. Now they will also serve to improve future behavior.
:::

## Visualization

![A learning agent based on @RusselNorvig2022AIMA [p. 74]](images/learning-agent.svg){#fig-l-agent}

---

## Building blocks

__Performance element:__ Processes percepts and chooses actions (relates to the basics of AI we have studied so far)

. . .

__Learning element:__ Carries out improvements. Requires awareness and feedback on how the agent is doing in the environment

. . .

__Critic:__ Evaluation of the agent‚Äôs behavior based on a given external behavioral measure (i.e., feedback)

. . .

__Problem generator:__ Suggests explorative actions that lead the agent to new experiences


:::{.notes}

The __performance elements__ of the agent designs described in chapter [Intelligent Agents](../2/) are composed of

- a direct mapping from conditions to the current state of actions;
- a means to infer relevant properties of the world from the percept sequence;
- information about the way the world evolves and about the results of possible actions the agent can take;
- utility information indicating the desirability of actions; and/or
- goals that describe the most desirable states; 

:::

## The learning element

The design of the learning element is influenced by four important aspects:

:::{.incremental}
- Which __component__ of the performance element is to be improved?
- What __representation__ should be chosen (i.e., what model)?
- What __prior information__ is available (i.e., prior knowledge that influences the model)?
- What form of __feedback__ is available?
:::

## Types of feedback

The type of feedback available for learning is usually the most important factor in determining the nature
of the learning problem.

. . .

:::{.incremental}
- __Supervised learning:__ Involves learning a function from examples of its inputs and outputs *‚ûû correct answer for each training instance*
- __Unsupervised learning:__ The agent has to learn patterns in the input when no specific output values are given *‚ûû reward sequence, no correct answers*
- __Reinforcement learning:__ The most general form of learning in which the agent is not told what to do by a teacher. Rather, it must learn from reinforcements (punishments or rewards). It typically involves learning how the environment works *‚ûû "just make sense of the data"*
:::

:::{.notes}
### Examples [@RusselNorvig2022AIMA, p. 671] {visibility=hidden}

For image classification, usually supervised learning is used. Inputs can be camera images, each one accompanied by an output saying, e.g., "bus" or "pedestrian". An output like this is called a __label__. The agents learns a function that, when given a new image, predicts the appropriate label.

The most common unsupervised learning task is clustering: detecting potentially useful clusters of input examples. For instance, when shown millions of images, a computer vision system could identify large cluster of similar images (without "knowing" what is shown on these).

An example for reinforcement learning is a chess agent. Imagine, it is told at the end of a game that it has won (a reward) or lost (a punishment). Based on that feedback, it has to decide which of the actions prior to the reinforcement were most responsible for it, and to alter its actions to aim towards more rewards in future.

:::

## Exercise ‚úèÔ∏è  {.vertical-center background-color=blue background-image="images/bg.jpeg" .unlisted}

Consider the problem faced by me learning to play tennis.

- Explain how this process fits into the general learning model.
- Describe the percepts and actions of the player.
- What types of learning I must do?
- What example data is available?

## Why learning works

How can we be sure that our learned hypothesis will predict well for previously unseen inputs? I.e., how do we know that the hypothesis $h$ is close to the target function $f$ when $f$ is unknown?

. . .

The underlying principle of __computational learning theory__ is, that any hypothesis that is seriously wrong will almost certainly be "found out" with high probability after a small number of examples

. . .

Thus, any hypothesis that is consistent with a sufficiently large set of training examples is unlikely to be seriously wrong: that is, it must be __probably approximately correct__ (PAC)

## Inductive learning

The task of learning is to find good hypotheses about the world.

:::{.incremental}
- An __example__ is a pair $(x, f(x))$ (input and output)
- The complete set of examples is called the __training set__ (supervised learning)
- __Pure inductive inference:__ for a collection of examples for $f$ (the __target function__), return a function $h$ (hypothesis) that approximates $f$
- The function h typically is member of a __hypothesis space__ $H$
- A good hypothesis should __generalize the data__ well (i. e., will __predict__ unseen examples correctly)
- A hypothesis is __consistent__ with the data set if it agrees with all the data
:::

. . .

How do we choose from among multiple consistent hypotheses?

. . .

__Ockham‚Äôs razor:__ prefer the simplest hypothesis that matches the data

:::{.notes}

Ockham‚Äôs razor is a choice between more complex, low-bias hypotheses that fit the training data well and simple, low-variance hypotheses that may generalize better. Wililiam of Ockham stated in the first century the principle that "plurality [of entities] should not be posited without necessity ‚Äî the so-called Ockham's razor that "shaves off" dubious explanations.

:::{.callout-note}
### Underfitting and overfitting [@RusselNorvig2022AIMA; p. 673]

A hypothesis is __underfitting__ when it fails to find a pattern in the data (i.e., the model has not learned enough from the data). In turn, a hypothesis is __overfitting__ the data when it pays too much attention to the particular data set it is trained on, causing it to perform poorly on unseen data (i.e., the generalization of the model is unreliable).

:::
:::

---

### Example: curve-fitting

![Finding hypotheses to fit data](images/curve-fitting.svg){#fig-fitting}

For plots of best-fit functions ($h$) from four different hypothesis spaces ($H$) trained on a data set (a = linear; b = degree-7 polynomial, c = degree-6 polynomial, d = sinusoidal)


# Decision trees {.vertical-center background-color=blue background-image="images/bg.jpeg"}

## Learning decision trees

A __decision tree__ is a representation of a function that maps a vector of attribute values to a single output value‚Äîa "decision". 

. . .

__Search__ is used to find a decision (i.e., performing a sequence of tests).

. . .

In __Boolean decision trees__, the input is a set of vector of input attributes $X$ and a single Boolean output value $y$

. . .

__Learning process__: Definition of the goal predicate in the form of a decision tree.

:::{.incremental}
- An internal node of the decision tree represents a test of a property
- Branches are labeled with the possible values of the test
- Each leaf node specifies the Boolean value to be returned if that leaf is reached
:::

## Expressiveness

A Boolean decision tree is equivalent to a logical statement of the form

$$
\begin{flalign}
Output \iff (Path_1 \lor Path_2 \lor ...)
\end{flalign}
$$

where each $Path_i$ is a __conjunction__ of the form $(A_m = v_x \; \land \; A_n = v_y \; \land \; ...)$ of __attribute-value tests__ corresponding to a path from the root to a $true$ leaf.

. . .

Any function in propositional logic can be represented by a decision tree by translating every row of a truth table to a path in the tree.

. . .

This can lead to a tree whose size is __exponential__ in the number of attributes.

:::{.notes}
:::{.callout-note}
### Digression: hypothesis spaces

How many distinct decision trees with $n$ Boolean attributes?  
= number of Boolean functions  
= number of distinct truth tables with $2^n$ rows = $2^{2^n}$

E.g., with 6 Boolean attributes, there are 18,446,744,073,709,551,616 trees

How many purely conjunctive hypotheses (e.g., $Hungry \land \neg Rain$)?

Each attribute can be in (positive), in (negative), or out:  
$3^n$ distinct conjunctive hypotheses
:::
:::

---

### Limitations

Although decision trees can represent functions with smaller trees, there are functions that require an exponentially large decision tree, e.g.

. . .

:::{.incremental}
- __Majority function__, which returns true if more than half of the inputs are true
- __Parity function__, which returns true if and only if an even number of inputs are true
- $y > A_1 + A_2$ with real-valued attributes [^1]
:::

. . .

Summary: decision trees are good for some kinds of functions and bad for others.

[^1]: The decision is a diagonal line, and all decision tree tests divide the space up into rectangular, axis-aligned boxes. We would have to stack a lot of boxes to closely approximate the diagonal line.

## Example problem

Supervised learning problem of deciding whether to wait for a table at a restaurant [@RusselNorvig2022AIMA, p. 668]

. . .

The output ($y$) is a Boolean variable **WillWait**

. . .

The input ($x$) is a vector of ten attributes values (discrete values):

:::{.smaller}
:::{.incremental}
- **Alternate** -- Is there an alternative? (T/F)
- **Bar** -- Does the restaurant have a bar to wait in? (T/F)
- **Fri** -- Is it Friday or Saturday? (T/F)
- **Hungry** -- Am I hungry? (T/F)
- **Patrons** -- How many guests are there? (none, some, full)
- **Price** -- How expensive is the food? (‚Ç¨, ‚Ç¨‚Ç¨, ‚Ç¨‚Ç¨‚Ç¨)
- **WaitEstimate** -- How long do we have to wait? (0-10, 10-30, 30-60, >60)
- **Reservation** -- Have I made a reservation? (T/F)
- **Raining** -- Is it raining outside? (T/F)
- **Type** -- What kind of restaurant is it? (French, Italian, Thai, Burger)
:::
:::

---

### Example decision tree

![Decision tree restaurant example based on @RusselNorvig2022AIMA [p. 674]](images/decision-tree.svg){#fig-tree}

---

### Training set 

:::{.smaller}
| Example | Alt   | Bar   | Fri   | Hun   | Pat    | Price   | Rain   | Res   | Type     | Est       | WillWait     |
|:--------|:-----:|:-----:|:-----:|:-----:|:------:|:-------:|:------:|:-----:|:--------:|:---------:|:-------------|
| $x_1$   | Yes | No  | No  | Yes | Some | ‚Ç¨‚Ç¨‚Ç¨   | No   | Yes | French  | 0-10  | $y_1 =$ Yes  |
| $x_2$   | Yes | No  | No  | Yes | Full | ‚Ç¨     | No   | No  | Thai    | 30-60 | $y_2 =$ No   |
| $x_3$   | No  | Yes | No  | No  | Some | ‚Ç¨     | No   | No  | Burger  | 0-10  | $y_3 =$ Yes  |
| $x_4$   | Yes | No  | Yes | Yes | Full | ‚Ç¨     | Yes  | No  | Thai    | 10-30 | $y_4 =$ Yes  |
| $x_5$   | Yes | No  | Yes | No  | Full | ‚Ç¨‚Ç¨‚Ç¨   | No   | Yes | French  | \>60  | $y_5 =$ No   |
| $x_6$   | No  | es  | No  | Yes | Some | ‚Ç¨‚Ç¨    | Yes  | Yes | Italian | 0-10  | $y_6 =$ Yes  |
| $x_7$   | No  | Yes | No  | No  | None | ‚Ç¨     | Yes  | No  | Burger  | 0-10  | $y_7 =$ No   |
| $x_8$   | No  | No  | No  | Yes | Some | ‚Ç¨‚Ç¨    | Yes  | Yes | Thai    | 0-10  | $y_8 =$ Yes  |
| $x_9$   | No  | Yes | Yes | No  | Full | ‚Ç¨     | Yes  | No  | Burger  | \>60  | $y_9 =$ No   |
| $x_{10}$  | Yes | Yes | Yes | Yes | Full | ‚Ç¨‚Ç¨‚Ç¨   | No   | Yes | Italian | 10-30 | $y_{10}=$ No  |
| $x_{11}$  | No  | No  | No  | No  | None | ‚Ç¨     | No   | No  | Thai    | 0-10  | $y_{11} =$ No  |
| $x_{12}$  | Yes | Yes | Yes | Yes | Full | ‚Ç¨     | No   | No  | Burger  | 30-60 | $y_{12} =$ Yes |

: Examples for the restaurant domain {#tbl-res-ts}

:::

## Inducing decision trees from examples

### Naive solution

. . .

To get a __naive solution__, we simply construct a tree with one path to a leaf for each example.

:::{.incremental}
- We test all the attributes along the path and attach the classification of the example to the leaf
- Whereas the resulting tree will correctly classify all given examples, it will not say much about other cases
- It just memorizes the observations and __does not generalize__
:::


---

### Smallest solution

We want to find a tree that is __consistent with the training set__ (@tbl-res-ts) and is __as small as possible.__

. . .

Unfortunately, it is __intractable__ to find a guaranteed smallest consistent tree.

. . .

However, with some simple heuristics, we can efficiently find one that is __close to the smallest__ (i.e., "smallish" tree).

. . .

__Decision tree learning__ adopts a greedy divide-and-conquer strategy.

---

### Divide-and-conquer strategy

Always use the __most important attribute__ first, then recursively solve the smaller subproblems

:::{.incremental}
- The "most important attribute" is the one that makes the most difference[^2]
- Split the training set into subsets each corresponding to a particular value of that attribute
- Now that we have divided the training set into several smaller training sets, we can recursively apply this process to the smaller training sets
:::

[^2]: The selection is implemented by means of a *choosing attribute test*, which is based on information theory and measures the information gain from the attribute tests. For more details please refer to @RusselNorvig2022AIMA [p.681 ff]

. . .

That way, we hope to get to the __correct classification__ with a __small number of tests__[^3]

[^3]:Meaning that all paths in the tree will be __short__ and the tree as a whole will be __shallow__

## Exercise ‚úèÔ∏è  {.vertical-center background-color=blue background-image="images/bg.jpeg" .unlisted}

Create the decision tree by applying the divide-and-conquer approach on the restaurant examples (approx. 20 minutes).

----

### Solution note

![Splitting the examples by testing on attributes, based on @RusselNorvig2022AIMA [p. 677]](images/divide-and-conquer.svg){#fig-l-agent}

:::{.notes}
At each node, we show the positive (light boxes) and negative (dark boxes) examples remaining. (a) Splitting on *Type* brings us no nearer to distinguishing between positive and negative examples. *Type* is a __poor attribute__ (b) Splitting on *Patrons* does a good job of separating positive and negative examples. After splitting on *Patrons*, *Hungry* is a fairly good selection test. The full tree would be *Patrons*, *Hungry*, *Type* and *Fri*.
:::

## Recursive learning process

In each recursive step there are four cases to consider:

:::{.incremental}
- Positive and negative examples: choose a __new attribute__
- __Common outcome__ (only positive or only negative examples): done (answer is *Yes* or *No*).
- __No examples:__ there was no example with the desired property. Answer *Yes* if the majority of the parent
node‚Äôs examples is positive, otherwise *No*.
- __No attributes left__, but there are still examples with different classifications: there were errors in the data (i.e., noise) or the attributes do not give sufficient information. Answer *Yes* if the majority of examples is positive, otherwise *No*.
:::

## Exercise ‚úèÔ∏è  {.vertical-center background-color=blue background-image="images/bg.jpeg" .unlisted}

Compare the naive tree with the tree gained by applying the divide-and-conquer heuristic. What differences do you see? (approx. 5 minutes)

## Resulting tree

Properties of the learning outcome:

:::{.incremental}
- The resulting tree is __considerably simpler__ than the one originally given (and from which the
training examples were generated)
- The learning algorithm outputs a tree that is __consistent__ with all examples it has seen
- The tree does not need to agree with the correct function, e.g. it suggests not to wait if we are
not hungry. If we are, there are cases in which it tells us to wait.
- Some tests (*Raining*, *Reservation*) are not included since the algorithm can classify the examples without them
:::

## Performance assessment

To assess the power of the prediction, the following method can be applied:

:::{.incremental}
- Collect a large number of examples
- Divide it into two disjoint sets: the __training set__ and the __test set__
- Use the training set to generate $h$
- Measure the percentage of examples of the test set that are correctly classified by $h$
- Repeat the process for randomly-selected training sets of different sizes
:::

. . .

As the training set grows, the prediction quality increases 

## Generalization

Pruning reduces the size of decision trees by removing sections of the tree that are non-critical and redundant to classify instances. 

:::{.incremental}
- Pruning reduces the complexity of the final hypothesis (tree size) and reduces overfitting[^4]
- Predictive accuracy as measured by a cross-validation set[^5]
- One of the simplest forms of pruning is __reduced error pruning__:
  - For each leave, each node is replaced with its most popular output
  - If the prediction accuracy is not affected then the change is kept
  - It is  somewhat naive, but simple and speedy
:::

[^4]: A tree that is too large risks overfitting the training data and poorly generalizing to new samples.
[^5]: The training set is divided into two groups; 70% of the training set is used to build the tree, and the remaining 30% for validation; leading to *three* data sets (training, validation, test)

## Summary

:::{.incremental}
- Decision trees are one possibility for __representing (Boolean) functions__
- They __can be exponential__ in the number of attributes
- It is often too difficult to find the minimal decision tree
- One method for generating decision trees that are as flat as possible is based on ranking the attributes
- The ranks are computed based on the information gain
:::

# Statistical ML {.vertical-center background-color=blue background-image="images/bg.jpeg"}

## Motivation

As discussed in [chapter probability](../6/), __probability and utility theory__ allow agents to deal with uncertainty

. . .

To apply probabilistic reasoning, however, the agents must first learn their probabilistic theories of the world from experience

. . .

We will discuss statistical learning methods as robust ways to __learn probabilistic models__

## Bayesian learning

Learning can be viewed as __Bayesian updating__ of a probability distribution over the hypothesis space

. . .

$H$ is the hypothesis variable (values $h_1, h_2, . . .$)

. . . 

$x_i$ gives the outcome of random variable $X_i$ after $i$ observations    
Training data $X = x_1,..., x_N$

. . .

Given the data so far, each hypothesis has a posterior probability:

$$
\begin{flalign}
P(h_k|X) = \alpha P(X|h_k)P(h_k)
\end{flalign}
$$

where $P(X|h_k)$ is called the __likelihood__

---

Predictions use a __likelihood-weighted average__ over the hypotheses:

$$
\begin{flalign}
P(X_{N+1}|X) = \sum_k{P(X_{N+1}|X,h_k)P(h_k|X)} = \sum_k{P(X_{N+1}|h_k)P(h_k|X)}
\end{flalign}
$$

## Example

Suppose there are five kinds of bags of candies:

:::{.incremental}
- 10% are $h_1$ : 100% *cherry* candies
- 20% are $h_2$ : 75% *cherry* and 25% *lime* candies
- 40% are $h_3$ : 50% *cherry* and 50% *lime* candies
- 20% are $h_4$ : 25% *cherry* and 75% *lime* candies
- 10% are $h_5$ : 100% *lime* candies
:::

. . .

Then we draw 10 candies from some bag ($d_1,...,d_10$), which are all *lime* candies.

. . .

What kind of bag is it?    
What flavor will the next candy be?

----

### Posterior probability of hypotheses

$P(h_k|X) = Œ±P(X|h_k)P(h_k)$

. . .

$P(h1 | 5\;limes) = Œ±P(5\;limes | h1)P(h1) = \alpha ¬∑ 0.0^5 ¬∑ 0.1 = 0$
$P(h2 | 5\;limes) = Œ±P(5\;limes | h2)P(h2) = \alpha ¬∑ 0.25^5¬∑ 0.2 = 0.000195Œ±$
$P(h3 | 5\;limes) = Œ±P(5\;limes | h3)P(h3) = \alpha ¬∑ 0.5^5 ¬∑ 0.4 = 0.0125Œ±$
$P(h4 | 5\;limes) = Œ±P(5\;limes | h4)P(h4) = \alpha ¬∑ 0.75^5 ¬∑ 0.2 = 0.0475Œ±$
$P(h5 | 5\;limes) = Œ±P(5\;limes | h5)P(h5) = \alpha ¬∑ 1.0^5 ¬∑ 0.1 = 0.1Œ±$

. . .

$\alpha = 1/(0 + 0.000195 + 0.0125 + 0.0475 + 0.1) = 6.2424$

. . .

$P(h_1 | 5\;limes) = 0$   
$P(h_2 | 5\;limes) = 0.00122$   
$P(h_3 | 5\;limes) = 0.07803$   
$P(h_4 | 5\;limes) = 0.29650$  
$P(h_5 | 5\;limes) = 0.62424$  

---

### Evolution of the five hypotheses

![Posterior probability of candy-hypotheses](images/example-probs.svg){#fig-eprob}

---

### Prediction probability

$$
\begin{flalign}
P(X_{N+1}|X) = \sum_k{P(X_{N+1}|X,h_k)P(h_k|X)} = \sum_k{P(X_{N+1}|h_k)P(h_k|X)}
\end{flalign}
$$

. . . 

$$
\begin{align}
P(lime \; on \; 6 | 5 \; limes) & = P(lime \; on \; 6 | h1)P(h1 | 5 \; limes) \\
& + P(lime \; on \; 6 | h2)P(h2 | 5 \; limes) \\
& + P(lime \; on \; 6 | h3)P(h3 | 5 \; limes) \\
& + P(lime \; on \; 6 | h4)P(h4 | 5 \; limes) \\
& + P(lime \; on \; 6 | h5)P(h5 | 5 \; limes) \\
& = 0 √ó 0 \\
& + 0.25 √ó 0.00122 \\
& + 0.5 √ó 0.07830 \\
& + 0.75 √ó 0.29650 \\
& + 1.0 √ó 0.62424 \\
& = 0.88607 \\
\end{align}
$$

----

### Likelihood-weighted average

![Probability that next candy is lime given __d__](images/example-p-prob.svg){#fig-ep-prob}

## Exercise ‚úèÔ∏è  {.vertical-center background-color=blue background-image="images/bg.jpeg" .unlisted}

What do you observe/learn from this example?

## Observations

The Bayesian prediction __eventually agrees with the true hypothesis__

:::{.incremental}
- For any fixed prior that does not rule out the true hypothesis, the posterior of any false hypothesis will eventually vanish
- The Bayesian prediction is __optimal__ and, given the hypothesis prior, any other prediction will be correct less often
- However, summing over the hypothesis space is often intractable
- Real problems require us to resort to __approximate or simplified methods__
:::

## MAP learning

A common approximation is to make predictions based on a __single most probable hypothesis__

. . .

__Maximum a posteriori__ (MAP)[^7] learning: choose $h_{MAP}$ maximizing $P(h_k|X)$[^8]

$$
\begin{flalign}
P(X|d) \approx P(X|h_{MAP})
\end{flalign}
$$

:::{.incremental}
- In the candy example, $h_{MAP}=h5$ after three lime candies in a row
- The __MAP learner__ the predicts that the fourth candy is lime with probability 1.0, whereas the Bayesian prediction is still 0.8
- As more data arrive, MAP and Bayesian predictions become closer
- Finding MAP hypotheses is often much easier than Bayesian learning
- MAP learning provides a natural embodiment of __Ockham's razor__
:::

[^7]: Pronounced "em-ay-pee"
[^8]: Which is equal to minimizing $‚àí \log P(X|h_k) ‚àí \log P(h_k)$

---

## Maximum likelihood hypothesis

For large data sets, prior becomes irrelevant

:::{.incremental}
- Thus, we can assume a __uniform prior__ over the hypothesis space
- __Maximum likelihood__ learning: choose $h_{ML}$ maximizing $P(X|h_k)$
- This hypothesis is called the __maximum likelihood hypothesis__
- Maximum likelihood is the "standard" (non-Bayesian) statistical learning method
:::

## Summary

:::{.incremental}
- Bayesian learning techniques formulate learning as a form of __probabilistic inference__
- __Full Bayesian learning__ gives best possible predictions but is intractable
- __Maximum a posterior__ learning selects the most likely hypothesis given the data (balancing complexity with accuracy on training data)
- __Maximum likelihood__ assumes uniform prior, OK for large data sets
:::

# Deepl learning {.vertical-center background-color=blue background-image="images/bg.jpeg"}

## Introduction

Conventional machine-learning techniques as those discussed above are limited in their ability to process __natural data in their raw form__. 

. . .

Careful engineering and considerable domain expertise are required to transform the raw data into a __suitable internal representation__ from which the learning system could detect or classify patterns in some input.

. . .

In __representation learning__ the system uses methods to automatically discover the representations needed for detection or classification. 

. . .

__Deep-learning methods__ creates multiple levels of representation by transforming the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. 

. . .

With the composition of enough such transformations, very complex functions can be learned. 

## Representations

The key aspect of deep learning is that the levels of representations (i.e., layers of features) __are not designed by human engineers__: they are learned from data using a __general-purpose learning procedure__.

. . .

Example: object detection in images

:::{.incremental}
- An image comes in the form of an array of pixel values (raw input; input layer)
- The first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image (hidden layer 1)
- The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions (hidden layer 2)
- The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects (hidden layer 3)
- Subsequent layers would detect objects as combinations of the parts of familiar objects
:::

----

### Visualization

![Illustration of a deep neural network consisting of multiple representation layers](images/deep-nn.svg){#fig-deep-nn}

## Application

Deep learning methods can __discover intricate structures in high-dimensional data__. 

. . .

Using this capability, deep learning is making major advances in solving problems that could not have been solved before (@lecun2015deep), e.g., 

:::{.incremental}
- image and speech recognition,
- analysing particle accelerator data,
- reconstructing brain circuits,
- predicting the effects of DNA mutations on gene expression and disease
- natural language understanding (e.g., topic classification, sentiment analysis, question answering and language translation)
:::

## Convolutional neural networks

A ___convolutional neural network (ConvNet)___ is a specific kind of neural network with multiple layers,designed to process data that come in the form of multiple arrays[^10]

[^10]: 1D for signals an sequences such as language, 2D for images or audio spectograms, 3D for video

. . .

The role of the ConvNet is to __reduce the arrays__ into a form which is easier to process, without losing features which are critical for getting a good prediction. 

. . .

A ConvNet is structured as a series of stages, which are composed of two types of layers: __convolutional layers__ and __pooling layers__.

:::{.incremental}
- The __convolution layer__: extraction of the high-level features from the input (by applying convolutional operations/filters)
- The __pooling layer__: reduction of the spatial size of the convoled feature to decrease the computational power required to process the data through dimensionality reduction.
:::

. . .

Good read: [A Comprehensive Guide to Convolutional Neural Networks ‚Äî the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)

# Development process {.vertical-center background-color=blue background-image="images/bg.jpeg"}

## Overview

We are still in the early stages of defining a methodology for machine learning projects; the tools and processes are not as well developed as in software engineering

. . .

@RusselNorvig2022AIMA [p. 722ff] propose a process that involves following typical steps

:::{.incremental}
- Problem formulation
- Data collection, assessment, and management
- Model selection and training
- Checking trustworthiness of the system
- Operation, monitoring, and maintenance
:::

## Problem

Figuring out what problem you want to solve compromises three parts:

:::{.incremental}
1. __Problem:__ What problem do I solve for my users?  
   ‚ûû Find an objective that you can track and that relates to your "true goals"
2. __Suitability:__ What parts of the problem(s) can be solved by ML?   
   ‚ûû Often not all parts of the problem require ML
3. __Approach:__ What kind of learning is appropriate?  
   ‚ûû Often a *semi-supervised learning approach* is suitable (few labeled examples, large collection of unlabeled examples)
:::

## Data

> Real data are messy

. . .

ML needs data, __a lot of data__, of which at least a subset is labeled

. . .

Manufacturing these data can be done by __own labor__ or by __crowdsourcing__ (paid, volunteers, users); one might also start with __publicly available general-purpose dataset__ (or a model that has been pretrained) and then add specific data

. . .

Maintain a __data provenance__ for all data (i.e., for each columns of your data set, you should know the exact definition, where the data come from, what the possible values are, and who has worked on it)

. . . 

When data are limited, __data augmentation__ can help (i.e., creating multiple versions of each image by rotating, translating, cropping, or scaling each image, or by changing brightness or color balancing or adding noise)

:::{.notes}
:::{.callout-note}
### Helpful questions
Questions to be asked are 
- Is this the right data for my task?
- Does it capture enough of the right inputs to give us a chance of learning a model? 
- Does it contain the outputs I want to predict? 
- If not, can I build an unsupervised model? 
- Or can I label a portion of the data and then do semi-supervised learning?
- Is it relevant data?
- How much data do I need? Recommendation: draw a learning curve to see if more data will help.
- Could there be data entry errors?
- What to be done with missing data fields?
- Are there spelling errors or inconsistent terminology in text data?
- Are there outliers in the data?
:::
:::

---

### Feature engineering

After correcting overt errors, the data should be preprocessed so that they can be handled more easily

:::{.incremental}
- __Quantization:__ forcing a continuous valued input into fixed bins (e.g., waiting time in 0-10, 10-30, 30-60, or >60 minutes)
- __Normalization data:__ transforming data so that it has a standard deviation of 1
- __Separating categorical attributes:__ transform the data into separate Boolean attributes, where exactly one of it is true
:::

. . .

> At the end of the day, some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used. *@domingos2012few*

## Model

Before starting with building a model, you might start with getting an __intuitive feel for the data__ (e.g., by means of exploratory data analysis)

. . .

There is no guaranteed way to pick the __best model class__, but there are some rough guidelines:

:::{.incremental}
- __Random forests__ are good then there are a lot of categorical features, where many of these may be irrelevant
- __Nonparametric methods__ are good when having a lot of data and no prior model
- __Logistic regression__ does well when the data are linearly separable (or can be converted to be so)
:::

. . .

Do what worked well in similar past problems‚Äîand search: run experiments with multiple possible models

## Trustworthiness

Doing well with test data is a necessary but not sufficient condition for __trust__ in the model (by you and your stakeholders), it also requires

:::{.incremental}
- __Verification and validation:__ you test on the training, validation, and datasets, do code reviews, monitoring, and set measures for accountability  
  ‚ûû Do the best to ensure that the system will not be wrong and, for the case, set responsibilities
- __Interpretability:__ you understand how answers relate to inputs 
  ‚ûû Do the best to inspect and interpret your model
- __Explainability:__ the model helps you to understand why a certain output has been produced for a given input 
  ‚ûû Do the best to explain what your model does[^9]
:::

[^9]: Regulations such as the European GDPR require systems to provide explanations

## Operation

After the model is deployed to the users, additional challenges will arise

:::{.incremental} 
- __Long tail of user inputs:__ you might see inputs that were never tested before and you need to know whether your model generalizes well for them (i.e., you need to monitor the performance)
- __Nonstationarity:__ the world changes over time (e.g., spammers adapt their tactics); you need to consider how often to adapt the model (i.e., find a tradeoff between a well tested model and a model that is built from the latest data)
:::

:::{.notes}
:::{.callout-note}
### A set of criteria to see how well you are doing at deploying ML models

__Tests for features and data__
(1) Feature expectations are captured in a schema. (2) AU feature. are beneficial. (3) No feature's cost is too much. ( 4) Features adhere to meta-level requirements. (5) The data pipeline has appropriate privacy controls. (6) New features can be added quickly. (7) All input feature code is tested.

__Tests for model development__
(1) Every model specification undergoes a code review. (2) Every model is checked in to a repository. (3) Offline proxy metrics correlate with actual metrics (4) All hyperparameters have been tuned. (5) The impact of model staleness is known. (6) A simpler model is not better. (7) Model quality is sufficient on all important data slices. The model has been tested for considerations of inclusion.

__Tests for ML infrastructure__
(1) Training is reproducible. (2) Model specification code is unit tested. (3) The full ML pipeline is integration tested. (4) Model quality is validated before attempting to serve it. (5) The model allows debugging by observing the step-by-step computation of training or inference on a single example. (6) Models are tested via a canary process before they enter production serving environments. (7) Models can be quickly and safely rolled back to a previous serving version.

__Monitoring tests for ML__
(1) Dependency changes result in notification. (2) Data invariants hold in training and serving inputs. (3) Training and serving features compute the same values (4) Models are not too tales (5) The model is numerically stable. (6) The model ha not experienced regressions in training speed, serving latency, throughput, or RAM usage. (7) The model has not experienced a regression in prediction quality on served data.

Source: @RusselNorvig2022AIMA [p. 731]

:::
:::

# ‚úèÔ∏è Exercises {.vertical-center background-color=blue background-image="images/bg.jpeg"}

## I2AI_7 E1

Consider the problem faced by an infant learning to speak and understand a language.

- Explain how this process fits into the general learning model.
- Describe the percepts and actions of the infant, and the types of learning the infant must do. 
- Describe the subfunctions the infant is trying to learn in terms of inputs and outputs, and available example data.

## I2AI_7 E2

Describe the differences between supervised, unsupervised, and reinforcement learning.

## I2AI_7 E3

Define the following machine-learning terms in your own words

a. Training set
b. Hypothesis
c. Bias
d. Variance

## I2AI_7 E4

Draw a decision tree for the problem of deciding whether to move forward at a road intersection, given that the light has just turned green.

What problems do you see? Argue based on the qualification problem discussed in [chapter probability](../6/#motivation).

## I2AI_7 E5

We never test the same attribute twice along one path in a decision tree. Why not?

## I2AI_7 E6

Two statisticians go to the doctor and are both given the same prognosis: A 40% chance that the problem is the deadly disease A, and a 60% chance of the fatal disease B. Fortunately, there are anti-A and anti-B drugs that are inexpensive, 100% effective, and free of side-effects. The statisticians have the choice of taking one drug, both, or neither. 

What will the first statistician (an avid Bayesian) do? How about the second statistician, who always uses the maximum likelihood hypothesis?

The doctor does some research and discovers that disease B actually comes in two versions, dextro-B and levo-B, which are equally likely and equally treatable by the anti-B drug. 

Now that there are three hypotheses, what will the two statisticians do?

# Literature
::: {#refs}
:::