---
title: "Seminar Group 4"
subtitle: "Academic Writing (AW)"
lang: en-US

bibliography: ../assets/literature.bib

title-slide-attributes:
  data-background-image: ../assets/bg.jpg
  data-background-size: cover
  data-background-opacity: "1"
  data-background-color: '#0333ff'

date: 11.30.2025

format:      
  presentation-revealjs:
    output-file: fantastic-four.html
    include-before-body: ../assets/footer.html
---

# Motivation

:::medium
Introduction sets expectations for entire thesis. [A good introduction promises: ]{.fragment} [*'here is an important problem, *]{.fragment} [*here is how I will solve it, *]{.fragment} [*and here is the new knowledge the research will produce.'*]{.fragment}
:::

:::fragment
If these points are unclear, readers disengage—even if your methods and findings are excellent.
:::

:::fragment
And: a strong introduction makes the rest of your writing easier.
:::

## Goal

:::large
From good to great — perfecting your thesis introductions.
:::

To demonstrate areas for improvement, we will use real examples from your cohort.

# Structure {.headline-only}

## The 5-paragraph formula

Every introduction needs:

:::incremental
1. Hook - _Why this topic matters now (context)_
2. Background - _What we know from literature (synthesis)_
3. Tension - _What's missing or unresolved (gap/problem)_
4. Resolution - _Your approach to address it (RQ, theory, method)_
5. Contribution - _Expected value of your work (new knowledge)_
:::

:::fragment
**Key principle:** Each element gets its own paragraph(s)
:::

## Overview

:::medium
Most introductions follow the formula,\
with some doing so particularly well.
:::

:::fragment
Several introductions demonstrated:
:::

:::incremental
- **Strong hooks** with contemporary relevance and urgency
- **Good background synthesis** positioning research in current discourse
- **Clear tension statements** identifying specific gaps
- **Appropriate theory selection** for research context
- **Methodological alignment** between RQ and design
:::

:::fragment
While considering the strengths, following patterns have been spotted:
:::

:::incremental
- Theory mentioned but not deeply integrated (theoretical embedding)
- Concepts are too vague and/or scope is too broad (research question operationalisation)
- Too generic or unclear theoretical advancement (contribution statements)
:::

# Theoretical embedding {.headline-only}

## Clarification

Strong theoretical embedding means:

:::incremental
- Your research is **grounded in** and **guided by** established theory
- Theory shapes your research question, design, and interpretation
- You explain **how** the theory applies to your specific context
- You show **what's new** or different about your application
:::

:::medium
[Not just *I will use Theory X*]{.fragment .fade-in-then-semi-out} [but rather *Theory X suggests Y relationship, but in context Z this may work differently because ...*]{.fragment .fade-in}
:::

## Example #1

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
This study draws on Cognitive Offloading Theory. It refers to the process by which
individuals shift mental effort to external systems to offload the burden of mental work
needed for a task (Risko and Gilbert 2016). With respect to AI, this means that instead of
evaluating ideas themselves, individuals increasingly allow AI systems to do the thinking
for them. While this can seem as helpful and efficient at first sight, researchers warn that
this pattern may lead to reduced cognitive effort, sometimes described as cognitive laziness
(Carr 2020), indicating that people may gradually stop using their own analytical abilities
when external tools are at one's fingertips. Over time, this reduced engagement with one's own 
decision-making processes may lower decision self-efficacy (Bandura 1977), which then reinforced
by Zhang et al. (2024), describes the belief in one's ability to make decisions independently. 
Through self-efficacy theory, this study suggests that low self-efficacy will result in increased
anxiety when an individual is forced to use his/her own judgment.
:::

:::link-color
[What's missing here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
Decent theoretical embedding, but the relationship given the specifics of the AI technology could be **explained more clearly**. 

Particularly the theoretical mechanism(s) linking **AI reliance**, offloading, self-efficacy, and anxiety.

:::
:::

:::{.fragment fragment-index=3}
*Improved version:*

Cognitive Offloading Theory (Risko & Gilbert, 2016) posits that individuals shift cognitive work to 
external tools when doing so reduces mental effort without compromising task performance. 
However, [this theory was developed in contexts where tools provide static support]{.highlight} (calculators, notes). 
AI advisory systems differ fundamentally: they actively generate recommendations and evolve through interaction, potentially creating
[dependency rather than augmentation]{.highlight}.

I extend Cognitive Offloading Theory by integrating Self-Efficacy Theory (Bandura, 1977) to explain a critical gap: 
[when does offloading become maladaptive?]{.highlight} I propose that [repeated AI reliance for consequential decisions]{.highlight}
creates a [feedback loop]{.highlight}: offloading reduces practice, practice reduction lowers self-efficacy, low self-efficacy 
increases anxiety when AI is unavailable, anxiety further increases AI dependence. This theoretical integration predicts 
that AI reliance effects vary by decision stakes and frequency—[a boundary condition not examined in either theory alone]{.highlight}.
:::

:::aside
Living with AI as a Co-Decision Maker: Longitudinal Effects of AI Reliance on Students‘ Self-Efficacy and Decision Anxiety (Megi Lluca)
:::

## Example #2

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
To examine whether "the right capability" aligns with "the right task" at each step, the thesis
adopts Task–Technology Fit (TTF) as the primary theoretical lens. TTF distinguishes task
requirements from technology characteristics and posits that higher fit improves task
performance and downstream outcomes (Goodhue & Thompson, 1995). Within this framing,
sourcing, screening, assessment, interviewing and decision/offer are treated as distinct task
environments with heterogeneous information-processing demands; the analysis evaluates how
specific AI capabilities display stronger or weaker fit to these demands, with implications for
matching accuracy and, ultimately, PJF^[Person–job fit].
:::

:::link-color
[What works well here?]{.fragment .custom .display-none fragment-index=5}
:::
:::

:::{.fragment fragment-index=3}
:::{.fragment .custom .display-none fragment-index=5}
Strengths:

- Clear theoretical choice with **explicit justification**
- Shows **how** TTF applies: different recruitment tasks have different requirements
- Explains theoretical mechanism: task-capability alignment → performance → PJF
- Demonstrates **conceptual fit**: TTF naturally maps to research design
- Implies testable predictions (stronger fit = better outcomes)

:::{.fragment fragment-index=4}
However: TTF is extremely difficult to assess (and not many want to read another *lame* TTF-study ;-).
:::

:::
:::

:::{.fragment fragment-index=5}
*Further improvement:*

While TTF has been applied to enterprise technology adoption, [it has not been used to analyze within-process heterogeneity]{.highlight}
—how different stages of a single business process (recruitment) demand different technological capabilities. 
This extension allows us to explain [why AI may excel at screening but underperform in interviewing]{.highlight}, advancing
TTF beyond uniform technology-process assumptions.
:::

:::aside
AI Capabilities in Talent Acquisition and Their Impact on Person–Job Fit: A Systematic Literature Review of Application Fields and Contextual Conditions Across the Recruitment Process (Alina Alles)
:::

## Example #3

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
The research aims to illuminate the interplay between identity, stress and recovery. While
identity theory provides the main explanatory lens, complementary insights from stress,
stereotype, psychological ownership, framing and sensemaking theory inform the broader
conceptual framing.
:::

:::link-color
[What's problematic here?]{.fragment .custom .display-none fragment-index=4}
:::
:::

:::{.fragment fragment-index=3}
:::{.fragment .custom .display-none fragment-index=4}
- **Six theories mentioned** with no explanation of relationships
- *Complementary insights* is vague—how do they complement?
- Reader cannot anticipate what each theory explains
:::
:::

:::{.fragment fragment-index=4}
*Improved approach^[Use one primary theory + specify auxiliary roles]:*

*Identity Theory* (Stets & Serpe, 2013) provides the primary explanatory framework: cybersecurity incidents threaten 
IT professionals' identity as "competent defenders," triggering identity verification processes. 
[I draw on three complementary perspectives to explain contextual variations:]{.highlight}. 
*Job Demands-Resources Theory* explains when organizational support buffers identity threat, and *Sensemaking Theory*
guides analysis of how professionals reconstruct threatened identities post-incident. [This integration explains]{.highlight} both 
universal identity-stress mechanisms and organizational contingencies that moderate outcomes.
:::

:::aside
Beyond the Breach: Understanding the Psychological Impact of Cybersecurity Incidents on IT Professionals (Eslem Saglam)
:::

## Recommendations

To strengthen theoretical embedding:

:::incremental
1. **Choose theory deliberately:** Explain *why* this theory (not just what it says)
2. **Show application:** How does theory *explain your phenomenon*? What mechanisms?
3. **Identify gaps or extensions:** What's *new* about applying theory to your context?
4. **Integrate multiple theories carefully:** Specify *primary* vs. *auxiliary* roles
5. **Derive expectations:** Theory should lead to testable predictions or analytical framework
:::

:::fragment
**Ask yourself:** *Could I conduct this study without the theory? If yes, your embedding is too weak.*
:::

# Research questions {.headline-only}

## Operationalization

Well-operationalized research questions have:

:::incremental
- **Aligned with theory** (concepts map to theoretical constructs)
- **Clear concepts** (every key term is defined or definable)
- **Appropriate scope** (answerable in one thesis with available resources)
- **Specified context** (population, setting, and boundaries stated)
- **Measurable or observable** (it is clear how you'd know you've answered it)
:::

## Example #1

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
:::medium
How do digital platform infrastructures enable the growth and monetization of AI-generated
intimate image abuse, and what regulatory or technical interventions could disrupt this
ecosystem?
:::
:::

:::link-color
[What needs operationalization?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
- "Platform infrastructures" — which components? (hosting, payment, DNS, advertising?)
- "Enable" — direct facilitation or passive permission?
- "Growth" vs. "monetization" — two different dependent variables
- "Regulatory or technical interventions" — evaluating interventions requires different methods than mapping infrastructure (actually, multiple RQs are merged)
:::
:::

:::{.fragment fragment-index=3}
*Operationalized version:*

> RQ1: Which digital infrastructure providers support the 50 most-visited AI nudification and deepfake websites with which services (hosting, payment, DNS, advertising)?
> RQ2: How do current EU regulatory mechanisms address infrastructural enablers?
:::

:::aside
Analyzing the Digital Infrastructure of AI-Driven Intimate Image Abuse (Melisha Benny)
:::

## Example #2

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
To resolve this issue, one of these possible research questions will be investigated:

1. How does IT identity shape the emotional and cognitive responses of IT professionals
   during and after significant cybersecurity incidents?

2. How do variations in IT identity strength and perceived organizational support influence
   IT professionals' coping strategies and long-term psychological outcomes following such
   incidents?
:::

:::link-color
[What's problematic about presenting alternatives?]{.fragment .custom .display-none fragment-index=5}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=5}
- Presenting **alternative RQs** signals indecision and undermines confidence
- RQ1 examines how identity impacts response mechanism (qualitative, exploratory)
- RQ2 examines moderating variables (quantitative, confirmatory)

:::{.fragment fragment-index=3}
BTW: I doubt that IT identity is the right concept here ...
:::
 
:::
:::

:::{.fragment fragment-index=5}
*Choose one RQ and commit:*

> How does professional identity shape IT professionals' emotional and cognitive responses during and after cybersecurity incidents?

or

> To what extent does professional identity strength moderate the relationship between cybersecurity incident severity and anxiety as long-term psychological outcomes, and how does organizational support buffer these effects?

:::

:::aside
Beyond the Breach: Understanding the Psychological Impact of Cybersecurity Incidents on IT Professionals (Eslem Saglam)
:::

## Example #3

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}

How can a security assessment framework evaluate vulnerabilities in LLM-generated code
compared to developer-written code using the dataset SecurityEval?

1. Compare vulnerabilities in LLM-generated code with developer-written code using
   the SecurityEval dataset (Siddiq & da Silva Santos 2022).

2. Design and implement a security assessment framework that integrates vulnerability
   detection techniques with automated mitigation mechanisms, validated through
   quantitative metrics (e.g., precision, recall, F1-score) and qualitative developer
   feedback evaluated through the Technology Acceptance Model (TAM).
:::

:::link-color
[How do objectives differ from RQs?]{.fragment .custom .display-none fragment-index=4}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=4}

- The "RQ" is actually a methodology statement ("how can a framework...")
- Point 1 is an objective (what you'll do), not a question
- Point 2 mixes design (artifact creation), evaluation, and validation
- Real questions are buried: "Are there differences?" and "Is the framework effective?"
:::
:::

:::{.fragment fragment-index=4}
*Operationalized version:*

> To what extent do security vulnerabilities differ between LLM-generated and developer-written code in the SecurityEval dataset, when categorized by CWE type and severity?

And (for evaluation):

> How does the proposed security assessment framework perform in detecting and mitigating vulnerabilities compared to existing static analysis tools, as measured by precision, recall, F1-score, and developer-perceived usefulness?"

*Frame artifact creation (objective 2) as contribution, not as research question.*
:::

:::aside
Security Analysis in LLMGenerated Code: Evaluating Vulnerabilities using SecurityEval Dataset (Vincy Methassery Jacob)
:::

## Example #4

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
:::medium
How and under what conditions does LLM grooming influence model retrieval and output
behaviour, particularly through variations in prompt sensitivity, and what safeguards could
mitigate such manipulation?
:::
:::

:::link-color
[What could be improved?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}

- "LLM grooming" needs operational definition upfront
- "Influence" is vague—increase in what (frequency, accuracy, ranking)?
- Two questions merged ("how does" + "what safeguards")

:::smaller
Strengths

- Specifies mechanism ("prompt sensitivity")
- Includes contingency ("under what conditions")
- Bounded scope (retrieval and output behavior)
:::

:::
:::

:::{.fragment fragment-index=3}
*Suggestion*

> RQ1: Under what conditions^[prompt framing, query type, real-time search activation] do LLMs reproduce content from coordinated propaganda networks in their outputs, and how does reproduction frequency vary across these conditions?

> RQ2: What safeguards^[prompt filtering, source verification, output monitoring] show potential to reduce propaganda reproduction?

*Each RQ is independently answerable with clear success criteria*
:::

:::aside
Investigating LLM Grooming: How Prompt Variations Shape Model Behaviour and Information Integrity (Christina Frömmel)
:::

## Recommendations

Test RQ operationalization with these questions:

:::incremental
1. **Concept clarity:** Can you define every key term specifically?
2. **Measurability:** What exactly would you measure/observe/analyze?
3. **Scope:** Could you complete this in one thesis with available data/access?
4. **Outcomes:** What would "answering" this question look like?
5. **Single focus:** Is this actually 2+ questions disguised as one?
:::

:::fragment
:::small
*Common fixes:*

- Split compound RQs into separate sub-questions
- Replace vague verbs ("influence," "affect") with specific relationships ("increase," "moderate," "mediate")
- Add operational definitions for novel concepts
:::
:::


# Contributions {.headline-only}

## Guidelines

Strong contribution statements:

:::incremental
- **Name specific theories** being extended, challenged, or integrated
- **Identify concrete deliverables** (what artifact/model/framework will exist?)
- **Specify novel constructs or relationships** being introduced
- **Differentiate theoretical and practical contributions** explicitly
- **Show advancement** (what can we know/do afterward that we couldn't before?)
:::

## Example #1

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
Theoretically, it extends the literature on technology-facilitated sexual violence by incorporating
insights from socio-technical systems theory and digital platform governance, reframing image-based
abuse as an infrastructural rather than behavioral problem.
:::

:::link-color
[What's too vague here?]{.fragment .custom .display-none fragment-index=4}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=4}

- "Extends the literature" — every study does this; how specifically?
- "Incorporating insights from" — what insights? Which concepts?
- "Reframing as infrastructural" — good insight, but what's the **theoretical claim**?
- Missing: What new construct, relationship, or framework does this create?
:::
:::

:::{.fragment fragment-index=4}
*More specific version:*

This study extends technology-facilitated sexual violence (TFSV) research by [introducing the concept 
 "abuse-enabling infrastructure"]{.highlight}—the technical and economic systems (hosting, payment, advertising) 
that mediate between abusive actors and victims.

Drawing on socio-technical systems theory (Trist & Bamforth, 1951), I argue that [intervention must target systemic 
interdependencies]{.highlight} rather than individual platforms. Specifically, I demonstrate that payment gatekeeping 
and hosting accountability function as structural bottlenecks capable of disrupting abuse networks—
[challenging the current regulatory focus on content moderation alone.]{.highlight}

This reframes TFSV from a behavioral problem requiring victim reporting to an infrastructural problem requiring 
systems-level governance, advancing theory by identifying previously unexamined leverage points for intervention.
:::

:::aside
Analyzing the Digital Infrastructure of AI-Driven Intimate Image Abuse (Melisha Benny)
:::

## Example #2

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
The expected contribution is twofold. First, it will provide an initial theoretical framework for
understanding LLM grooming as a form of information operation targeting foundation models.
Second, it will identify and evaluate practical safeguards that can strengthen the epistemic
resilience of large-scale language systems.
:::

:::link-color
[What works? What could improve?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
**Strengths:**

- Clear two-part structure (theoretical + practical)
- Introduces novel concept ("epistemic resilience")
- Promises framework creation

**Room for improvement:**

- "Initial framework" — what are its components?
- "Identify and evaluate safeguards" — which ones? How evaluated?
- Missing: How does framework **extend existing theory**?
:::
:::

:::{.fragment fragment-index=3}
*Enhanced version:*

This study extends Information Foraging Theory (IFT) from individual cognition to [adversarial information environments]{.highlight}.
I introduce the concept of ["information patch poisoning"]{.highlight}: deliberate manipulation of cue density and relevance signals
that IFT-driven systems use for retrieval decisions.

The study contributes a [theoretically-grounded vulnerability taxonomy]{.highlight} identifying three exploitation vectors: 
(1) cue salience manipulation, (2) source authority spoofing, and (3) retrieval pathway optimization. This framework 
[predicts how grooming effectiveness varies by query type and search mechanism]{.highlight}—advancing IFT into contested information spaces.

The research evaluates five safeguard strategies (source diversity requirements, temporal verification, cross-reference validation)
against the theoretical taxonomy, delivering [evidence-based design principles]{.highlight} for LLM developers and 
red-teaming protocols for information integrity auditors.
:::

:::aside
Investigating LLM Grooming: How Prompt Variations Shape Model Behaviour and Information Integrity (Christina Frömmel)
:::

## Recommendations

Make contributions specific and concrete:

:::incremental
1. **Name your theories:** Which specific theory are you extending?
2. **Identify deliverables:** What tangible artifact/framework/model will exist?
3. **Specify novel elements:** What construct/relationship/mechanism is new?
4. **Show advancement:** What becomes possible afterward?
5. **Differentiate types:** Theory contribution ≠ practical contribution ≠ methodological contribution
:::

:::fragment
**Use the specificity test:**

- *What exactly will exist after this study?* (name it)
- *Which theory are you extending?* (must name specific theory)
- *What new construct/relationship?* (must be nameable and definable)
:::

# Language and style {.headline-only}

# Summary {.headline-only}

## Key takeaways

:::incremental
- **Theoretical embedding** requires showing **how theory explains** your phenomenon, not just citing it
- **Multiple theories** need explicit integration model—specify primary vs. auxiliary roles
- **Research questions** must be operationalized: clear concepts, measurable, appropriate scope
- **Contributions** need specificity: name theories, deliverables, and novel elements
- **Avoid generic language:** "extends literature", instead specify theory and contribution
- **Objectives ≠ research questions:** "Compare X" is what you do, not what you ask
:::


## Final advice

:::incremental
- **Start specific, not general:** Easier to broaden than narrow during revision
- **Make theory work for you:** Choose theories that **genuinely explain** your phenomenon
- **Write testable:** Can someone design a study from your RQ? If not, add precision
- **Name everything:** Contributions, constructs, frameworks—unnamed elements feel vague
- **Read aloud:** If you stumble explaining theory application, so will your reader
:::

:::{.fragment .medium}
Strong introductions require multiple revisions—every pass should increase precision!
:::

# Q&A {.html-hidden .headline-only}

Find slides here:

{{< qrcode http://awe-hnu.github.io/lectures/AW/25WT/seminar/fantastic-four.html qr1 width=200 height=200 colorDark='#0333ff' >}}

(only for your personal use, do not share)