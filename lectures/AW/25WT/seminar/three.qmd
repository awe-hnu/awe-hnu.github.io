---
title: "Seminar Group 3"
subtitle: "Academic Writing (AW)"
lang: en-US

bibliography: ../assets/literature.bib

title-slide-attributes:
  data-background-image: ../assets/bg.jpg
  data-background-size: cover
  data-background-opacity: "1"
  data-background-color: '#0333ff'

date: 11.30.2025

format:      
  presentation-revealjs:
    output-file: thr33.html
    include-before-body: ../assets/footer.html
---

# Motivation

:::medium
Introduction sets expectations for entire thesis. [A good introduction promises: ]{.fragment} [*'here is an important problem, *]{.fragment} [*here is how I will solve it, *]{.fragment} [*and here is the new knowledge the research will produce.'*]{.fragment}
:::

:::fragment
If these points are unclear, readers disengage—even if your methods and findings are excellent.
:::

:::fragment
And: a strong introduction makes the rest of your writing easier.
:::

## Goal

:::large
From good to great — perfecting your thesis introductions.
:::

To demonstrate areas for improvement, we will use real examples from your cohort.

# Structure {.headline-only}

## The 5-paragraph formula

Every introduction needs:

:::incremental
1. Hook - _Why this topic matters now (context)_
2. Background - _What we know from literature (synthesis)_
3. Tension - _What's missing or unresolved (gap/problem)_
4. Resolution - _Your approach to address it (RQ, theory, method)_
5. Contribution - _Expected value of your work (new knowledge)_
:::

:::fragment
**Key principle:** Each element gets its own paragraph(s)
:::

## Overview

:::medium
Most introductions follow the formula,\
with some doing so particularly well.
:::

:::fragment
Others make a good attempt, but have the following issues:
:::

:::incremental
- The hook could be more powerful.
- The hook is blended with the background.
- Too extensive review of literature without clear synthesis.
- Weak boundary between the tension and resolution.
- The gap only emerges implicitly through literature.
- The gap is presented *as absence* rather than *as problem*.
- The research question is vague and/or too broad.
- Contribution statements are too generic.
:::

# Hook {.headline-only}

## Example #1 — power of the hook

:::fragment
:::{.fragment .custom .display-none}
As artificial intelligence (AI) becomes increasingly integrated into organizational decision-making
processes, its benefits and associated risks have become a top priority for users and
researchers. AI systems now determine who gets hired and who is evaluated for
performance, and it’s doing this through a new form of algorithmic accountability and
ethical exposure (Bauer & Gill, 2024; Rhue, 2024). With the increasing popularity of
Responsible-AI frameworks seeking to promote fairness, transparency, and trustworthiness
(Papagiannidis, Mikalef, & Conboy, 2025), making employees aware of and adhering to
these principles becomes increasingly important. Yet, recent insights indicate that, even
when employees use AI systems that they have only a partial understanding of, they tend to
suffer from ambiguity and moral strain (Jussupow, Benbasat, & Heinzl, 2024). This
increasing divergence between organizational AI governance aspirations and employees’
perception of risks associated with AI use highlights a new issue for the sustainable and
ethical implementation of AI.
:::

:::link-color
What works here? What could improve?
:::
:::

:::fragment
*Could add more urgency—what's at stake **right now?***

AI systems now make over 50% of hiring and performance decisions in Fortune 500 companies [Source], yet 73% of employees report they don't understand how these systems work or when to question their recommendations [Source]. [This opacity creates a critical governance challenge]{.link-color} ...
:::

:::aside
Investigating Employees’ Perceptions of AI Risks and Compliance: Toward an Extension of Organizational Risk-Compliance Theory (Ernest Aduwenye)
:::

## Recommendations

Consider structuring your first paragraph as follows:

:::medium
[From [context]{.highlight} (what is happening in the world?) ]{.fragment .fade-in-then-semi-out}\
[to [importance]{.highlight} (why is this timely/important *now*?)]{.fragment .fade-in-then-semi-out}\
[to the [puzzle]{.highlight} (what is problematic/surprising?)]{.fragment .fade-in-then-semi-out}
:::

## Example #2 — background blending

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
Technological innovation is widely regarded as a primary catalyst for competitiveness, growth, 
and long-term corporate development (Damanpour 1991). In knowledge-and technology-intensive industries
in particular, a company's ability to develop and successfully implement new products and processes 
is a determining factor in its adaptability and survivability in dynamic markets (Teece 2007). 
Whilst innovation research has historically concentrated on large, professionally managed companies, 
in recent years the innovation performance of small, owner-managed companies has attracted increasing 
attention (Kearney et al. 2017; Massis et al. 2017).

The owner-managed small and medium-sized enterprise (OMSME) is a unique entity characterised by a 
high degree of personal and cognitive influence of the owner on strategic and operational decisions. 
The owner's dual roles as manager and central decision-maker result in the presence of short 
communication channels, informal processes, and a pronounced personality-driven organisational 
culture (Hambrick and Mason 1984; Zahra 2018).
:::

:::link-color
[What is the probleme here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
The opening immediately launches into literature—this is background (what research tells us), not a hook (what's the problem?). 

The reader is confronted with theoretical statements before understanding **why this topic matters** and/or what organizational challenge exists.
:::
:::

:::{.fragment fragment-index=3}
*Possible revision:*

Owner-managed small and medium-sized enterprises face a critical paradox: they must continuously innovate to survive in dynamic markets, yet they operate under constraints that make innovation systematically difficult [Source]. 
Unlike large corporations with dedicated R&D departments, professional management teams, and deep resource pools, owner-managed SMEs rely heavily on one person—the owner—who must simultaneously maintain daily operations, manage customer relationships, and drive innovation [Source].
This dual role creates constant tension: short-term operational demands crowd out long-term innovation investments. The stakes are high—70% of German SMEs are owner-managed [Source], forming the backbone of the economy, yet many struggle to sustain innovation beyond the founder's initial ideas. 
The puzzle is: how do these resource-constrained, personality-driven organizations develop systematic innovation capabilities rather than relying solely on the owner's sporadic insights?

Innovation research offers insights ... Foundational work establishes ...
:::

:::aside
Innovation Capability in Owner-Managed SMEs: Dynamic Capabilities and the Early Innovation Phase (Anne Steinhauser)
:::

## Recommendations

Your first paragraph is a proper hook if it:

:::incremental
- Describes a **contemporary challenge or puzzle** (individual, organizational, or societal)
- Uses vivid, **specific examples** (with numbers/statistics if possible)
- **Establishes stakes:** *What's at risk?*
- Contains citations only for statistics/facts, not theory
- Makes the reader think *Yes, that is a problem—how do we solve it?*
:::

# Background {.headline-only}

## Example — missing synthesis

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
In research, [...] generally called speech emotion recognition (SER). SER has moved from theory to 
practice in recent years. For example, Yurtay et al. (2024) trained deep learning models on large
volumes of real call-centre audio in Turkish and showed that it is possible to classify
broad affective states. Similarly, Martín-Doas et al. (2024) presented an industrial
pipeline for Spanish call centres that uses modern self-supervised speech models to extract
emotion-related information at scale. However, emotion in a call is rarely static. [...]
Feng and Devillers (2023) respond to this limitation by modelling emotion as something
that changes continuously over time. [...] Macary et al. (2023) combined acoustic
descriptors—how something is said—with linguistic descriptors—what is said—to estimate
customer satisfaction continuously across a call. [...] There is also a very practical
challenge. Real service audio includes background noise, poor microphones, people talking
over each other [...]. Parra-Gallego and Orozco-Arroyave (2021) [...] introduce phonation,
articulation and prosody features that are specifically designed to survive harsh acoustic
conditions.
:::

:::link-color
[What is the probleme here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
Reads like a comprehensive literature review, not a synthesized background paragraph.

What came to my mind is: *When will this end? What's the **main point?***
:::
:::
:::{.fragment fragment-index=3}
*Possible revision:*

Speech Emotion Recognition (SER) has evolved from static classification to dynamic, context-aware analysis. Early industrial applications classified entire calls with single emotion labels (Yurtay et al., 2024; Martín-Doas et al., 2024), but recent work recognizes emotion shifts throughout conversations, modeling continuous temporal changes rather than fixed states (Feng & Devillers, 2023). Researchers now combine acoustic signals (how something is said) with linguistic content (what is said) for richer analysis (Macary et al., 2023), and address real-world complexities like multilingual code-mixing (Abhishek & Bhattacharyya, 2023) and noisy environments (Parra-Gallego & Orozco-Arroyave, 2021). However, these advances share a limitation: they focus on technical accuracy without addressing how emotion-aware systems should ethically support service interactions.
:::

:::aside
EmoVoice: Understanding Customer Emotions Through Voice Analysis (Dharati Trivedi)
:::

## Recommendations

The background is properly synthesized if it:

:::incremental
- **Groups citations** thematically (by approach, not chronologically)
- **Shows relationships** between sources (builds on, contradicts, extends)
- **Highlights evolution** in thinking: early work → recent advances
- **Stays concise** (6-10 sentences maximum for your initial introduction)
- **Builds toward the gap** (sets up what we know, *preparing for what we don't know*)
:::

:::fragment
Synthesis patterns to use:

- "Early work established X (cite), while recent studies reveal Y (cite)"
- "Research has progressed from A to B to C"
- "Two schools of thought have emerged: X approach (cite) vs. Y approach (cite)"
- "These studies collectively show... however, they share a limitation..."
:::

# Tension {.headline-only}

## Example #2 — merged middle

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
[...] Despite these technological advancements[^1], two critical gaps remain in literature. First,
there is limited research on how service ticket data can be systematically analyzed to
detect workforce skill gaps and [...]. Organizations continue to rely
heavily on lagging indicators [...] while overlooking the wealth of frontline knowledge
embedded in support documentation. Second, [...] there remains a lack of comparative
studies focused on their application in enterprise learning contexts. It is still unclear
which method offers the best trade-off between accuracy, explainability, and integration
feasibility [...]. These gaps [...] leave practitioners without clear guidance on how to
adopt AI tools for learning analytics. This thesis aims to address these issues through
the following research question: What AI-based framework should be designed and evaluated
to identify training gaps [...], and how do its constituent methods (classic NLP pipelines
and local LLMs) compare in effectiveness and integration suitability? To investigate this
question, the study follows a Design Science Research (DSR) methodology [...]. The research
involves building [...]
:::

[^1]: Sidenote: the sentence before does not discuss advantages.

:::link-color
[What is the probleme here?]{.fragment .custom .display-none fragment-index=6}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=6}

:::{.fragment fragment-index=3}
**The gap and solution run together** in one paragraph—no boundary between "what's wrong" and "what I'll do about it"
:::

:::{.fragment fragment-index=4}
The gap feels like **two disconnected problems forced together**:

- Domain-specific: *We need better ways to use ticket data for training*
- Methodological: *We need to compare NLP vs. LLMs in enterprise contexts*  (with training as a convenient testbed)

The gap's coherence—and thus the introduction—could be strengthened by focusing on one core problem.
:::

:::{.fragment fragment-index=5}
Almost all **factual claims without any evidence**
:::
:::
:::

:::{.fragment fragment-index=6}
*Possible revision (without necessary references):*

Despite advances in learning analytics, organizations continue identifying skill gaps reactively through surveys and performance reviews, detecting problems 6-12 months after they emerge. This costs organizations in repeated service incidents that trained employees could prevent. Meanwhile, thousands of daily support tickets document exactly which knowledge gaps frontline teams encounter, yet this operational intelligence remains systematically underutilized. Without methods to extract training insights from service interactions, organizations miss opportunities to proactively address emerging skill deficiencies before they cascade into customer-facing failures.

To address this gap, this study develops an AI-based framework that transforms support ticket data into predictive training recommendations using DSR methodology. The framework compares traditional NLP pipelines with locally-deployed LLMs to provide evidence-based guidance for organizations choosing between approaches for learning analytics applications.
:::


:::aside
From Service Tickets to Predictive Training: An AI Framework for Organizational Skill-Gap Detection (Mohamed Bouna)
:::

## Example #2 — weak boundary

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
[...] Consequently, data products today primarily provide the technical foundation for
scaling advanced services but not the dual value logic required by complete servitization.
Achieving this would mean integrating external customer outcomes and internal process
optimization in a continuous feedback process.

Based on these observations in current servitization, data product, and Industry 4.0
literature, the following research question is posed: How should data products be designed
in terms of their concept, monetization strategy, and organizational anchoring to fulfill
the full servitization logic as "factory-integrated substituting services" and achieve a
two-sided value contribution for both customer outcomes and internal processes?
:::

:::link-color
[What is the probleme here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
The paragraphs are technically separate, but the boundary is weak.

- Tension ends with: "...integrating external customer outcomes and internal process optimization"
- Resolution starts with: "Based on these observations in current [...] literature, the following research question is posed:"

The vague transition ("Based on these observations...") doesn't clearly signal the move from gap to resolution.
:::
:::

:::{.fragment fragment-index=3}
*Possible revision (sources need to be added):*

[...] Consequently, data products today provide technical infrastructure for scaling services but lack the dual value logic of complete servitization. This limits their potential: organizations can improve internal data management but cannot [...]. Without integrating servitization principles, data products remain internal efficiency tools rather than revenue-generating service offerings, leaving organizations unable to [...].

To address this gap, this thesis investigates how data products can evolve beyond internal management tools to become servitized, outcome-oriented offerings that fulfill the complete servitization logic. The research question asks: How should data products be designed in terms of concept, monetization strategy, and organizational anchoring to achieve two-sided value contribution for both customer outcomes and internal processes? Using conceptual research that bridges servitization and data product literature, the study develops design principles for organizations establishing service-oriented business models around data assets.
:::

:::aside
Servitization of Data Products: Extending the Concept of Data Products toward Service-Oriented Business Models (Philip Gassmann)
:::

## Example #3 — gap emerges implicitly

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
Literature review discusses:

- Adversarial attack research
- LLM-specific vulnerabilities
- Jailbreaking techniques and safety evaluation methods
- Multiple evaluation frameworks and benchmarks

After 5-6 paragraphs of literature review without synthesis:

Together, these works highlight a common problem: evaluation methods focus either on
deterministic adversarial examples or qualitative jailbreak demonstrations, but rarely
provide probabilistic estimates of model robustness under varied attack conditions. However,
these two approaches have so far developed separately [...]
:::

:::link-color
[What is the probleme here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
The gap doesn't have its own paragraph—**it emerges implicitly** after extensive literature review.

The reader must piece together *what's missing* from scattered hints throughout the background section, rather than encountering a clear, dedicated gap statement.
:::
:::

:::{.fragment fragment-index=3}
*Possible revision (sources need to be added):*

Adversarial robustness research has evolved from early image-based attacks to LLM-specific vulnerabilities like prompt injection and jailbreaking. Current evaluation approaches fall into two camps: deterministic adversarial testing that measures specific attack success rates, and qualitative jailbreak demonstrations that show proof-of-concept exploits.

However, these evaluation methods share a critical limitation: neither provides probabilistic estimates of overall model robustness under varied attack conditions. Deterministic tests measure narrow scenarios but don't quantify the full attack surface. Qualitative demonstrations show vulnerabilities exist but don't measure their likelihood or severity. This leaves organizations deploying LLMs unable to estimate: "What is the probability this model will fail under adversarial pressure?" Without probabilistic robustness metrics, safety teams cannot make risk-informed deployment decisions or compare model resilience systematically.
:::

:::aside
Probabilistic Evaluation of LLM Robustness against Adversarial attacks (Javeria Raja)
:::

## Example #4 — gap as absence vs. problem

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}
The consequences of algorithmic persuasion in health situations have recently been the
subject of scholarly investigation. According to Liu-Thompkins et al. (2022), emotionally
intelligent algorithms can mimic empathy to increase user engagement, but if used without
ethical guidelines or transparency, they may also have unforeseen psychological effects.
[...] A significant gap remains where the literature provides little information about
the impact of emotional targeting in AI-driven health-related advertisements on users'
anxiety or perceived autonomy in the area of making health decisions, in spite of
advancements in associated fields like algorithmic bias (Mittelstadt et al., 2016),
misinformation (Bridgman et al., 2020), and chatbot-based mental health tools (Li et al.,
2023).
:::

:::link-color
[What can be improved here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}
The intro only states what's missing from literature, not what's broken in practice.

- "Literature provides little information" (academic gap only)
- "In spite of advancements" (comparison with other areas — why should I care?)

No explanation of real-world harm or organizational/individual cost
:::
:::

:::{.fragment fragment-index=3}
*Possible revision (sources need to be added):*

Emotionally intelligent algorithms now target vulnerable health decisions through fear and hope appeals, 
yet we cannot predict or prevent the psychological harm this creates. Research shows AI can mimic empathy 
to boost engagement (Liu-Thompkins et al., 2022), [but without understanding how emotional targeting affects 
anxiety and autonomy, platforms deploy these systems blind to their psychological impact.]{.highlight} 
The consequence: users experiencing health crises—cancer diagnoses, chronic conditions, mental health 
episodes—encounter AI-optimized ads designed to exploit their emotional vulnerability. [These users cannot 
distinguish genuine health information from emotionally manipulated persuasion]{.highlight}, leading to 
anxiety-driven decisions (hasty treatments, unnecessary purchases, delayed care) that worsen health outcomes. 
Platforms profit from emotional targeting while remaining unaccountable for the psychological harm, leaving 
users and regulators unable to establish ethical boundaries for AI-driven health advertising.
:::

:::aside
Emotional Targeting in AI-Driven Health Ads on Social Media: Implications for Decision-making and Health Anxiety (Dina Mohamed)
:::

## Recommendations

Your tension and resolution paragraph(s) are properly separated if:

:::incremental
- The tension ends with the problem/consequence (not your solution)
- The resolution starts with "To address this gap..." or similar transition
- A reader can draw a line between "what's wrong" and "what I'll do"
- The tension contains *zero* mention of your method, approach, or research question
- The resolution focuses entirely on your approach, not re-explaining the gap
:::

:::fragment
Reframe absence framing to problem framing (e.g., "no research exists on [...]" to "organizations cannot [...] because [...]" )
:::

:::fragment
After stating your gap, ask yourself *so what?* until you reach a tangible real-world-impact.
:::

# Resolution {.headline-only}

## Example #1 — vague constructs

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}

[How does emotional microtargeting in AI-powered social media health advertisements affect users' decision-making and health anxiety?]{.medium}

:::

:::link-color
[What is vague here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}

Multiple undefined terms that need operationalization:

- *Emotional microtargeting* — Which specific techniques? Fear appeals? Hope messaging? Personalized empathy?
- *Affect* — Increase/decrease? Change type? Mediate? Moderate?
- *Decision-making* — Which decisions? Treatment choices? Product purchases? Information seeking?
- *Health anxiety* — Temporary worry? Clinical anxiety? Health-related fear?

Reading the introduction, I cannot determine what you'll actually focus on (and how you will measure it).

:::
:::

:::{.fragment fragment-index=3}
*Possible revision*

> RQ1: How do fear-based versus hope-based emotional appeals in AI-targeted health advertisements influence individuals' tendency toward immediate action or deliberative consideration in treatment decisions?

> RQ2: How does this relationship differ based on baseline health anxiety levels?

:::incremental
- Specific dependent variables: immediate vs. deliberative decision-making
- Comparable conditions: fear vs. hope appeals
- Specific moderator: baseline anxiety (measured e.g., by Health Anxiety Inventory)
:::
:::

:::aside
Emotional Targeting in AI-Driven Health Ads on Social Media: Implications for Decision-making and Health Anxiety (Dina Mohamed)
:::

## Example #2 — too many questions

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}

> How can an AI-based assistant system be designed to support junior project managers in the practical application of project management methods during the planning and executing phases?

Sub-questions:

- What features should the system include?
- How do junior PMs perceive its usefulness?
- Does it improve planning quality?
- What are the acceptance factors?

:::

:::link-color
[What is the problem with the (multitude of) questions?]{.fragment .custom .display-none fragment-index=4}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=4}

Combines design, perception, effectiveness, and adoption questions—this indicates at least 3+ separate studies:

- Design science study (what to build; effectiveness as evaluation criteria)
- Perception study (user experience)
- Adoption study (acceptance factors)

:::{.fragment fragment-index=3}
Also vague:

- "Support" — how exactly? Automate? Suggest? Validate? Teach?
- "Planning and executing phases" — 100+ possible activities
- No comparison baseline specified
:::
:::
:::

:::{.fragment fragment-index=4}
*More focused question:*

> How does an AI assistant providing real-time risk identification prompts during project planning improve risk coverage completeness among junior project managers compared to traditional checklist-based planning?

:::incremental
- Single focused question (effectiveness)
- Specific intervention (real-time risk prompts)
- Specific activity (risk identification in planning)
- Measurable outcome (% of risk categories identified)
- Comparison baseline (traditional checklists)
:::

:::

:::aside
Development of an AI-Based Assistant System for Supporting Junior Project Managers in Planning and Executing Phases (Emily Brotzmann)
:::

## Example #3 — no comparison baseline

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}

[How do different explanation designs affect advice-seeking users' appropriate reliance on Al career guidance?]{.medium}

:::

:::link-color
[What's vague here?]{.fragment .custom .display-none fragment-index=3}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=3}

Multiple undefined terms:

- "Appropriate reliance" — needs operational definition (agreement with correct predictions + disagreement with incorrect ones?)
- "Advice-seeking users" — would also benefit from focus (e.g., Students, career changers, all adults, specific experience levels?)

:::
:::

:::{.fragment fragment-index=3}
*More operationalized version:*

> RQ1: Do SHAP feature importance explanations (versus simple confidence scores) improve students' alignment with expert career counselor judgments[^2] when evaluating AI-generated major selection advice?

> RQ2: How does this effect vary by students' career decision-making self-efficacy?

[^2]: Alignment with expert careed counselor judgements is measured as agreement rate with expert-endorsed recommendations minus agreement rate with expert-rejected recommendations.

:::incremental
- Specific comparison (SHAP explanations vs. confidence scores)
- Operational definition (alignment with expert career counselor judgments — only serves as a proxy for recommendation quality)
- Specific population and context (undergraduate students and major selection decisions) 
- Moderator specified (career decision-making self-efficacy)
:::

:::

:::aside
When to Trust the Algorithm: Measuring Appropriate Reliance in AI Career Guidance with SHAP Explanations (Uddeshya Singh)
:::

## Recommendations

Test if your RQ is well-operationalized by asking following questions:

:::incremental
- *What exactly would you measure?* (if they can't answer specifically, add operational definitions)
- *What would success look like?* (if unclear, specify measurable outcomes)
- *Compared to what?* (if no baseline exists, add comparison condition)
- *Could you do this in one thesis?*
:::

# Contribution {.headline-only}

## Example #1 — generic theory claim

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}

This study contributes both theoretically and practically. Theoretically, it extends
information systems research on XAI and human-AI collaboration in financial contexts.
Practically, it offers design principles for organizations implementing cloud cost
forecasting systems.

:::

:::link-color
[What's too generic here?]{.fragment .custom .display-none fragment-index=4}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=4}

Multiple generic claims without specifics:

- "Extends IS research" — Every study extends research. How specifically?
- "In financial contexts" — What's novel about the financial context?
- "Offers design principles" — How many principles? For what aspects?

:::{.fragment fragment-index=3}
Missing:

- Which XAI theory/framework are you extending?
- What new constructs or relationships are you proposing?
- What exactly will practitioners receive?
:::
:::
:::

:::{.fragment fragment-index=4}
*More specific version:*

This study makes three specific contributions. Theoretically, it extends XAI effectiveness research by 
demonstrating that explanation utility is moderated by decision stakes and user expertise—challenging 
the assumption that more transparency always improves trust. The study contributes a contingency framework 
specifying when SHAP explanations help versus harm decision quality in financial forecasting. Methodologically, 
it provides a validated instrument for measuring explanation comprehension in financial contexts. 
Practically, it delivers six design principles for cloud cost forecasting UIs, specifying: (1) when to show 
SHAP values vs. confidence intervals, (2) expertise-based explanation scaffolding, and (3) progressive disclosure 
patterns for complex forecasts.

:::

:::aside
Bridging Trust and Transparency: Explainable Artificial Intelligence for Cloud Cost Forecasting (Yannic Urban)
:::

## Example #2 — vague practical value

:::{.fragment fragment-index=1}
:::{.fragment .custom .display-none fragment-index=2}

The expected contribution of this thesis is threefold. First, it delivers design knowledge
for AI-powered assistance tools tailored to the needs of junior project managers. Second,
it offers empirical insights into user acceptance, task alignment and human-AI collaboration
in project environments. Third, it contributes to the academic discourse on AI in project
management by applying and integrating TAM, TTF and Human-AI Complementarity into a coherent
and practically tested design approach.

:::

:::link-color
[What's too generic here?]{.fragment .custom .display-none fragment-index=4}
:::
:::

:::{.fragment fragment-index=2}
:::{.fragment .custom .display-none fragment-index=4}

Lists contribution areas but no concrete deliverables:

- "Design knowledge" — What kind? Principles? Patterns? Guidelines? How many?
- "Empirical insights" — What specifically will we learn? What relationships?
- "Contributes to discourse" — Not a contribution
- "Applying and integrating" — Application isn't contribution; what's new in the integration?

:::{.fragment fragment-index=3}
Missing:

- What artifact will exist after this study?
- What new knowledge will practitioners have?
- What theories are being challenged or extended?
:::
:::
:::

:::{.fragment fragment-index=4}
*More specific version (aligned to the refined RQ):*

This study makes three contributions. First, it provides evidence that real-time AI risk identification prompts improve 
risk coverage completeness compared to traditional checklists among junior PMs. Second, it challenges the assumption that 
more information aids novice decision-making—demonstrates that interactive prompting outperforms comprehensive checklists 
because it reduces cognitive load during planning (supporting cognitive load theory in PM contexts). Third, we provide a 
validated prototype demonstrating effective prompt timing, prompt specificity, and prompt density that organizations can 
implement in existing PM tools.

:::

:::aside
Development of an AI-Based Assistant System for Supporting Junior Project Managers in Planning and Executing Phases (Emily Brotzmann) 
:::

## Recommendations

Strong contribution statements specify:

:::incremental
- **Named theories/frameworks*** you're extending, challenging, or integrating
- **Specific constructs or relationships** being introduced or tested
- **Concrete deliverables** — What artifact/knowledge/tool will exist after your study?
:::

:::fragment
Use specificity test and ask
:::

:::incremental
- *What exactly will exist after this study?* (name the artifact/model/framework)
- *Which theory are you extending?* (must refer to a specific theory, not "IS research")
- *What new construct/relationship are you proposing?* (must be nameable)
- *How will we know you succeeded?* (should have measurable indicators)
:::

# Language and style {.headline-only}

# Summary {.headline-only}

## Key takeaways

:::incremental
- **Each paragraph has one job:** Hook (problem), Background (what we know), Tension (what's wrong), Resolution (your approach), Contribution (new knowledge)
- **Strong transitions matter:** Clear boundaries between paragraphs guide your reader through your argument
- **Gaps are problems, not absences:** Transform "no research exists" into problems
- **Specificity separates good from great:** Name your theories, operationalize your constructs, quantify your outcomes
- **Your RQ must be doable:** One focused question you can answer in one thesis
- **Contributions need deliverables:** State what artifact/model/framework will exist and which specific theory you're extending
:::

## Final advices

:::incremental
- **Start with structure, end with flow:** Use the 5-paragraph formula as scaffolding, then polish for natural reading
- **Invest time in your hook:** A compelling first paragraph earns you an engaged reader for the entire thesis
- **Read your introduction aloud:** If you stumble or get lost, so will your reader
- **Get specific early:** Vague language signals unclear thinking—operationalize as you write, not during revision
- **Test with the "So What?" question:** Keep asking until you reach tangible impact—this reveals your real contribution
:::

:::{.fragment .medium}
Great introductions aren't written, they're rewritten!
:::

# Q&A {.html-hidden .headline-only}

Find slides here:

{{< qrcode http://awe-hnu.github.io/lectures/AW/25WT/seminar/thr33.html qr1 width=200 height=200 colorDark='#0333ff' >}}

(only for your personal use, do not share)